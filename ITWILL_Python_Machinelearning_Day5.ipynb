{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 판다스 배운 내용 복습\n",
    "\n",
    "1. 판다스 기본 문법과 판다스 데이터 구조\n",
    "2. 판다스에서 데이터 검색하는 방법\n",
    "3. 판다스로 그래프 그리는 방법\n",
    "    - matplotlib \n",
    "    - seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 6장. 데이터 전처리\n",
    "\n",
    "1. 누락 데이터 처리\n",
    "2. 중복 데이터 처리\n",
    "3. 데이터 표준화\n",
    "4. 범주형 데이터 처리\n",
    "5. 정규화\n",
    "6. 시계열 데이터 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 1. 누락 데이터 처리\n",
    "   - 누락 데이터 제거 : 열삭제 , 행 삭제\n",
    "   - 누락 데이터 치환\n",
    "        1. 평균값\n",
    "        2. 가장 빈번한 값\n",
    "        3. 바로 앞행의 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 2. 중복 데이터 처리 \n",
    "   - 중복 데이터를 검색\n",
    "   - 중복 데이터 제거 하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 3. 데이터 표준화\n",
    "### - 키와 체중처럼 서로 다른 단위가 섞여있거나 같은 대상을 다른 형식으로 표현한 경우 표준화가 필요하다.\n",
    "\n",
    "   - __3.1 단위환산 :__ 같은 단위로 맞춰주는 작업\n",
    "   - __3.2 자료형 변환 :__ 숫자가 문자열로 저장된 경우, 숫자(int)로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 4. 범주형 데이터 처리\n",
    "   - 4.1 구간 분할\n",
    "        - 데이터 분석 알고리즘에 따라서 연속데이터를 그대로 사용하기 보다는 일정한 구간으로 나누어서 분석하는것이 효율적인 경우가 있다.  \n",
    "          가격, 비용, 효율 등 연속적인 값을 일정한 수준이나 정도를  나타내는 이산적인 값으로 나타내어 구간별 차이를 드러내는 것이다.\n",
    "          \n",
    "    \n",
    "          \n",
    "   - 4.2 더미 변수 생성 : 데이터를 숫자 0 또는 1로 표현하는 변수를 말한다.\n",
    "        - 카테고리를 나타내는 범주형 데이터는 회귀분석등의 머신러닝 알고리즘에서는 바로 사용할 수 없는 경우가 있는데   \n",
    "        이럴때는 숫자 0또는 1로 표현되는 더미변수를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 5. 정규화\n",
    "\n",
    "데이터 프레임 열에 들어있는 숫자 데이터의 상대적 크기 차이 때문에 머신러닝 분석 결과가 달라질 수 있다.\n",
    "\n",
    "* A 변수 : 0 ~ 1000 범위\n",
    "* B 변수 : 0 ~ 1 범위\n",
    "\n",
    "※ 이 경우는 상대적으로 큰 숫자값을 갖는 A 변수의 영향이 더 커진다.\n",
    "\n",
    "둘다 min/max 정규화를 써서 0~1 사이의 범위로 만들어 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 6. 시계열 데이터 생성\n",
    "\n",
    "일정한 시간 간격으로 배치된 데이터들의 수열을 말한다.\n",
    "\n",
    "1. 다른 자료형   -------> 시계열 데이터\n",
    "2. 시계열 데이터 만들기\n",
    "3. 시계열 데이터 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 6.2 가장 많이 나타나는 데이터로 누락 데이터 바꾸기\n",
    "\n",
    "__※ 문법__\n",
    "\n",
    "타이타닉 데이터의 나이 데이터에서 누락 데이터를 뺀 나머지 데이터의 건수중에 가장 건수가 많은 데이터를 most_freq에 담는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 데이터의 나이 데이터에서 누락 데이터를 뺀 나머지 데이터의 건수중에 가장 건수가 많은 데이터를 most_freq에 담는다.\n",
    "most_freq = df['age'].value_counts(dropna=True).idxmax() \n",
    "\n",
    "# 타이타닉 나이 데이터의 누락 데이터를 most_freq로 변경하겠다.\n",
    "df['age'].fillna(most_freq, inplace=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제130. seaborn의 타이타닉 데이터에서 embark_town(승선한 도시명)의 데이터의 행을 가져오는데 825행부터 829행까지 검색하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Southampton\n",
      "1      Cherbourg\n",
      "2    Southampton\n",
      "3    Southampton\n",
      "4    Southampton\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "Name: embark_town, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(df['embark_town'].head(), end= '\\n\\n')\n",
    "\n",
    "# 앞부분 열, 뒷부분 행\n",
    "print(df['embark_town'][825:830], end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제131. embark_town(승선도시)명을 출력하고 승선한 도시명별 건수를 출력하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Southampton    644\n",
      "Cherbourg      168\n",
      "Queenstown      77\n",
      "Name: embark_town, dtype: int64\n",
      "\n",
      "\n",
      "Southampton    644\n",
      "Cherbourg      168\n",
      "Queenstown      77\n",
      "NaN              2\n",
      "Name: embark_town, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(df['embark_town'].value_counts(), end = '\\n\\n\\n')\n",
    "\n",
    "# dropna=False라고 설정하면 누락데이터도 나타나게 해준다.\n",
    "print(df['embark_town'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제132. 위의 결과중에서 가장 건수가 많은 도시명만 출력하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Southampton\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# idxmax() 를 활용하여 가장 건수가 많은 도시명만 출력할 수 있다.\n",
    "most_freq = df['embark_town'].value_counts(dropna=True).idxmax()\n",
    "\n",
    "print(most_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제133. 타이타닉의 승선 도시의 누락 데이터 2건을 가장 빈번하게 나타나는 Southampton으으로 치환하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829    Southampton\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# idxmax() 를 활용하여 가장 건수가 많은 도시명만 출력할 수 있다.\n",
    "most_freq = df['embark_town'].value_counts(dropna=True).idxmax()\n",
    "\n",
    "df['embark_town'].fillna(most_freq, inplace=True)\n",
    "\n",
    "print(df['embark_town'][825:830]) # embark_town이 NaN에서 Southampton으로 바뀌었다는것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  \" 타이타닉 생존자 예측을 위한 머신러닝 모델에 학습데이터를 제공할 때 embark_town의 누락 데이터 처리는?? \"\n",
    "\n",
    "1. 가장 빈번한 값으로 치환 하는게 낳을까?\n",
    "2. 바로 앞행의 값으로 치환 하는게 낳을지?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제134. 이번에는 embark_town의 누락 데이터를 바로 앞행의 값으로 치환시키시오~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829     Queenstown\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# idxmax() 를 활용하여 가장 건수가 많은 도시명만 출력할 수 있다.\n",
    "most_freq = df['embark_town'].value_counts(dropna=True).idxmax()\n",
    "\n",
    "df['embark_town'].fillna(method = 'ffill', inplace=True)\n",
    "\n",
    "print(df['embark_town'][825:830]) # embark_town이 NaN에서 Southampton으로 바뀌었다는것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 6.3 중복 데이터 처리\n",
    "\n",
    "하나의 데이터셋에서 동일한 관측값이 2개 이상 중복되는 경우 중복 데이터를 찾아서 삭제해야한다.   \n",
    "왜냐하면 동일한 대상이 중복으로 존재하는 것이므로 분석결과를 왜곡하기 때문입니다.\n",
    "\n",
    "__문법 :__ df.duplicated() # df 데이터 프레임에 중복된 데이터가 있는지 확인하는 방법."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 예제\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'c1' : ['a','a','b','a','b'], 'c2' : [1,1,1,2,2], 'c3' : [1,1,2,2,2]})\n",
    "\n",
    "print(df, end = '\\n\\n\\n')\n",
    "\n",
    "print(df.duplicated()) # 전에 나온 행들과 비교하여 중복되는 행이면 True로 반환, 처음나온 행이면 False로 반환."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제. 위의 c2 컬럼에만 중복된 데이터가 있는지 확인하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: c2, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 예제\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'c1' : ['a','a','b','a','b'], 'c2' : [1,1,1,2,2], 'c3' : [1,1,2,2,2]})\n",
    "\n",
    "print(df, end = '\\n\\n\\n')\n",
    "\n",
    "print(df['c2'].duplicated()) # 전에 나온 행들과 비교하여 중복되는 행이면 True로 반환, 처음나온 행이면 False로 반환.\n",
    "\n",
    "# duplicated() 는 True or False 로 결과값을 반환함. (중복데이터 확인용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제135. 아래의 데이터 프레임에서 중복된 행을 제거하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n",
      "0    1\n",
      "3    2\n",
      "Name: c2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 예제\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'c1' : ['a','a','b','a','b'], 'c2' : [1,1,1,2,2], 'c3' : [1,1,2,2,2]})\n",
    "\n",
    "df2 = df.drop_duplicates()\n",
    "print(df2, end = '\\n\\n\\n')\n",
    "\n",
    "df3 = df['c2'].drop_duplicates()\n",
    "print(df3)\n",
    "\n",
    "# duplicates() 는 중복된 행을 제거하여 DataFrame을 보여줌. (중복 데이터 제거용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제136. seaborn의 타이타닉 데이터의 중복된 데이터가 있는지 확인하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "886     True\n",
      "887    False\n",
      "888    False\n",
      "889    False\n",
      "890    False\n",
      "Length: 891, dtype: bool\n",
      "\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "\n",
    "print(df.duplicated(), end = '\\n\\n')\n",
    "\n",
    "print(df.duplicated().sum()) # True를 1로 가정하고 다 더한 값을 나타내줌."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생각해야할 문제\n",
    "\n",
    "'문제136'에서 타이타닉 데이터의 중복된 데이터가 107개가 나오는 이유가 무엇인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 6.4 데이터 표준화\n",
    "\n",
    "### 1. 단위 환산\n",
    "\n",
    "실무에서 접하는 데이터셋을 다양한 사람들의 손에 거쳐 만들어진다.  \n",
    "여러 곳에서 수집한 자료들은 단위 선택, 대소문자 구분, 약칭활용등 여러가지 원인에 의해 다양한 형태로 표현된다.  \n",
    "잘 정리된 것으로 보이는 자료를 자세히 들어다보면, 서로 다른 단위가 섞여있거나 같은 대상을 다른 형식으로 표현한 경우가 의외로 많다.\n",
    "\n",
    "__예 :__ 모학생이 모전자에서 모제품의 판매 댓수를 미리 예측하여 생산라인에 다음달에 몇대가 판매가 될거라는것을 통보한다.   \n",
    "전세계의 대리점에서 엑셀 파일을 보내준다. 이번달 몇대 팔았다는 판매 현황 정보이다.  \n",
    "__(데이터 전처리에 대한 개념과 코딩 지식이 중요하다!!!)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model_year  \\\n",
      "0  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "1  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "2  16.0          8         304.0      150.0  3433.0          12.0          70   \n",
      "\n",
      "   origin                name  \n",
      "0       1   buick skylark 320  \n",
      "1       1  plymouth satellite  \n",
      "2       1       amc rebel sst  \n"
     ]
    }
   ],
   "source": [
    "# 예: UCI 머신러닝 데이터셋 중에 자동차 연비 데이터를 불러옵니다.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\auto-mpg.csv\")\n",
    "\n",
    "# 컬럼명 지정하기\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ※설명 \n",
    "mpg열은 mile per gallon의 약자인 컬럼으로 영국과 미국에서는 한국과 달리 갤런당 마일 단위(mile/Gallon)로 연비를 표시합니다.  \n",
    "한국은 리터당 킬로미터(km/L) 단위로 표시한다.  \n",
    "따라서 mpg열을 한국에서 사용하는 리터당 킬로미터 단위로 변환하여야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제137. 1갤런이 3.78541L 1마일이 1.60934km 이다. 그러면 1mpg(mile per gallon)는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42514285110463595\n"
     ]
    }
   ],
   "source": [
    "print(1.60934/3.78541) # 0.425 km/L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제138. UCI 자동차 연비를 가지고있는 df 데이터 프레임에 kpl이라는 변수를 추가해서 한국식 연비 단위로 값이 출력되게하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model_year  \\\n",
      "0  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "1  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "2  16.0          8         304.0      150.0  3433.0          12.0          70   \n",
      "\n",
      "   origin                name       kpl  \n",
      "0       1   buick skylark 320  6.377143  \n",
      "1       1  plymouth satellite  7.652571  \n",
      "2       1       amc rebel sst  6.802286  \n"
     ]
    }
   ],
   "source": [
    "mpg_to_kpl = 1.60934/3.78541\n",
    "df['kpl'] = df['mpg'] * mpg_to_kpl # 'kpl' 이라는 열을 추가하고 값을 정해줌.\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제139. 위의 kpl 컬럼의 데이터를 소수점이후 2자리까지만 허용되겠금 반올림하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model_year  \\\n",
      "0  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "1  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "2  16.0          8         304.0      150.0  3433.0          12.0          70   \n",
      "\n",
      "   origin                name   kpl  \n",
      "0       1   buick skylark 320  6.38  \n",
      "1       1  plymouth satellite  7.65  \n",
      "2       1       amc rebel sst  6.80  \n"
     ]
    }
   ],
   "source": [
    "mpg_to_kpl = 1.60934/3.78541\n",
    "\n",
    "# 'kpl' 이라는 열을 추가하고 값을 정해줌.\n",
    "# round 함수를 이용하자 !!!\n",
    "df['kpl'] = round(df['mpg'] * mpg_to_kpl, 2) \n",
    "\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model_year  \\\n",
      "0  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "1  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "2  16.0          8         304.0      150.0  3433.0          12.0          70   \n",
      "\n",
      "   origin                name   kpl  \n",
      "0       1   buick skylark 320  6.38  \n",
      "1       1  plymouth satellite  7.65  \n",
      "2       1       amc rebel sst  6.80  \n"
     ]
    }
   ],
   "source": [
    "mpg_to_kpl = 1.60934/3.78541\n",
    "\n",
    "# 'kpl' 이라는 열을 추가하고 값을 정해줌.\n",
    "# round 함수를 이용하자 !!!\n",
    "df['kpl'] = df['mpg'] * mpg_to_kpl\n",
    "df['kpl'] = df['kpl'].round(2)\n",
    "\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 표준화의 자료형 변환\n",
    "\n",
    "숫자가 문자열로 저장된 경우에 숫자형(int)으로 변환해야 한다.  \n",
    "숫자 데이터 안에 문자 데이터가 있는지 먼저 검색을 해야한다.  \n",
    "\n",
    "csv 파일을 데이터 프레임으로 변환하는 과정에서 문자중에 '?'가 섞여있어서 분석이 안되는 경우가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18.0  8  307.0  130.0   3504.  12.0  70  1 chevrolet chevelle malibu\n",
      "0    15.0  8  350.0  165.0  3693.0  11.5  70  1         buick skylark 320\n",
      "1    18.0  8  318.0  150.0  3436.0  11.0  70  1        plymouth satellite\n",
      "2    16.0  8  304.0  150.0  3433.0  12.0  70  1             amc rebel sst\n",
      "3    17.0  8  302.0  140.0  3449.0  10.5  70  1               ford torino\n",
      "4    15.0  8  429.0  198.0  4341.0  10.0  70  1          ford galaxie 500\n",
      "..    ... ..    ...    ...     ...   ...  .. ..                       ...\n",
      "392  27.0  4  140.0  86.00  2790.0  15.6  82  1           ford mustang gl\n",
      "393  44.0  4   97.0  52.00  2130.0  24.6  82  2                 vw pickup\n",
      "394  32.0  4  135.0  84.00  2295.0  11.6  82  1             dodge rampage\n",
      "395  28.0  4  120.0  79.00  2625.0  18.6  82  1               ford ranger\n",
      "396  31.0  4  119.0  82.00  2720.0  19.4  82  1                chevy s-10\n",
      "\n",
      "[397 rows x 9 columns] \n",
      "\n",
      "\n",
      "\n",
      "['165.0' '150.0' '140.0' '198.0' '220.0' '215.0' '225.0' '190.0' '170.0'\n",
      " '160.0' '95.00' '97.00' '85.00' '88.00' '46.00' '87.00' '90.00' '113.0'\n",
      " '200.0' '210.0' '193.0' '?' '100.0' '105.0' '175.0' '153.0' '180.0'\n",
      " '110.0' '72.00' '86.00' '70.00' '76.00' '65.00' '69.00' '60.00' '80.00'\n",
      " '54.00' '208.0' '155.0' '130.0' '112.0' '92.00' '145.0' '137.0' '158.0'\n",
      " '167.0' '94.00' '107.0' '230.0' '49.00' '75.00' '91.00' '122.0' '67.00'\n",
      " '83.00' '78.00' '52.00' '61.00' '93.00' '148.0' '129.0' '96.00' '71.00'\n",
      " '98.00' '115.0' '53.00' '81.00' '79.00' '120.0' '152.0' '102.0' '108.0'\n",
      " '68.00' '58.00' '149.0' '89.00' '63.00' '48.00' '66.00' '139.0' '103.0'\n",
      " '125.0' '133.0' '138.0' '135.0' '142.0' '77.00' '62.00' '132.0' '84.00'\n",
      " '64.00' '74.00' '116.0' '82.00'] \n",
      "\n",
      "      mpg  cylinders  displacement horsepower  weight  acceleration  \\\n",
      "0    15.0          8         350.0      165.0  3693.0          11.5   \n",
      "1    18.0          8         318.0      150.0  3436.0          11.0   \n",
      "2    16.0          8         304.0      150.0  3433.0          12.0   \n",
      "3    17.0          8         302.0      140.0  3449.0          10.5   \n",
      "4    15.0          8         429.0      198.0  4341.0          10.0   \n",
      "..    ...        ...           ...        ...     ...           ...   \n",
      "392  27.0          4         140.0      86.00  2790.0          15.6   \n",
      "393  44.0          4          97.0      52.00  2130.0          24.6   \n",
      "394  32.0          4         135.0      84.00  2295.0          11.6   \n",
      "395  28.0          4         120.0      79.00  2625.0          18.6   \n",
      "396  31.0          4         119.0      82.00  2720.0          19.4   \n",
      "\n",
      "     model_year  origin                name  \n",
      "0            70       1   buick skylark 320  \n",
      "1            70       1  plymouth satellite  \n",
      "2            70       1       amc rebel sst  \n",
      "3            70       1         ford torino  \n",
      "4            70       1    ford galaxie 500  \n",
      "..          ...     ...                 ...  \n",
      "392          82       1     ford mustang gl  \n",
      "393          82       2           vw pickup  \n",
      "394          82       1       dodge rampage  \n",
      "395          82       1         ford ranger  \n",
      "396          82       1          chevy s-10  \n",
      "\n",
      "[397 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# 예시\n",
    "# 모듈 불러오기!\n",
    "import pandas as pd\n",
    "\n",
    "# 예: UCI 머신러닝 데이터셋 중에 자동차 연비 데이터를 불러옵니다.\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\auto-mpg.csv\")\n",
    "print(df, '\\n\\n\\n')\n",
    "\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "print(df['horsepower'].unique(), '\\n') # 'horsepower' 컬럼의 값들의 종류를 확인한다.\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제140. horsepower 열의 문자열 '?'를 NaN값으로 변환하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['165.0' '150.0' '140.0' '198.0' '220.0' '215.0' '225.0' '190.0' '170.0'\n",
      " '160.0' '95.00' '97.00' '85.00' '88.00' '46.00' '87.00' '90.00' '113.0'\n",
      " '200.0' '210.0' '193.0' nan '100.0' '105.0' '175.0' '153.0' '180.0'\n",
      " '110.0' '72.00' '86.00' '70.00' '76.00' '65.00' '69.00' '60.00' '80.00'\n",
      " '54.00' '208.0' '155.0' '130.0' '112.0' '92.00' '145.0' '137.0' '158.0'\n",
      " '167.0' '94.00' '107.0' '230.0' '49.00' '75.00' '91.00' '122.0' '67.00'\n",
      " '83.00' '78.00' '52.00' '61.00' '93.00' '148.0' '129.0' '96.00' '71.00'\n",
      " '98.00' '115.0' '53.00' '81.00' '79.00' '120.0' '152.0' '102.0' '108.0'\n",
      " '68.00' '58.00' '149.0' '89.00' '63.00' '48.00' '66.00' '139.0' '103.0'\n",
      " '125.0' '133.0' '138.0' '135.0' '142.0' '77.00' '62.00' '132.0' '84.00'\n",
      " '64.00' '74.00' '116.0' '82.00']\n"
     ]
    }
   ],
   "source": [
    "# 예시\n",
    "# 모듈 불러오기!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 예: UCI 머신러닝 데이터셋 중에 자동차 연비 데이터를 불러옵니다.\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\auto-mpg.csv\")\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace = True) # np.nan으로 바꿔줌 // inplace = True (변경을 적용하겠다.)\n",
    "\n",
    "print(df['horsepower'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제141. dropna(axis = 0) 메소드로 NaN값이 들어있는 모든행을 삭제하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 예시\n",
    "# 모듈 불러오기!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 예: UCI 머신러닝 데이터셋 중에 자동차 연비 데이터를 불러옵니다.\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\auto-mpg.csv\")\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace = True) # np.nan으로 바꿔줌 // inplace = True (변경을 적용하겠다.)\n",
    "\n",
    "df.dropna(subset = ['horsepower'], axis = 0, inplace = True) # NaN =누락데이터를 제거함.\n",
    "\n",
    "print(df['horsepower'].dtypes)\n",
    "\n",
    "print(df['horsepower'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제142. 위의 horsepower의 데이터 유형을 실수형인 float으로 변환하시오! (점심시간문제)\n",
    "\n",
    "\n",
    "df['열이름'].astype('데이터 유형타입')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165. 150. 140. 198. 220. 215. 225. 190. 170. 160.  95.  97.  85.  88.\n",
      "  46.  87.  90. 113. 200. 210. 193. 100. 105. 175. 153. 180. 110.  72.\n",
      "  86.  70.  76.  65.  69.  60.  80.  54. 208. 155. 130. 112.  92. 145.\n",
      " 137. 158. 167.  94. 107. 230.  49.  75.  91. 122.  67.  83.  78.  52.\n",
      "  61.  93. 148. 129.  96.  71.  98. 115.  53.  81.  79. 120. 152. 102.\n",
      " 108.  68.  58. 149.  89.  63.  48.  66. 139. 103. 125. 133. 138. 135.\n",
      " 142.  77.  62. 132.  84.  64.  74. 116.  82.]\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# 예시\n",
    "# 모듈 불러오기!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 예: UCI 머신러닝 데이터셋 중에 자동차 연비 데이터를 불러옵니다.\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\auto-mpg.csv\")\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace = True) # np.nan으로 바꿔줌 // inplace = True (변경을 적용하겠다.)\n",
    "\n",
    "df.dropna(subset = ['horsepower'], axis = 0, inplace = True)\n",
    "\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "print(df['horsepower'].unique())\n",
    "\n",
    "print(df['horsepower'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 6.5 범주형 데이터 처리\n",
    "\n",
    "   __1. 구간 분할 :__ 연속형 데이터 ---> 일정한 구간으로 나눔  \n",
    "       예) 사원 테이블의 월급의 경우 고소득자, 중간소득자, 저소득자로 나눈다.\n",
    "       \n",
    "       \n",
    "   __2. 더미 변수 :__ 숫자 0또는 1로 표현하는 것  \n",
    "       예) UCI 연비 데이터의 MPG를 고출력, 저출력으로 변경했다면, 고출력을 1로 저출력을 0으로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 구간 분할 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257 102  32]\n",
      "[ 46.         107.33333333 168.66666667 230.        ]\n",
      "    horsepower hp_bin\n",
      "0        165.0   보통출력\n",
      "1        150.0   보통출력\n",
      "2        150.0   보통출력\n",
      "3        140.0   보통출력\n",
      "4        198.0    고출력\n",
      "5        220.0    고출력\n",
      "6        215.0    고출력\n",
      "7        225.0    고출력\n",
      "8        190.0    고출력\n",
      "9        170.0    고출력\n",
      "10       160.0   보통출력\n",
      "11       150.0   보통출력\n",
      "12       225.0    고출력\n",
      "13        95.0    저출력\n",
      "14        95.0    저출력\n"
     ]
    }
   ],
   "source": [
    "# 예시\n",
    "# 모듈 불러오기!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 예: UCI 머신러닝 데이터셋 중에 자동차 연비 데이터를 불러옵니다.\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\auto-mpg.csv\")\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace = True) # np.nan으로 바꿔줌 // inplace = True (변경을 적용하겠다.)\n",
    "df.dropna(subset = ['horsepower'], axis = 0, inplace = True) # 누락 데이터를 제거 \n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "print(count) # 각 구간에 속하는 값의 갯수 [257 102  32] \n",
    "print(bin_dividers) # 경계값 리스트 [ 46.         107.33333333 168.66666667 230.  ]\n",
    "\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "df['hp_bin'] = pd.cut(x = df['horsepower'], bins = bin_dividers, labels = bin_names, include_lowest = True) # 첫 경계값 포함\n",
    "\n",
    "# 데이터 배열: x = df['horsepower']\n",
    "# 경계값 리스트: bins = bin_dividers\n",
    "# bin 이름: labels = bin_names\n",
    "# 첫 경계값 포함 유무: include_lowest = True\n",
    "\n",
    "print(df[['horsepower', 'hp_bin']].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "\n",
    "이처럼 연속 변수를 일정한 구간으로 나누고, 각 구간을 범주형 이산변수로 변환하는 과정을 __구간분할(binning)__이라고 합니다.  \n",
    "판다스 cut() __함수(pd.cut)__를 이용하면 연속 데이터를 여러구간으로 나누고 범주형 데이터로 변환 할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제143. emp.csv를 판다스로 불러와서 이름, 월급, 월급을 구간 분할한 결과를 출력하시오!\n",
    "## (고소득, 중간소득, 저소득)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['empno', 'ename', 'job', 'mgr', 'hiredate', 'sal', 'comm', 'deptno'], dtype='object')\n",
      "\n",
      "     ename     sal sal_bin\n",
      "0     KING  5000.0     고소득\n",
      "1    BLAKE  2850.0    중간소득\n",
      "2    CLARK  2450.0    중간소득\n",
      "3    JONES  2975.0    중간소득\n",
      "4   MARTIN  1250.0     저소득\n",
      "5    ALLEN  1600.0     저소득\n",
      "6   TURNER  1500.0     저소득\n",
      "7    JAMES   950.0     저소득\n",
      "8     WARD  1250.0     저소득\n",
      "9     FORD  3000.0    중간소득\n",
      "10   SMITH   800.0     저소득\n",
      "11   SCOTT  3000.0    중간소득\n",
      "12   ADAMS  1100.0     저소득\n",
      "13  MILLER  1300.0     저소득\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "emp = pd.read_csv(\"d:\\\\data\\\\emp.csv\", header = 0)\n",
    "print(emp.columns, end = '\\n\\n')\n",
    "\n",
    "emp['sal'] = emp['sal'].astype(\"float\")\n",
    "count, bin_dividers = np.histogram(emp['sal'], bins=3)\n",
    "\n",
    "bin_names = ['저소득', ' 중간소득', '고소득']\n",
    "\n",
    "emp['sal_bin'] = pd.cut(x = emp['sal'], bins = bin_dividers, labels = bin_names, include_lowest = True)\n",
    "\n",
    "print(emp[['ename', 'sal', 'sal_bin']].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 더미 변수 \n",
    "\n",
    "머신러닝 알고리즘에 따라 범주형 데이터를 바로 사용할 수 없는 알고리즘이 있는데 이럴때는 컴퓨터가 인식 가능한 입력값으로 변환을 해주어야 \n",
    "한다.  \n",
    "이럴때 __숫자 0 또는 1로 표현__되는 __더미변수(dummy variable)__를 사용합니다.  \n",
    "__여기서 0과 1은__ 수의 크고 작음을 나타내지는 않고, __어떤 특성이 있는지 없는지 여부만 표시한다,__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower_dumies = pd.get_dummies(df['hp_bin']) # 더미 특성 추가하는 코드\n",
    "print(horsepower_dummies.head(15)) # 더미 특성 추가되었는지 확인!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257 102  32]\n",
      "[ 46.         107.33333333 168.66666667 230.        ]\n",
      "    horsepower hp_bin\n",
      "0        165.0   보통출력\n",
      "1        150.0   보통출력\n",
      "2        150.0   보통출력\n",
      "3        140.0   보통출력\n",
      "4        198.0    고출력\n",
      "5        220.0    고출력\n",
      "6        215.0    고출력\n",
      "7        225.0    고출력\n",
      "8        190.0    고출력\n",
      "9        170.0    고출력\n",
      "10       160.0   보통출력\n",
      "11       150.0   보통출력\n",
      "12       225.0    고출력\n",
      "13        95.0    저출력\n",
      "14        95.0    저출력 \n",
      "\n",
      "\n",
      "\n",
      "hp_bin  저출력  보통출력  고출력\n",
      "0         0     1    0\n",
      "1         0     1    0\n",
      "2         0     1    0\n",
      "3         0     1    0\n",
      "4         0     0    1\n",
      "5         0     0    1\n",
      "6         0     0    1\n",
      "7         0     0    1\n",
      "8         0     0    1\n",
      "9         0     0    1\n",
      "10        0     1    0\n",
      "11        0     1    0\n",
      "12        0     0    1\n",
      "13        1     0    0\n",
      "14        1     0    0\n"
     ]
    }
   ],
   "source": [
    "# 예시\n",
    "# 모듈 불러오기!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 예: UCI 머신러닝 데이터셋 중에 자동차 연비 데이터를 불러옵니다.\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\auto-mpg.csv\")\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace = True) # np.nan으로 바꿔줌 // inplace = True (변경을 적용하겠다.)\n",
    "df.dropna(subset = ['horsepower'], axis = 0, inplace = True) # 누락 데이터를 제거 \n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "print(count) # 각 구간에 속하는 값의 갯수 [257 102  32] \n",
    "print(bin_dividers) # 경계값 리스트 [ 46.         107.33333333 168.66666667 230.  ]\n",
    "\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "df['hp_bin'] = pd.cut(x = df['horsepower'], bins = bin_dividers, labels = bin_names, include_lowest = True) # 첫 경계값 포함유무\n",
    "# 데이터 배열: x = df['horsepower']\n",
    "# 경계값 리스트: bins = bin_dividers\n",
    "# bin 이름: labels = bin_names\n",
    "# 첫 경계값 포함 유무: include_lowest = True\n",
    "\n",
    "print(df[['horsepower', 'hp_bin']].head(15), '\\n\\n\\n')\n",
    "\n",
    "horsepower_dumies = pd.get_dummies( df['hp_bin'] )\n",
    "\n",
    "print ( horsepower_dumies.head(15)  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제144. 사원 테이블의 월급을 더미변수로 생성하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['empno', 'ename', 'job', 'mgr', 'hiredate', 'sal', 'comm', 'deptno'], dtype='object')\n",
      "sal_bin  저소득   중간소득  고소득\n",
      "0          0      0    1\n",
      "1          0      1    0\n",
      "2          0      1    0\n",
      "3          0      1    0\n",
      "4          1      0    0\n",
      "5          1      0    0\n",
      "6          1      0    0\n",
      "7          1      0    0\n",
      "8          1      0    0\n",
      "9          0      1    0\n",
      "10         1      0    0\n",
      "11         0      1    0\n",
      "12         1      0    0\n",
      "13         1      0    0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "emp = pd.read_csv(\"d:\\\\data\\\\emp.csv\", header = 0)\n",
    "print(emp.columns)\n",
    "\n",
    "emp['sal'] = emp['sal'].astype(\"float\")\n",
    "count, bin_dividers = np.histogram(emp['sal'], bins=3)\n",
    "\n",
    "bin_names = ['저소득', ' 중간소득', '고소득']\n",
    "\n",
    "emp['sal_bin'] = pd.cut(x = emp['sal'], bins = bin_dividers, labels = bin_names, include_lowest = True) \n",
    "# 데이터 배열: x = emp['sal']\n",
    "# 경계값 리스트: bins = bin_dividers\n",
    "# bin 이름: labels = bin_names\n",
    "# 첫 경계값 포함 유무: include_lowest = True\n",
    "\n",
    "sal_dumies = pd.get_dummies( emp['sal_bin'] )\n",
    "\n",
    "print(sal_dumies.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제145. 위의 결과에 맨 앞에 이름을 출력하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ename  저소득   중간소득  고소득\n",
      "0     KING  0.0    0.0  1.0\n",
      "1    BLAKE  0.0    1.0  0.0\n",
      "2    CLARK  0.0    1.0  0.0\n",
      "3    JONES  0.0    1.0  0.0\n",
      "4   MARTIN  1.0    0.0  0.0\n",
      "5    ALLEN  1.0    0.0  0.0\n",
      "6   TURNER  1.0    0.0  0.0\n",
      "7    JAMES  1.0    0.0  0.0\n",
      "8     WARD  1.0    0.0  0.0\n",
      "9     FORD  0.0    1.0  0.0\n",
      "10   SMITH  NaN    NaN  NaN\n",
      "11   SCOTT  NaN    NaN  NaN\n",
      "12   ADAMS  NaN    NaN  NaN\n",
      "13  MILLER  NaN    NaN  NaN\n",
      "\n",
      "\n",
      "     ename  저소득   중간소득  고소득\n",
      "0     KING    0      0    1\n",
      "1    BLAKE    0      1    0\n",
      "2    CLARK    0      1    0\n",
      "3    JONES    0      1    0\n",
      "4   MARTIN    1      0    0\n",
      "5    ALLEN    1      0    0\n",
      "6   TURNER    1      0    0\n",
      "7    JAMES    1      0    0\n",
      "8     WARD    1      0    0\n",
      "9     FORD    0      1    0\n",
      "10   SMITH    1      0    0\n",
      "11   SCOTT    0      1    0\n",
      "12   ADAMS    1      0    0\n",
      "13  MILLER    1      0    0\n",
      "\n",
      "\n",
      "    empno   ename        job     mgr    hiredate     sal    comm  deptno  \\\n",
      "0    7839    KING  PRESIDENT     NaN  1981-11-17  5000.0     NaN      10   \n",
      "1    7698   BLAKE    MANAGER  7839.0  1981-05-01  2850.0     NaN      30   \n",
      "2    7782   CLARK    MANAGER  7839.0  1981-05-09  2450.0     NaN      10   \n",
      "3    7566   JONES    MANAGER  7839.0  1981-04-01  2975.0     NaN      20   \n",
      "4    7654  MARTIN   SALESMAN  7698.0  1981-09-10  1250.0  1400.0      30   \n",
      "5    7499   ALLEN   SALESMAN  7698.0  1981-02-11  1600.0   300.0      30   \n",
      "6    7844  TURNER   SALESMAN  7698.0  1981-08-21  1500.0     0.0      30   \n",
      "7    7900   JAMES      CLERK  7698.0  1981-12-11   950.0     NaN      30   \n",
      "8    7521    WARD   SALESMAN  7698.0  1981-02-23  1250.0   500.0      30   \n",
      "9    7902    FORD    ANALYST  7566.0  1981-12-11  3000.0     NaN      20   \n",
      "10   7369   SMITH      CLERK  7902.0  1980-12-09   800.0     NaN      20   \n",
      "11   7788   SCOTT    ANALYST  7566.0  1982-12-22  3000.0     NaN      20   \n",
      "12   7876   ADAMS      CLERK  7788.0  1983-01-15  1100.0     NaN      20   \n",
      "13   7934  MILLER      CLERK  7782.0  1982-01-11  1300.0     NaN      10   \n",
      "\n",
      "   sal_bin  \n",
      "0      고소득  \n",
      "1     중간소득  \n",
      "2     중간소득  \n",
      "3     중간소득  \n",
      "4      저소득  \n",
      "5      저소득  \n",
      "6      저소득  \n",
      "7      저소득  \n",
      "8      저소득  \n",
      "9     중간소득  \n",
      "10     저소득  \n",
      "11    중간소득  \n",
      "12     저소득  \n",
      "13     저소득  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "emp = pd.read_csv(\"d:\\\\data\\\\emp.csv\", header = 0)\n",
    "\n",
    "emp['sal'] = emp['sal'].astype(\"float\")\n",
    "count, bin_dividers = np.histogram(emp['sal'], bins=3)\n",
    "\n",
    "bin_names = ['저소득', ' 중간소득', '고소득']\n",
    "\n",
    "emp['sal_bin'] = pd.cut(x = emp['sal'], bins = bin_dividers, labels = bin_names, include_lowest = True) \n",
    "# 데이터 배열: x = emp['sal']\n",
    "# 경계값 리스트: bins = bin_dividers\n",
    "# bin 이름: labels = bin_names\n",
    "# 첫 경계값 포함 유무: include_lowest = True\n",
    "\n",
    "sal_dumies = pd.get_dummies( emp['sal_bin'] ) # 더미 변수 만들기 코드\n",
    "\n",
    "print(emp[['ename']].join(sal_dumies.head(10)), end = '\\n\\n\\n')\n",
    "print(emp[['ename']].join(sal_dumies)) \n",
    "print('\\n')\n",
    "\n",
    "print(emp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 더미변수를 생성하는 다른 방법\n",
    "\n",
    "sklearn 라이브러리를 이용해서 __원핫인코딩__을 편하게 처리할 수 있다.  \n",
    "데이터 프레임 df의 'hp_bin'열에 들어있는 범주형 데이터를 0과 1로 __원핫인코딩__ 해서 벡터로 반환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 0 0 0 0 1 1 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "onehot_encoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "onehot_labeled = label_encoder.fit_transform(df['hp_bin'].head(15))\n",
    "print(onehot_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257 102  32]\n",
      "[ 46.         107.33333333 168.66666667 230.        ]\n",
      "\n",
      "\n",
      "[1 1 1 1 0 0 0 0 0 0 1 1 0 2 2]\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]]\n",
      "  (0, 1)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (4, 0)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (10, 1)\t1.0\n",
      "  (11, 1)\t1.0\n",
      "  (12, 0)\t1.0\n",
      "  (13, 2)\t1.0\n",
      "  (14, 2)\t1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wdp\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 예: UCI 머신러닝 데이터셋 중에 자동차 연비 데이터를 불러옵니다.\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\auto-mpg.csv\")\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace = True) # np.nan으로 바꿔줌 // inplace = True (변경을 적용하겠다.)\n",
    "df.dropna(subset = ['horsepower'], axis = 0, inplace = True) # 누락 데이터를 제거 \n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "print(count) # 각 구간에 속하는 값의 갯수 [257 102  32] \n",
    "print(bin_dividers, end = '\\n\\n\\n') # 경계값 리스트 [ 46.         107.33333333 168.66666667 230.  ]\n",
    "\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "df['hp_bin'] = pd.cut(x = df['horsepower'], bins = bin_dividers, labels = bin_names, include_lowest = True) # 첫 경계값 포함유무\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "onehot_encoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "onehot_labeled = label_encoder.fit_transform(df['hp_bin'].head(15))\n",
    "# 1차원 벡터를 2차원 행렬로 변환한다.\n",
    "onehot_reshaped = onehot_labeled.reshape(len(onehot_labeled), 1)\n",
    "\n",
    "# 2차원 행렬을 희소행렬로 변환한다. 희소행렬은 '(행,열) 좌표'와 '값'의 형태로 정리된다.\n",
    "onehot_encode = onehot_encoder.fit_transform(onehot_reshaped)\n",
    "\n",
    "print(onehot_labeled)\n",
    "print(onehot_reshaped)\n",
    "print(onehot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ※코딩 결과값 설명\n",
    "(0,1)은 0행의 1열의 위치를 말하고 데이터 값은 숫자 1.0이 입력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 정규화\n",
    "\n",
    "각 변수(데이터프레임의 열)에 들어있는 숫자 데이터의 상대적 크기 차이 때문에 머신러닝 분석 결과가 달라질 수 있다.  \n",
    "따라서 숫자 데이터의 상대적인 크기 차이를 제거할 필요가 있다.  \n",
    "각 열(변수)에 속하는 데이터 값을 동일한 크기 기준으로 나눈 비율로 나타내는 것을 __정규화(normalization)__라고 합니다.  \n",
    "정규화 과정을 거친 데이터의 범위는 0~1 또는 -1 ~ 1 이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제146. UCI 연비 데이터 프레임의 horsepower 데이터에서 '?'를 결측치로 대체하고 결측치를 제거하여 float로 변환한 데이터를 출력하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165. 150. 140. 198. 220. 215. 225. 190. 170. 160.  95.  97.  85.  88.\n",
      "  46.  87.  90. 113. 200. 210. 193. 100. 105. 175. 153. 180. 110.  72.\n",
      "  86.  70.  76.  65.  69.  60.  80.  54. 208. 155. 130. 112.  92. 145.\n",
      " 137. 158. 167.  94. 107. 230.  49.  75.  91. 122.  67.  83.  78.  52.\n",
      "  61.  93. 148. 129.  96.  71.  98. 115.  53.  81.  79. 120. 152. 102.\n",
      " 108.  68.  58. 149.  89.  63.  48.  66. 139. 103. 125. 133. 138. 135.\n",
      " 142.  77.  62. 132.  84.  64.  74. 116.  82.]\n"
     ]
    }
   ],
   "source": [
    "# 예시\n",
    "# 모듈 불러오기!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 예: UCI 머신러닝 데이터셋 중에 자동차 연비 데이터를 불러옵니다.\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\auto-mpg.csv\")\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace = True) # np.nan으로 바꿔줌 // inplace = True (변경을 적용하겠다.)\n",
    "df.dropna(subset = ['horsepower'], axis = 0, inplace = True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "print(df['horsepower'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제147. 위의 horsepower 데이터의 통계요약을 확인하시오!( describe()를 사용하시오 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    391.000000\n",
      "mean     104.404092\n",
      "std       38.518732\n",
      "min       46.000000\n",
      "25%       75.000000\n",
      "50%       93.000000\n",
      "75%      125.000000\n",
      "max      230.000000\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "count    391.000000\n",
      "mean     104.404092\n",
      "std       38.518732\n",
      "min       46.000000\n",
      "25%       75.000000\n",
      "50%       93.000000\n",
      "75%      125.000000\n",
      "max      230.000000\n",
      "Name: horsepower, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 예시\n",
    "# 모듈 불러오기!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 예: UCI 머신러닝 데이터셋 중에 자동차 연비 데이터를 불러옵니다.\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\auto-mpg.csv\")\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace = True) # np.nan으로 바꿔줌 // inplace = True (변경을 적용하겠다.)\n",
    "df.dropna(subset = ['horsepower'], axis = 0, inplace = True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "print(df['horsepower'].describe(), end= '\\n\\n')\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제148. 위의 horsepower 데이터를 0~1 사이의 데이터로 정규화하시오!\n",
    "## (각 값들의 가장 큰값으로 나누면 됩니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.717391\n",
      "1    0.652174\n",
      "2    0.652174\n",
      "3    0.608696\n",
      "4    0.860870\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "count    391.000000\n",
      "mean       0.453931\n",
      "std        0.167473\n",
      "min        0.200000\n",
      "25%        0.326087\n",
      "50%        0.404348\n",
      "75%        0.543478\n",
      "max        1.000000\n",
      "Name: horsepower, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 예시\n",
    "# 모듈 불러오기!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 예: UCI 머신러닝 데이터셋 중에 자동차 연비 데이터를 불러옵니다.\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\auto-mpg.csv\")\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace = True) # np.nan으로 바꿔줌 // inplace = True (변경을 적용하겠다.)\n",
    "df.dropna(subset = ['horsepower'], axis = 0, inplace = True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "df['horsepower'] = df['horsepower'] / abs(df['horsepower'].max())\n",
    "\n",
    "print(df['horsepower'].head(), end = '\\n\\n')\n",
    "print(df['horsepower'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제149.  각 열(변수)의 데이터 중에서 최대값(max)와 최소값(min)을 뺀 값으로 나누는 방법을 사용하시오. 각 열 데이터에서 해당 열의 최소값을 뺀 값을 분자로 하고, 해당 열의 최대값과 최소값의 차를 분모로 하는 수를 계산하면 가장 큰 값은 역시 1이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.646739\n",
      "1    0.565217\n",
      "2    0.565217\n",
      "3    0.510870\n",
      "4    0.826087\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "count    391.000000\n",
      "mean       0.317414\n",
      "std        0.209341\n",
      "min        0.000000\n",
      "25%        0.157609\n",
      "50%        0.255435\n",
      "75%        0.429348\n",
      "max        1.000000\n",
      "Name: horsepower, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 두번째 정규화 방법\n",
    "# 모듈 불러오기!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 예: UCI 머신러닝 데이터셋 중에 자동차 연비 데이터를 불러옵니다.\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\auto-mpg.csv\")\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace = True) # np.nan으로 바꿔줌 // inplace = True (변경을 적용하겠다.)\n",
    "df.dropna(subset = ['horsepower'], axis = 0, inplace = True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "min_x = df.horsepower - df.horsepower.min() \n",
    "min_max = df.horsepower.max() - df.horsepower.min() # df['horsepower'].max() - df['horsepower'].min()\n",
    "df.horsepower = min_x / min_max\n",
    "\n",
    "print(df.horsepower.head(), end = '\\n\\n')\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 6.7 판다스로 시계열 데이터 생성하기\n",
    "\n",
    "### 일정한 시간 간격으로 배치된 데이터들의 수열을 말한다.\n",
    "\n",
    "__다른자료형 ---------------------->  시계열 데이터로 변환__\n",
    "\n",
    "주식, 환율등의 금융 데이터를 다루기 위해 개발된 판다스는 시계열(time series) 데이터를 다루는 여러가지 유용한 기능을 제공한다.    \n",
    "특히, 시계열 데이터를 데이터프레임의 행 인덱스로 사용하면 시간으로 기록된 데이터를 분석하는것이 매우 편리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 문자열을 to_datetime() 함수를 이용하여 timestamp로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume\n",
      "0  2018-07-02  10100  10850  10900  10000  137977\n",
      "1  2018-06-29  10700  10550  10900   9990  170253\n",
      "2  2018-06-28  10400  10900  10950  10150  155769\n",
      "3  2018-06-27  10900  10800  11050  10500  133548\n",
      "4  2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      "Date      20 non-null object\n",
      "Close     20 non-null int64\n",
      "Start     20 non-null int64\n",
      "High      20 non-null int64\n",
      "Low       20 non-null int64\n",
      "Volume    20 non-null int64\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 1.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\stock-data.csv\")\n",
    "print(df.head(), end = '\\n\\n')\n",
    "print(df.info()) # Date 컬럼의 자료형이 무엇이지 알수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ info() 메소드로 Date 열의 자료형을 확인해보니 문자열(object)임을 알 수 있다.  \n",
    "### 판다스의 to_datetime 함수를 써서 Timestamp 객체로 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Close  Start   High    Low  Volume   new_Date\n",
      "0   2018-07-02  10100  10850  10900  10000  137977 2018-07-02\n",
      "1   2018-06-29  10700  10550  10900   9990  170253 2018-06-29\n",
      "2   2018-06-28  10400  10900  10950  10150  155769 2018-06-28\n",
      "3   2018-06-27  10900  10800  11050  10500  133548 2018-06-27\n",
      "4   2018-06-26  10800  10900  11000  10700   63039 2018-06-26\n",
      "5   2018-06-25  11150  11400  11450  11000   55519 2018-06-25\n",
      "6   2018-06-22  11300  11250  11450  10750  134805 2018-06-22\n",
      "7   2018-06-21  11200  11350  11750  11200  133002 2018-06-21\n",
      "8   2018-06-20  11550  11200  11600  10900  308596 2018-06-20\n",
      "9   2018-06-19  11300  11850  11950  11300  180656 2018-06-19\n",
      "10  2018-06-18  12000  13400  13400  12000  309787 2018-06-18\n",
      "11  2018-06-15  13400  13600  13600  12900  201376 2018-06-15\n",
      "12  2018-06-14  13450  13200  13700  13150  347451 2018-06-14\n",
      "13  2018-06-12  13200  12200  13300  12050  558148 2018-06-12\n",
      "14  2018-06-11  11950  12000  12250  11950   62293 2018-06-11\n",
      "15  2018-06-08  11950  11950  12200  11800   59258 2018-06-08\n",
      "16  2018-06-07  11950  12200  12300  11900   49088 2018-06-07\n",
      "17  2018-06-05  12150  11800  12250  11800   42485 2018-06-05\n",
      "18  2018-06-04  11900  11900  12200  11700   25171 2018-06-04\n",
      "19  2018-06-01  11900  11800  12100  11750   32062 2018-06-01\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 7 columns):\n",
      "Date        20 non-null object\n",
      "Close       20 non-null int64\n",
      "Start       20 non-null int64\n",
      "High        20 non-null int64\n",
      "Low         20 non-null int64\n",
      "Volume      20 non-null int64\n",
      "new_Date    20 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(5), object(1)\n",
      "memory usage: 1.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\stock-data.csv\")\n",
    "\n",
    "df['new_Date'] = pd.to_datetime(df['Date']) # 새로운 컬럼을 추가\n",
    "print(df, end = '\\n\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__※설명 :__ 위와 같이 datetime으로 변경이 되면 시간 순서에 맞춰 데이터를 검색하기가 편리해진다. 시계열 컬럼을 로우 인덱스로 지정하면  \n",
    "시간 순서에 맞춰 인덱싱 또는 슬라이싱 하기가 편해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제150. 지금 추가한 new_Date 컬럼을 행 인덱스로 지정하고 기존의 Date 컬럼을 삭제하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close  Start   High    Low  Volume\n",
      "new_Date                                      \n",
      "2018-07-02  10100  10850  10900  10000  137977\n",
      "2018-06-29  10700  10550  10900   9990  170253\n",
      "2018-06-28  10400  10900  10950  10150  155769\n",
      "2018-06-27  10900  10800  11050  10500  133548\n",
      "2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20 entries, 2018-07-02 to 2018-06-01\n",
      "Data columns (total 5 columns):\n",
      "Close     20 non-null int64\n",
      "Start     20 non-null int64\n",
      "High      20 non-null int64\n",
      "Low       20 non-null int64\n",
      "Volume    20 non-null int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 960.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\stock-data.csv\")\n",
    "\n",
    "df['new_Date'] = pd.to_datetime(df['Date']) # 새로운 컬럼을 추가\n",
    "df.set_index('new_Date', inplace = True)\n",
    "df.drop('Date', axis = 1, inplace = True) # axis = 1 (열)\n",
    "\n",
    "print(df.head(), end = '\\n\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제151. 위의 new_Date 시계열 데이터를 이용하여 새로운 파생변수 3가지를 생성하시오! ( Year, Month, Day)\n",
    "### Year 변수에는 2018과 같이 년도만 담고\n",
    "### Month 변수에는 7,8 처럼 월 데이터만 담으시오!\n",
    "### Day 변수에는 29,28 처럼 일 데이터만 담으시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date  Year  Month  Day\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018      7    2\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018      6   29\n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018      6   28\n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018      6   27\n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018      6   26\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\stock-data.csv\")\n",
    "\n",
    "df['new_Date'] = pd.to_datetime(df['Date']) # 새로운 컬럼을 추가\n",
    "\n",
    "df['Year'] = df['new_Date'].dt.year\n",
    "df['Month'] = df['new_Date'].dt.month\n",
    "df['Day'] = df['new_Date'].dt.day\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 7장. 판다스 데이터 프레임의 응용\n",
    "\n",
    "   - 7.1 개별 원소에 함수 매핑\n",
    "       - 시리즈 원소에 함수 매핑( 문법 : 시리즈 객체.apply('매핑함수'))\n",
    "       - 데이터 프레임 원소에 함수 매핑( 문법 : 데이터프레임객체.applymap('매핑함수'))\n",
    "       \n",
    "       \n",
    "   - 7.2 시리즈 객체에 함수 매핑 (axis 부분 잘 주시해서 외워두기)\n",
    "       - 데이터 프레임의 각 열에 함수 매핑( 문법 : 데이터프레임객체.apply('매핑함수', axis = 0))\n",
    "       - 데이터 프레임의 각 행에 함수 매핑( 문법 : 데이터프레임객체.apply('매핑함수', axis = 1))\n",
    "       - 데이터 프레임 객체의 함수 매핑( 문법: 데이터프레임객체.pipe('매핑함수')\n",
    "       \n",
    "       \n",
    "   - 7.3 열의 재구성\n",
    "       - 열순서 변경( 문법 : 데이터프레임 객체([재구성할 열이름 리스트])\n",
    "       - 열분리 : 하나의 열이 여러가지 정보를 담고 있을 때 각 정보를 서로 분리해서 사용하는 경우가 많다.\n",
    "       \n",
    "       \n",
    "   - 7.4 필터링 : 시리즈 또는 데이터 프레임의 데이터 중에서 특정 조건에 만족하는 원소만 따로 추출하는 개념\n",
    "       - 불린 인덱싱\n",
    "       - isin 메소드\n",
    "       \n",
    "       \n",
    "   - 7.5 데이터 프레임 합치기 : 데이터가 여러 군데 나누어져 있을때 하나로 합치거나 데이터를 연결해야하는 경우가 있다.\n",
    "       - 데이터 프레임 연결 ( 문법 : pandas.concat(데이터프레임리스트) )\n",
    "       - 데이터 프레임 병합 ( 문법 : pandas.merge(emp,dept, how = 'inner') \n",
    "       - 데이터 프레임 결합 ( 문법 : DataFrame1.join(DataFrame2, how = 'left')\n",
    "       \n",
    "       \n",
    "   - 7.6 그룹연산\n",
    "       - 그룹객체 만들기 : 1개의 열을 기준으로 그룹화 ( 문법 : DataFrame객체.groupby('기준이되는 열')\n",
    "       - 여러열을 기준으로 그룹화 ( 문법 : DataFrame객체.groupby('기준이되는 열의 리스트')\n",
    "       - 그룹 연산 메소드( 문법 : DataFrame.max() or .min() or .sum() or .count() or .std() or .var() or .describe() or .info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".min()  \n",
    ".sum()  \n",
    ".count()  \n",
    ".std()  \n",
    ".var()  \n",
    ".describe()  \n",
    ".info()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 시리즈 원소에 함수 매핑\n",
    "\n",
    "__문법 :__ Series객체.apply('매핑함수')\n",
    "\n",
    "시리즈 객체에 apply() 메소드를 적용하면 인자로 전달하는 매핑함수에 시리즈의 모든 원소를 하나씩 입력하고 함수의 리턴값을 돌려받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      32.0\n",
      "1      48.0\n",
      "2      36.0\n",
      "3      45.0\n",
      "4      45.0\n",
      "       ... \n",
      "886    37.0\n",
      "887    29.0\n",
      "888     NaN\n",
      "889    36.0\n",
      "890    42.0\n",
      "Name: age, Length: 891, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def add_10(n): # 10을 더하는 함수\n",
    "    return n+10\n",
    "\n",
    "import seaborn as sns\n",
    "titanic = sns.load_dataset('titanic')\n",
    "sr1 = titanic['age'].apply(add_10)\n",
    "print(sr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제152. 타이타닉 데이터의 age2라는 파생변수를 생성하는데 기존 나이의 10살을 추가한 파생변수를 생성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
      "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
      "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
      "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
      "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
      "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
      "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
      "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
      "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
      "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
      "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
      "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  age2  \n",
      "0      man        True  NaN  Southampton    no  False  32.0  \n",
      "1    woman       False    C    Cherbourg   yes  False  48.0  \n",
      "2    woman       False  NaN  Southampton   yes   True  36.0  \n",
      "3    woman       False    C  Southampton   yes  False  45.0  \n",
      "4      man        True  NaN  Southampton    no   True  45.0  \n",
      "..     ...         ...  ...          ...   ...    ...   ...  \n",
      "886    man        True  NaN  Southampton    no   True  37.0  \n",
      "887  woman       False    B  Southampton   yes   True  29.0  \n",
      "888  woman       False  NaN  Southampton    no  False   NaN  \n",
      "889    man        True    C    Cherbourg   yes   True  36.0  \n",
      "890    man        True  NaN   Queenstown    no   True  42.0  \n",
      "\n",
      "[891 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "def add_10(n): # 10을 더하는 함수\n",
    "    return n+10\n",
    "\n",
    "import seaborn as sns\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "titanic['age2'] = titanic['age'].apply(add_10)\n",
    "\n",
    "print(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제153. (오늘의 마지막 문제) 미국 국민의 의료비 데이터(insurance.csv)를 판다스 데이터 프레임으로 생성하고 나이가 많을 수록 의료비가 많이드는지 회귀분석 모델로 확인하기 위하여 age2라는 파생변수를 생성하고, 기존 나이의 제곱으로 데이터를 생성하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age     sex     bmi  children smoker     region      charges  age2\n",
      "0      19  female  27.900         0    yes  southwest  16884.92400   361\n",
      "1      18    male  33.770         1     no  southeast   1725.55230   324\n",
      "2      28    male  33.000         3     no  southeast   4449.46200   784\n",
      "3      33    male  22.705         0     no  northwest  21984.47061  1089\n",
      "4      32    male  28.880         0     no  northwest   3866.85520  1024\n",
      "...   ...     ...     ...       ...    ...        ...          ...   ...\n",
      "1333   50    male  30.970         3     no  northwest  10600.54830  2500\n",
      "1334   18  female  31.920         0     no  northeast   2205.98080   324\n",
      "1335   18  female  36.850         0     no  southeast   1629.83350   324\n",
      "1336   21  female  25.800         0     no  southwest   2007.94500   441\n",
      "1337   61  female  29.070         0    yes  northwest  29141.36030  3721\n",
      "\n",
      "[1338 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "def square(n):\n",
    "    return n ** 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"d:\\\\data\\\\pandas\\\\insurance.csv\")\n",
    "\n",
    "df['age2'] = df['age'].apply(square)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
