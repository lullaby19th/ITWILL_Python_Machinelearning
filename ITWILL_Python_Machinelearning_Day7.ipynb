{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 7장. 데이터 프레임의 다양한 응용 복습\n",
    "\n",
    "1. 데이터 프레임에 함수를 매핑\n",
    "    - apply\n",
    "    - applymap\n",
    "    - pipe\n",
    "    \n",
    "    \n",
    "2. 열을 재구성\n",
    "    - dataframe객체[재구성할 열 이름 리스트]\n",
    "\n",
    "\n",
    "3. 열분리\n",
    "    - dataframe.str.split('-')\n",
    "\n",
    "\n",
    "4. 필터링\n",
    "    - dataframe객체[mask]  # mask <-- True or False 에 해당하는 Mask\n",
    "    - isin() 메소드\n",
    "\n",
    "\n",
    "5. 데이터 프레임 합치기\n",
    "    - dataframe.concat\n",
    "    - dataframe.merge\n",
    "    - dataframe.join\n",
    "    \n",
    "\n",
    "6. 그룹연산\n",
    "    - 1단계 : 분할(split)  \n",
    "    질문 : 운임클래스 3개중에서 가장 생존율이 높은 클래스는 어디인가 ?\n",
    "    \n",
    "    - 2단계 : 집계 및 변환, 필터링하는데 필요한 메소드를 적용\n",
    "    - 3단계 : 2단계의 처리결과를 하나로 결합\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 그룹연산\n",
    "   - df.groupby\n",
    "   - 그룹객체.함수()\n",
    "   - 그룹객체.agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 그룹객체.agg\n",
    "\n",
    "문법 : 그룹객체.agg(매핑함수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sal  deptno\n",
      "0   5000      10\n",
      "1   2850      30\n",
      "2   2450      10\n",
      "3   2975      20\n",
      "4   1250      30\n",
      "5   1600      30\n",
      "6   1500      30\n",
      "7    950      30\n",
      "8   1250      30\n",
      "9   3000      20\n",
      "10   800      20\n",
      "11  3000      20\n",
      "12  1100      20\n",
      "13  1300      10 \n",
      "\n",
      "          sal\n",
      "deptno       \n",
      "10       8750\n",
      "20      10875\n",
      "30       9400\n",
      "          sal\n",
      "deptno       \n",
      "10       8750\n",
      "20      10875\n",
      "30       9400\n"
     ]
    }
   ],
   "source": [
    "# 예제1.\n",
    "\n",
    "\"\"\"\n",
    "SQL>\n",
    "SELECT deptno, sum(sal)\n",
    "    from emp\n",
    "    group by deptno;\n",
    "\"\"\"\n",
    "\n",
    "# Pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "emp = pd.read_csv(\"d:\\\\data\\\\emp.csv\")\n",
    "df = emp.loc[:, ['sal', 'deptno']]\n",
    "print(df, '\\n')\n",
    "\n",
    "grouped = df.groupby('deptno')\n",
    "print(grouped.agg(sum)) # 그룹객체 : grouped // 매핑함수 : sum\n",
    "print(grouped.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제182. 아래의 SQL을 판다스로 구현하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   sal\n",
      "deptno job            \n",
      "10     CLERK      1300\n",
      "       MANAGER    2450\n",
      "       PRESIDENT  5000\n",
      "20     ANALYST    6000\n",
      "       CLERK      1900\n",
      "       MANAGER    2975\n",
      "30     CLERK       950\n",
      "       MANAGER    2850\n",
      "       SALESMAN   5600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SQL>\n",
    "select deptno, job, sum(sal)\n",
    "    from emp\n",
    "    grouped by deptno,job;\n",
    "\"\"\"\n",
    "\n",
    "# pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "emp = pd.read_csv(\"d:\\\\data\\\\emp.csv\")\n",
    "df = emp.loc[:, ['deptno', 'job', 'sal']]\n",
    "\n",
    "grouped = df.groupby(['deptno', 'job'])\n",
    "\n",
    "print(grouped.agg(sum)) # 정렬까지 아주 친절하게 해줌 (SQL> orderby까지 자동으로 잘해줌!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제183. 아래의 SQL을 판다스로 변경하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sal      \n",
      "         max   min\n",
      "deptno            \n",
      "10      5000  1300\n",
      "20      3000   800\n",
      "30      2850   950\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SQL>\n",
    "select deptno, min(sal), max(sal)\n",
    "    from emp\n",
    "    group by deptno;\n",
    "\"\"\"\n",
    "# Pandas\n",
    "\n",
    "import pandas as pd\n",
    "emp = pd.read_csv(\"d:\\\\data\\\\emp.csv\")\n",
    "df = emp.loc[:,['deptno', 'sal']]\n",
    "\n",
    "grouped = df.groupby(['deptno'])\n",
    "\n",
    "print(grouped.agg(['max','min']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제184. 타이타닉 운임클래스별로 각각 운임의 최대값과 최소값을 아래와 같이 출력하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "            Fare     \n",
      "             max  min\n",
      "Pclass               \n",
      "1       512.3292  0.0\n",
      "2        73.5000  0.0\n",
      "3        69.5500  0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tat = pd.read_csv(\"d:\\\\data\\\\train.csv\")\n",
    "print(tat.columns)\n",
    "\n",
    "df = tat.loc[:,['Pclass','Fare']]\n",
    "grouped = df.groupby(['Pclass'])\n",
    "\n",
    "\n",
    "print(grouped.agg(['max','min']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 그룹연산\n",
    "\n",
    "   - df.groupby\n",
    "   - 그룹객체.함수()\n",
    "   - 그룹객체.agg\n",
    "   - 그룹객체.filter(조건식함수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 그룹객체.filter(조건식함수)\n",
    "\n",
    "그룹객체 filter() 메소드를 적용할 때 조건식을 가진 함수를 전달하면 조건인 참인 그룹만을 남긴다.\n",
    "\n",
    "__문법 :__ group객체.filter(조건식함수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 : 이름과 월급과 직업과 부서번호를 출력하는데 자기 부서번호의 평균월급이 2000보다 작은 사원들만 출력하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ename   sal       job  deptno\n",
      "1   BLAKE  2850   MANAGER      30\n",
      "4  MARTIN  1250  SALESMAN      30\n",
      "5   ALLEN  1600  SALESMAN      30\n",
      "6  TURNER  1500  SALESMAN      30\n",
      "7   JAMES   950     CLERK      30\n",
      "8    WARD  1250  SALESMAN      30\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SQL>\n",
    "select ename, sal, job, deptno\n",
    "    from emp\n",
    "    where deptno in ( select deptno\n",
    "                        from emp\n",
    "                        group by deptno\n",
    "                        having avg(sal) < 2000);\n",
    "    \n",
    "\"\"\"\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "emp = pd.read_csv(\"d:\\\\data\\\\emp.csv\")\n",
    "df = emp.loc[:, ['ename','sal','job','deptno']]\n",
    "\n",
    "grouped = df.groupby(['deptno'])\n",
    "\n",
    "# result = grouped.filter(함수)\n",
    "result = grouped.filter(lambda x: x['sal'].mean() < 2000) # (lambda x: x.sal.mean() < 2000)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제185. 타이타닉 데이터에서 운임 클래스별로 평균나이가 30살보다 작은 운임클래스의 승객들의 이름과 성별과 나이와 운임과 생존여부를 출력하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object') \n",
      "\n",
      "              Age       Fare\n",
      "             mean       mean\n",
      "Pclass                      \n",
      "1       38.233441  84.154687\n",
      "2       29.877630  20.662183\n",
      "3       25.140620  13.675550 \n",
      "\n",
      "      Age     Fare  Pclass\n",
      "0    22.0   7.2500       3\n",
      "2    26.0   7.9250       3\n",
      "4    35.0   8.0500       3\n",
      "5     NaN   8.4583       3\n",
      "7     2.0  21.0750       3\n",
      "..    ...      ...     ...\n",
      "884  25.0   7.0500       3\n",
      "885  39.0  29.1250       3\n",
      "886  27.0  13.0000       2\n",
      "888   NaN  23.4500       3\n",
      "890  32.0   7.7500       3\n",
      "\n",
      "[675 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tat = pd.read_csv(\"d:\\\\data\\\\train.csv\")\n",
    "print(tat.columns, '\\n')\n",
    "\n",
    "df = tat.loc[:,['Age', 'Fare', 'Pclass']]\n",
    "grouped = df.groupby(['Pclass'])\n",
    "\n",
    "print(grouped.agg(['mean']), '\\n')\n",
    "\n",
    "result = grouped.filter(lambda x: x['Age'].mean() < 30)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 그룹객체.apply\n",
    "\n",
    "apply() 메소드는 판다스 객체의 개별 원소를 특정 함수에 일대일로 매핑한다.\n",
    "\n",
    "__문법 :__ group객체.apply(매핑함수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 : class 열을 기준으로 구분한 3개의 그룹에 요약통계정보를 확인할 수 있다.\n",
    "\n",
    "grouped = df.groupby(['Pclass'])  \n",
    "result = grouped.apply(lambda x:x.describe())  \n",
    "print(result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object') \n",
      "\n",
      "                     Age        Fare  Pclass\n",
      "Pclass                                      \n",
      "1      count  186.000000  216.000000   216.0\n",
      "       mean    38.233441   84.154687     1.0\n",
      "       std     14.802856   78.380373     0.0\n",
      "       min      0.920000    0.000000     1.0\n",
      "       25%     27.000000   30.923950     1.0\n",
      "       50%     37.000000   60.287500     1.0\n",
      "       75%     49.000000   93.500000     1.0\n",
      "       max     80.000000  512.329200     1.0\n",
      "2      count  173.000000  184.000000   184.0\n",
      "       mean    29.877630   20.662183     2.0\n",
      "       std     14.001077   13.417399     0.0\n",
      "       min      0.670000    0.000000     2.0\n",
      "       25%     23.000000   13.000000     2.0\n",
      "       50%     29.000000   14.250000     2.0\n",
      "       75%     36.000000   26.000000     2.0\n",
      "       max     70.000000   73.500000     2.0\n",
      "3      count  355.000000  491.000000   491.0\n",
      "       mean    25.140620   13.675550     3.0\n",
      "       std     12.495398   11.778142     0.0\n",
      "       min      0.420000    0.000000     3.0\n",
      "       25%     18.000000    7.750000     3.0\n",
      "       50%     24.000000    8.050000     3.0\n",
      "       75%     32.000000   15.500000     3.0\n",
      "       max     74.000000   69.550000     3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tat = pd.read_csv(\"d:\\\\data\\\\train.csv\")\n",
    "print(tat.columns, '\\n')\n",
    "\n",
    "df = tat.loc[:,['Age', 'Fare', 'Pclass']]\n",
    "grouped = df.groupby(['Pclass'])\n",
    "\n",
    "result = grouped.apply(lambda x:x.describe())  \n",
    "print(result)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply 함수로 데이터 전처리시 유용하게 사용하는 코드는?\n",
    "\n",
    "#### 데이터 정규화 할때 유용함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "print(titanic.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object') \n",
      "\n",
      "count    7.140000e+02\n",
      "mean    -7.945714e-17\n",
      "std      9.985965e-01\n",
      "min     -2.520692e+00\n",
      "25%     -5.714600e-01\n",
      "50%     -6.268304e-02\n",
      "75%      5.922208e-01\n",
      "max      3.910190e+00\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "tat = sns.load_dataset('titanic')\n",
    "print(tat.columns, '\\n')\n",
    "\n",
    "df = tat.loc[:,['age', 'fare', 'class', 'fare', 'survived','sex']]\n",
    "grouped = df.groupby(['class'])\n",
    "\n",
    "def z_score(x):\n",
    "    return (x-x.mean()) / x.std()\n",
    "\n",
    "agg_grouped = grouped['age'].apply(z_score)\n",
    "print(agg_grouped.describe()) # 통계정보 확인 describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제186. 타이타닉 데이터의 운임 데이터를 정규화하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object') \n",
      "\n",
      "count    8.910000e+02\n",
      "mean     1.951301e-16\n",
      "std      9.988758e-01\n",
      "min     -1.539954e+00\n",
      "25%     -5.455487e-01\n",
      "50%     -4.475536e-01\n",
      "75%      2.527764e-01\n",
      "max      5.462777e+00\n",
      "Name: fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "tat = sns.load_dataset('titanic')\n",
    "print(tat.columns, '\\n')\n",
    "\n",
    "df = tat.loc[:,['age', 'fare', 'class', 'survived','sex']]\n",
    "grouped = df.groupby(['class'])\n",
    "\n",
    "def z_score(x):\n",
    "    return (x-x.mean()) / x.std()\n",
    "\n",
    "fare_grouped = grouped['fare'].apply(z_score)\n",
    "print(fare_grouped.describe()) # 통계정보 확인 describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 멀티 인덱스\n",
    "\n",
    "groupby() 메소드에 여러 열을 리스트 형태로 전달하면 각 열들이 다중으로 행 인덱스를 구성하는 것을 보았다.  \n",
    "이처럼 판다스는 행 인덱스를 여러 레벨로 구현 할 수 있도록 멀티 인덱스 클래스를 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     age        fare  survived\n",
      "class  sex                                    \n",
      "First  female  34.611765  106.125798  0.968085\n",
      "       male    41.281386   67.226127  0.368852\n",
      "Second female  28.722973   21.970121  0.921053\n",
      "       male    30.740707   19.741782  0.157407\n",
      "Third  female  21.750000   16.118810  0.500000\n",
      "       male    26.507589   12.661633  0.135447\n"
     ]
    }
   ],
   "source": [
    "# 예제\n",
    "import seaborn as sns\n",
    "tat = sns.load_dataset('titanic')\n",
    "df = tat.loc[:,['age', 'fare', 'class', 'survived','sex']]\n",
    "\n",
    "grouped = df.groupby(['class', 'sex'])\n",
    "gdf = grouped.mean()\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제187. 위의 결과에서 first 클래스만 따로 검색하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     age        fare  survived\n",
      "class  sex                                    \n",
      "First  female  34.611765  106.125798  0.968085\n",
      "       male    41.281386   67.226127  0.368852\n",
      "Second female  28.722973   21.970121  0.921053\n",
      "       male    30.740707   19.741782  0.157407\n",
      "Third  female  21.750000   16.118810  0.500000\n",
      "       male    26.507589   12.661633  0.135447\n",
      "\n",
      "\n",
      "\n",
      "              age        fare  survived\n",
      "sex                                    \n",
      "female  34.611765  106.125798  0.968085\n",
      "male    41.281386   67.226127  0.368852\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "tat = sns.load_dataset('titanic')\n",
    "df = tat.loc[:,['age', 'fare', 'class', 'survived','sex']]\n",
    "\n",
    "grouped = df.groupby(['class', 'sex'])\n",
    "gdf = grouped.mean()\n",
    "print(gdf)\n",
    "print('\\n\\n')\n",
    "print(gdf.loc['First'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제188. 위의 결과 first 클래스의 female 데이터만 검색하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age          34.611765\n",
      "fare        106.125798\n",
      "survived      0.968085\n",
      "Name: (First, female), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "tat = sns.load_dataset('titanic')\n",
    "df = tat.loc[:,['age', 'fare', 'class', 'survived','sex']]\n",
    "\n",
    "grouped = df.groupby(['class', 'sex'])\n",
    "gdf = grouped.mean()\n",
    "print(gdf.loc[('First', 'female')], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제189. 남자 승객에 class 별 평균나이와 평균 운임 데이터만 검색하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     age        fare  survived\n",
      "class  sex                                    \n",
      "First  female  34.611765  106.125798  0.968085\n",
      "       male    41.281386   67.226127  0.368852\n",
      "Second female  28.722973   21.970121  0.921053\n",
      "       male    30.740707   19.741782  0.157407\n",
      "Third  female  21.750000   16.118810  0.500000\n",
      "       male    26.507589   12.661633  0.135447\n",
      "\n",
      "              age       fare  survived\n",
      "class                                 \n",
      "First   41.281386  67.226127  0.368852\n",
      "Second  30.740707  19.741782  0.157407\n",
      "Third   26.507589  12.661633  0.135447\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "tat = sns.load_dataset('titanic')\n",
    "df = tat.loc[:,['age', 'fare', 'class', 'survived','sex']]\n",
    "\n",
    "grouped = df.groupby(['class', 'sex'])\n",
    "gdf = grouped.mean()\n",
    "print(gdf, end = '\\n\\n')\n",
    "print(gdf.xs('male', level = 'sex'))\n",
    "# 나이가 많을수록 상대적으로 비싼요금을 지불하고 높은 객실 등급을 이용하는 경향을 보이고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제190. 사원 테이블에서 직업별 평균 월급과 평균 커미션이 아래와 같이 출력되게 하시오.\n",
    "### 어느 직업군이 월급이 가장 많고 커미션이 가장 많은지 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   sal   comm\n",
      "job                          \n",
      "PRESIDENT  5000.000000    0.0\n",
      "ANALYST    3000.000000    0.0\n",
      "MANAGER    2758.333333    0.0\n",
      "SALESMAN   1400.000000  550.0\n",
      "CLERK      1037.500000    0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emp = pd.read_csv(\"d:\\\\data\\\\emp.csv\")\n",
    "df = emp.loc[:,['sal','ename','comm','deptno','job']]\n",
    "\n",
    "grouped = df.groupby(['job'])\n",
    "gdf = grouped.mean().fillna(0)\n",
    "\n",
    "print(gdf[['sal','comm']].sort_values(by = 'sal', ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 8장. 머신러닝이란?\n",
    "\n",
    "__스스로 데이터를 학습하여 서로 다른 변수간의 관계를 찾아 나가는 과정__\n",
    "\n",
    "해결하려는 문제에 따라 __예측(prediction), 분류(classification), 군집(clustering)__ 등으로 분류된다.\n",
    "\n",
    "__예를들면,__ (주가, 환율) 등 경제지표를 예측한다든가, 은행에서 고객을 분류하여 대출을 승인하거나 거절하는 문제, 비슷한 소비패턴을 가진 고객 유형을 군집으로 묶어내는 문제등이 있다.\n",
    "\n",
    "머신러닝이 워낙 다양한 영역에 걸쳐있고, 사용하는 알고리즘과 방법론이 무수히 많기 때문에   \n",
    "체계적으로 이론을 정립해 나가려면 상당한 시간과 노력이 필요하다.  \n",
    "\n",
    "이 과정에서 많은 초심자들이 중간에 포기하거나 흥미를 잃게 된다.   \n",
    "따라서 복잡한 이론보다는 실제 데이터를 가지고 간단한 문제부터 예측해보는 실습을 통해 익혀나가는것이 바람직하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 머신러닝의 종류 3가지 (OneNote 참고)\n",
    "\n",
    "1. 지도학습\n",
    "2. 비지도학습\n",
    "3. 강화학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 머신러닝 분석하는 과정\n",
    "\n",
    "머신러닝 데이터 분석을 시작하기 전에 컴퓨터 알고리즘이 이해할수 있는 형태로 데이터를 변환하는 작업이 선행되어야 합니다.  \n",
    "( 무엇으로 하는가? 판다스로 수행 )\n",
    "\n",
    "#### < 데이터 전처리 >  \n",
    "1. csv 파일을 데이터프레임으로 변환합니다.\n",
    "2. 결측치를 제거하거나 치환합니다.\n",
    "3. 범주형 데이터를 머신러닝 모델이 인식할 수 있도록 숫자형으로 변환합니다.\n",
    "4. 정규화를 진행합니다.\n",
    "5. 데이터를 훈련 데이터와 테스트 데이터로 나눕니다.\n",
    "\n",
    "#### < 모델 생성 >  \n",
    "6. 훈련 데이터로 모형을 학습하여 모형을 생성합니다.\n",
    "\n",
    "#### < 모델 예측 및 평가 >  \n",
    "7. 테스트 데이터를 훈련 모델을 넣어 예측을 합니다.\n",
    "8. 모형의 예측능력을 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 9장. knn 알고리즘 이론 설명\n",
    "\n",
    "__k nearest neighbor__의 약자로 k개의 최근 이웃이라는 뜻이다.  \n",
    "머신러닝의 지도학습에 분류에 해당하는 알고리즘이다.  \n",
    "새로 들어온 데이터가 기존 데이터의 그룹에 어느 그룹에 속하는지 찾을 때   \n",
    "거리가 가까운 데이터의 그룹을 자기 그룹으로 선택하는 아주 간단한 알고리즘이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ knn 알고리즘의 장단점\n",
    "\n",
    "- 장점 : 단순하고 효율적이다. 훈련 단계가 빠르다.\n",
    "- 단점 : 모델을 생성하지 않아서 특징과 클래스간의 관계를 이해하는 능력이 제약된다 & 적절한 k 값을 사용자가 직접 알아내야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ knn의 원리\n",
    "\n",
    "새로 들어온 데이터가 기존의 데이터 중(악성종양, 양성종양) 에 어느 데이터에 더 인접해 있는지 거리를 계산해서   \n",
    "가장 가까운 거리에 있는 데이터를 자기 이웃으로 선택한다.\n",
    "\n",
    "__<거리를 계산할 때 사용하는 수학식?>__\n",
    "\n",
    "__★유클리드 거리 계산식★__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제1. 유클리드 거리 공식을 이용해서 토마토가 가장 가까운 거리에 있는 category가 무엇인지 파이썬으로 구현하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['과일', '과일', '단백질']\n",
      "Counter({'과일': 2, '단백질': 1})\n",
      "과일\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "def knn(t,k):\n",
    "    x = [8,2,7,7,3,1]\n",
    "    y = [5,3,10,3,8,1]\n",
    "    label = ['과일', '단백질', '채소', '과일', '채소', '단백질']    \n",
    "    d = []\n",
    "    \n",
    "    box = defaultdict(list)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        x_t = (t[0] - x[i]) ** 2\n",
    "        y_t = (t[1] - y[i]) ** 2\n",
    "        result = round(math.sqrt(x_t + y_t),k)\n",
    "        d.append(result) # 유클리드 기하학으로 나온거리를 리스트로 다 나타냄.\n",
    "    \n",
    "    s_d = sorted(d)[0:k] # k까지 순위 정해서 추출.\n",
    "    \n",
    "    for i, label in enumerate(label):\n",
    "        box[label].append(d[i])\n",
    "    \n",
    "    li = []\n",
    "    \n",
    "    for i in box.keys():\n",
    "        for j in range (len(box[i])):    \n",
    "            if box[i][j] in s_d:\n",
    "                li.append(i)\n",
    "    print(li)\n",
    "    \n",
    "    li_s = Counter(li)\n",
    "    \n",
    "    print(li_s)\n",
    "    \n",
    "    tmp = list(li_s.keys())[0]\n",
    "    \n",
    "    return tmp\n",
    "    \n",
    "\n",
    "tomato = [6,4]\n",
    "\n",
    "print ( knn(tomato,k=3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제2. 타이타닉 생존자를 예측하는 머신러닝 모델을 knn으로 구현하는 방법 총정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True   \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "survived       891 non-null int64\n",
      "pclass         891 non-null int64\n",
      "sex            891 non-null object\n",
      "age            714 non-null float64\n",
      "sibsp          891 non-null int64\n",
      "parch          891 non-null int64\n",
      "fare           891 non-null float64\n",
      "embarked       889 non-null object\n",
      "class          891 non-null category\n",
      "who            891 non-null object\n",
      "adult_male     891 non-null bool\n",
      "deck           203 non-null category\n",
      "embark_town    889 non-null object\n",
      "alive          891 non-null object\n",
      "alone          891 non-null bool\n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.6+ KB\n",
      "None\n",
      "\n",
      "\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64 \n",
      "\n",
      "['survived' 'pclass' 'sex' 'age' 'sibsp' 'parch' 'fare' 'embarked' 'class'\n",
      " 'who' 'adult_male' 'alive' 'alone'] \n",
      "\n",
      "714 \n",
      "\n",
      "survived      0\n",
      "pclass        0\n",
      "sex           0\n",
      "age           0\n",
      "sibsp         0\n",
      "parch         0\n",
      "fare          0\n",
      "embarked      0\n",
      "class         0\n",
      "who           0\n",
      "adult_male    0\n",
      "alive         0\n",
      "alone         0\n",
      "dtype: int64 \n",
      "\n",
      "   survived  pclass     sex   age  sibsp  parch embarked\n",
      "0         0       3    male  22.0      1      0        S\n",
      "1         1       1  female  38.0      1      0        C\n",
      "2         1       3  female  26.0      0      0        S\n",
      "3         1       1  female  35.0      1      0        S\n",
      "4         0       3    male  35.0      0      0        S \n",
      "\n",
      "   survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
      "0         0       3  22.0      1      0       0     1       0       0       1\n",
      "1         1       1  38.0      1      0       1     0       1       0       0\n",
      "2         1       3  26.0      0      0       1     0       0       0       1\n",
      "3         1       1  35.0      1      0       1     0       0       0       1\n",
      "4         0       3  35.0      0      0       0     1       0       0       1\n",
      "\n",
      "\n",
      "[[ 0.91123237 -0.53037664  0.52457013 ... -0.47180795 -0.20203051\n",
      "   0.53307848]\n",
      " [-1.47636364  0.57183099  0.52457013 ...  2.11950647 -0.20203051\n",
      "  -1.87589641]\n",
      " [ 0.91123237 -0.25482473 -0.55170307 ... -0.47180795 -0.20203051\n",
      "   0.53307848]\n",
      " ...\n",
      " [-1.47636364 -0.73704057 -0.55170307 ... -0.47180795 -0.20203051\n",
      "   0.53307848]\n",
      " [-1.47636364 -0.25482473 -0.55170307 ...  2.11950647 -0.20203051\n",
      "  -1.87589641]\n",
      " [ 0.91123237  0.15850313 -0.55170307 ... -0.47180795  4.94974747\n",
      "  -1.87589641]]\n",
      "\n",
      "\n",
      "train data 의 갯수: (499, 9)\n",
      "test data 의 갯수: (215, 9)\n",
      "\n",
      "\n",
      "[1 1 1 1 0 0 0 1 0 0]\n",
      "\n",
      "\n",
      "[[106  21]\n",
      " [ 21  67]]\n",
      "\n",
      "\n",
      "[[106  21]\n",
      " [ 21  67]]\n",
      "\n",
      "\n",
      "106 21 21 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       127\n",
      "           1       0.76      0.76      0.76        88\n",
      "\n",
      "    accuracy                           0.80       215\n",
      "   macro avg       0.80      0.80      0.80       215\n",
      "weighted avg       0.80      0.80      0.80       215\n",
      " \n",
      "\n",
      "0.8046511627906977\n",
      "\n",
      "\n",
      "0.7613636363636364\n",
      "\n",
      "\n",
      "0.7613636363636364\n",
      "\n",
      "\n",
      "0.7613636363636364\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1단계. csv --> 데이터 프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "print(df.head(), '\\n')\n",
    "\n",
    "# 2.1 결측치를 확인하고 제거하거나 치환한다.\n",
    "# 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "print(df.info()) # 자료형 확인하는 방법\n",
    "print('\\n')\n",
    "# 2.2 결측치(NaN)을 확인한다.\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함\n",
    "# embark 와 embark_town이 같은 데이터(중복데이터)여서 컬럼을 하나 삭제해야함.\n",
    "# embark 컬럼은 삭제한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "rdf = df.drop(['deck', 'embark_town'], axis =1)\n",
    "print(rdf.columns.values, '\\n')\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든 행을 삭제한다.\n",
    "# age 열에 891개의 행중에 177개가 NaN값\n",
    "\n",
    "rdf = rdf.dropna(subset = ['age'], how='any', axis = 0)\n",
    "print(len(rdf), '\\n')\n",
    "\n",
    "# 설명\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "# 2.5 embark 열의 NaN값을 승선도시중 가장 많이 출현한 값으로 치환하기.\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 3. 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked']]\n",
    "print(ndf.head(), '\\n')\n",
    "# 선택된 컬럼중 2개(sex, embarked)가 범주형(문자형)이다.\n",
    "\n",
    "# 3.2 범주형 데이터를 숫자로 변환(원핫 인코딩)\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix = 'town') # 접두사를 정함.\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis = 1 , inplace = True)\n",
    "print(ndf.head())\n",
    "print('\\n')\n",
    "\n",
    "# 4단계. 정규화\n",
    "# survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
    "# survived (종속변수 y)\n",
    "# pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S (독립변수 X)\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨)를 지정한다.\n",
    "X = ndf[['pclass','age','sibsp','parch','female','male','town_C','town_Q','town_S']] # 독립변수\n",
    "y = ndf['survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화(normalization) 한다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "print(X)\n",
    "print('\\n')\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 10)\n",
    "\n",
    "# 설명 : test_size = 0.3 에 의해서 7:3 비율로 훈련과 테스트를 나누고 \n",
    "# random_state = 10 에 의해서 나중에 split할 때도 항상 일정하게 split 할 수 있게 한다.\n",
    "\n",
    "print('train data 의 갯수:', X_train.shape) # (499,9)\n",
    "print('test data 의 갯수:', X_test.shape) # (215, 9)\n",
    "print('\\n')\n",
    "\n",
    "# 6단계. 머신러닝 모델을 생성한다.(knn을 사용)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5) # n_neighbors = 5 (knn의 k값은 5) 변수\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 7단계. 테스트 데이터로 예측하기\n",
    "\n",
    "y_hat = knn.predict(X_test)\n",
    "print(y_hat[0:10])\n",
    "print('\\n')\n",
    "\n",
    "# 8단계. 모형의 예측 능력을 평가한다.\n",
    "from sklearn import metrics\n",
    "knn_matrix = metrics.confusion_matrix(y_hat,y_test)\n",
    "print(knn_matrix)\n",
    "print('\\n')\n",
    "#%%\n",
    "\n",
    "# 8단계. 모형의 예측 능력을 평가한다.\n",
    "from sklearn import metrics\n",
    "knn_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "print(knn_matrix)\n",
    "print('\\n')\n",
    "\n",
    "\"\"\"\n",
    "             예측\n",
    "           사망 생존\n",
    "실제 사망 [[109  16]\n",
    "     생존  [ 25  65]]\n",
    "     \n",
    "\"\"\"\n",
    "\n",
    "# 정확도 : (109 + 65) / (109 + 16 + 25 + 65)\n",
    "# 정확도 100%는 현실적으로 나오기 힘드니 (예측: 생존 , 실제: 사망 데이터인 25를 0으로 만드는 것을 궁극적으로 추구한다.)\n",
    "\n",
    "# confusion matrix에 대한 변수 지정 (tn,fp,fn,tp)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "print(f1_report,'\\n')\n",
    "\n",
    "# 9단계 정확도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "# 정확도 : (109 + 65) / (109 + 16 + 25 + 65)\n",
    "# 정확도 100%는 현실적으로 나오기 힘드니 (예측: 생존 , 실제: 사망 데이터인 25를 0으로 만드는 것을 궁극적으로 추구한다.)\n",
    "\n",
    "# precision(정밀도) 구하는 코드\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_hat)\n",
    "print(precision)\n",
    "print('\\n')\n",
    "\n",
    "# recall(재현율) 구하는 코드\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test,y_hat)\n",
    "print(recall)\n",
    "print('\\n')\n",
    "\n",
    "# f1-score 구하는 코드\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test,y_hat)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ver2. 반복문과 최대값 함수를 추가하여 정확도 최대치를 뽑도록 Upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True   \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "survived       891 non-null int64\n",
      "pclass         891 non-null int64\n",
      "sex            891 non-null object\n",
      "age            714 non-null float64\n",
      "sibsp          891 non-null int64\n",
      "parch          891 non-null int64\n",
      "fare           891 non-null float64\n",
      "embarked       889 non-null object\n",
      "class          891 non-null category\n",
      "who            891 non-null object\n",
      "adult_male     891 non-null bool\n",
      "deck           203 non-null category\n",
      "embark_town    889 non-null object\n",
      "alive          891 non-null object\n",
      "alone          891 non-null bool\n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.6+ KB\n",
      "None\n",
      "\n",
      "\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64 \n",
      "\n",
      "   survived  pclass     sex   age  sibsp  parch embarked\n",
      "0         0       3    male  22.0      1      0        S\n",
      "1         1       1  female  38.0      1      0        C\n",
      "2         1       3  female  26.0      0      0        S\n",
      "3         1       1  female  35.0      1      0        S\n",
      "4         0       3    male  35.0      0      0        S \n",
      "\n",
      "n_neighbors = 5 random_state = 10\n",
      "[[109  16]\n",
      " [ 25  65]]\n",
      "0.8093023255813954\n",
      "precision은 0.8024691358024691\n",
      "recall은 0.7222222222222222\n",
      "f1-score 은 0.7602339181286549\n",
      "n_neighbors = 6 random_state = 10\n",
      "[[116   9]\n",
      " [ 33  57]]\n",
      "0.8046511627906977\n",
      "precision은 0.8636363636363636\n",
      "recall은 0.6333333333333333\n",
      "f1-score 은 0.7307692307692307\n",
      "n_neighbors = 7 random_state = 10\n",
      "[[113  12]\n",
      " [ 30  60]]\n",
      "0.8046511627906977\n",
      "precision은 0.8333333333333334\n",
      "recall은 0.6666666666666666\n",
      "f1-score 은 0.7407407407407408\n",
      "n_neighbors = 8 random_state = 10\n",
      "[[118   7]\n",
      " [ 33  57]]\n",
      "0.813953488372093\n",
      "precision은 0.890625\n",
      "recall은 0.6333333333333333\n",
      "f1-score 은 0.7402597402597403\n",
      "n_neighbors = 9 random_state = 10\n",
      "[[117   8]\n",
      " [ 33  57]]\n",
      "0.8093023255813954\n",
      "precision은 0.8769230769230769\n",
      "recall은 0.6333333333333333\n",
      "f1-score 은 0.7354838709677419\n",
      "n_neighbors = 5 random_state = 11\n",
      "[[111  19]\n",
      " [ 33  52]]\n",
      "0.7581395348837209\n",
      "precision은 0.7323943661971831\n",
      "recall은 0.611764705882353\n",
      "f1-score 은 0.6666666666666667\n",
      "n_neighbors = 6 random_state = 11\n",
      "[[122   8]\n",
      " [ 37  48]]\n",
      "0.7906976744186046\n",
      "precision은 0.8571428571428571\n",
      "recall은 0.5647058823529412\n",
      "f1-score 은 0.6808510638297872\n",
      "n_neighbors = 7 random_state = 11\n",
      "[[115  15]\n",
      " [ 35  50]]\n",
      "0.7674418604651163\n",
      "precision은 0.7692307692307693\n",
      "recall은 0.5882352941176471\n",
      "f1-score 은 0.6666666666666667\n",
      "n_neighbors = 8 random_state = 11\n",
      "[[120  10]\n",
      " [ 38  47]]\n",
      "0.7767441860465116\n",
      "precision은 0.8245614035087719\n",
      "recall은 0.5529411764705883\n",
      "f1-score 은 0.6619718309859155\n",
      "n_neighbors = 9 random_state = 11\n",
      "[[119  11]\n",
      " [ 38  47]]\n",
      "0.772093023255814\n",
      "precision은 0.8103448275862069\n",
      "recall은 0.5529411764705883\n",
      "f1-score 은 0.6573426573426574\n",
      "n_neighbors = 5 random_state = 12\n",
      "[[106  18]\n",
      " [ 27  64]]\n",
      "0.7906976744186046\n",
      "precision은 0.7804878048780488\n",
      "recall은 0.7032967032967034\n",
      "f1-score 은 0.739884393063584\n",
      "n_neighbors = 6 random_state = 12\n",
      "[[110  14]\n",
      " [ 29  62]]\n",
      "0.8\n",
      "precision은 0.8157894736842105\n",
      "recall은 0.6813186813186813\n",
      "f1-score 은 0.7425149700598803\n",
      "n_neighbors = 7 random_state = 12\n",
      "[[107  17]\n",
      " [ 26  65]]\n",
      "0.8\n",
      "precision은 0.7926829268292683\n",
      "recall은 0.7142857142857143\n",
      "f1-score 은 0.7514450867052024\n",
      "n_neighbors = 8 random_state = 12\n",
      "[[111  13]\n",
      " [ 28  63]]\n",
      "0.8093023255813954\n",
      "precision은 0.8289473684210527\n",
      "recall은 0.6923076923076923\n",
      "f1-score 은 0.7544910179640718\n",
      "n_neighbors = 9 random_state = 12\n",
      "[[110  14]\n",
      " [ 28  63]]\n",
      "0.8046511627906977\n",
      "precision은 0.8181818181818182\n",
      "recall은 0.6923076923076923\n",
      "f1-score 은 0.7500000000000001\n",
      "n_neighbors = 5 random_state = 13\n",
      "[[106  17]\n",
      " [ 26  66]]\n",
      "0.8\n",
      "precision은 0.7951807228915663\n",
      "recall은 0.717391304347826\n",
      "f1-score 은 0.7542857142857142\n",
      "n_neighbors = 6 random_state = 13\n",
      "[[108  15]\n",
      " [ 30  62]]\n",
      "0.7906976744186046\n",
      "precision은 0.8051948051948052\n",
      "recall은 0.6739130434782609\n",
      "f1-score 은 0.7337278106508877\n",
      "n_neighbors = 7 random_state = 13\n",
      "[[104  19]\n",
      " [ 26  66]]\n",
      "0.7906976744186046\n",
      "precision은 0.7764705882352941\n",
      "recall은 0.717391304347826\n",
      "f1-score 은 0.7457627118644068\n",
      "n_neighbors = 8 random_state = 13\n",
      "[[106  17]\n",
      " [ 30  62]]\n",
      "0.7813953488372093\n",
      "precision은 0.7848101265822784\n",
      "recall은 0.6739130434782609\n",
      "f1-score 은 0.7251461988304092\n",
      "n_neighbors = 9 random_state = 13\n",
      "[[102  21]\n",
      " [ 23  69]]\n",
      "0.7953488372093023\n",
      "precision은 0.7666666666666667\n",
      "recall은 0.75\n",
      "f1-score 은 0.7582417582417583\n",
      "n_neighbors = 5 random_state = 14\n",
      "[[108  14]\n",
      " [ 30  63]]\n",
      "0.7953488372093023\n",
      "precision은 0.8181818181818182\n",
      "recall은 0.6774193548387096\n",
      "f1-score 은 0.7411764705882352\n",
      "n_neighbors = 6 random_state = 14\n",
      "[[112  10]\n",
      " [ 34  59]]\n",
      "0.7953488372093023\n",
      "precision은 0.855072463768116\n",
      "recall은 0.6344086021505376\n",
      "f1-score 은 0.728395061728395\n",
      "n_neighbors = 7 random_state = 14\n",
      "[[109  13]\n",
      " [ 26  67]]\n",
      "0.8186046511627907\n",
      "precision은 0.8375\n",
      "recall은 0.7204301075268817\n",
      "f1-score 은 0.7745664739884393\n",
      "n_neighbors = 8 random_state = 14\n",
      "[[112  10]\n",
      " [ 33  60]]\n",
      "0.8\n",
      "precision은 0.8571428571428571\n",
      "recall은 0.6451612903225806\n",
      "f1-score 은 0.7361963190184049\n",
      "n_neighbors = 9 random_state = 14\n",
      "[[108  14]\n",
      " [ 25  68]]\n",
      "0.8186046511627907\n",
      "precision은 0.8292682926829268\n",
      "recall은 0.7311827956989247\n",
      "f1-score 은 0.777142857142857\n",
      "n_neighbors = 5 random_state = 15\n",
      "[[106  21]\n",
      " [ 21  67]]\n",
      "0.8046511627906977\n",
      "precision은 0.7613636363636364\n",
      "recall은 0.7613636363636364\n",
      "f1-score 은 0.7613636363636364\n",
      "n_neighbors = 6 random_state = 15\n",
      "[[113  14]\n",
      " [ 26  62]]\n",
      "0.813953488372093\n",
      "precision은 0.8157894736842105\n",
      "recall은 0.7045454545454546\n",
      "f1-score 은 0.7560975609756098\n",
      "n_neighbors = 7 random_state = 15\n",
      "[[109  18]\n",
      " [ 24  64]]\n",
      "0.8046511627906977\n",
      "precision은 0.7804878048780488\n",
      "recall은 0.7272727272727273\n",
      "f1-score 은 0.7529411764705882\n",
      "n_neighbors = 8 random_state = 15\n",
      "[[117  10]\n",
      " [ 25  63]]\n",
      "0.8372093023255814\n",
      "precision은 0.863013698630137\n",
      "recall은 0.7159090909090909\n",
      "f1-score 은 0.782608695652174\n",
      "n_neighbors = 9 random_state = 15\n",
      "[[110  17]\n",
      " [ 20  68]]\n",
      "0.827906976744186\n",
      "precision은 0.8\n",
      "recall은 0.7727272727272727\n",
      "f1-score 은 0.7861271676300577\n",
      "n_neighbors = 5 random_state = 16\n",
      "[[111  15]\n",
      " [ 24  65]]\n",
      "0.8186046511627907\n",
      "precision은 0.8125\n",
      "recall은 0.7303370786516854\n",
      "f1-score 은 0.7692307692307693\n",
      "n_neighbors = 6 random_state = 16\n",
      "[[115  11]\n",
      " [ 29  60]]\n",
      "0.813953488372093\n",
      "precision은 0.8450704225352113\n",
      "recall은 0.6741573033707865\n",
      "f1-score 은 0.7499999999999999\n",
      "n_neighbors = 7 random_state = 16\n",
      "[[106  20]\n",
      " [ 24  65]]\n",
      "0.7953488372093023\n",
      "precision은 0.7647058823529411\n",
      "recall은 0.7303370786516854\n",
      "f1-score 은 0.7471264367816092\n",
      "n_neighbors = 8 random_state = 16\n",
      "[[113  13]\n",
      " [ 28  61]]\n",
      "0.8093023255813954\n",
      "precision은 0.8243243243243243\n",
      "recall은 0.6853932584269663\n",
      "f1-score 은 0.7484662576687118\n",
      "n_neighbors = 9 random_state = 16\n",
      "[[111  15]\n",
      " [ 25  64]]\n",
      "0.813953488372093\n",
      "precision은 0.810126582278481\n",
      "recall은 0.7191011235955056\n",
      "f1-score 은 0.761904761904762\n",
      "n_neighbors = 5 random_state = 17\n",
      "[[123  14]\n",
      " [ 26  52]]\n",
      "0.813953488372093\n",
      "precision은 0.7878787878787878\n",
      "recall은 0.6666666666666666\n",
      "f1-score 은 0.7222222222222221\n",
      "n_neighbors = 6 random_state = 17\n",
      "[[127  10]\n",
      " [ 28  50]]\n",
      "0.8232558139534883\n",
      "precision은 0.8333333333333334\n",
      "recall은 0.6410256410256411\n",
      "f1-score 은 0.7246376811594204\n",
      "n_neighbors = 7 random_state = 17\n",
      "[[125  12]\n",
      " [ 27  51]]\n",
      "0.8186046511627907\n",
      "precision은 0.8095238095238095\n",
      "recall은 0.6538461538461539\n",
      "f1-score 은 0.7234042553191489\n",
      "n_neighbors = 8 random_state = 17\n",
      "[[128   9]\n",
      " [ 28  50]]\n",
      "0.827906976744186\n",
      "precision은 0.847457627118644\n",
      "recall은 0.6410256410256411\n",
      "f1-score 은 0.7299270072992702\n",
      "n_neighbors = 9 random_state = 17\n",
      "[[123  14]\n",
      " [ 26  52]]\n",
      "0.813953488372093\n",
      "precision은 0.7878787878787878\n",
      "recall은 0.6666666666666666\n",
      "f1-score 은 0.7222222222222221\n",
      "n_neighbors = 5 random_state = 18\n",
      "[[102  14]\n",
      " [ 32  67]]\n",
      "0.786046511627907\n",
      "precision은 0.8271604938271605\n",
      "recall은 0.6767676767676768\n",
      "f1-score 은 0.7444444444444445\n",
      "n_neighbors = 6 random_state = 18\n",
      "[[108   8]\n",
      " [ 40  59]]\n",
      "0.7767441860465116\n",
      "precision은 0.8805970149253731\n",
      "recall은 0.5959595959595959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score 은 0.7108433734939759\n",
      "n_neighbors = 7 random_state = 18\n",
      "[[99 17]\n",
      " [30 69]]\n",
      "0.7813953488372093\n",
      "precision은 0.8023255813953488\n",
      "recall은 0.696969696969697\n",
      "f1-score 은 0.745945945945946\n",
      "n_neighbors = 8 random_state = 18\n",
      "[[108   8]\n",
      " [ 36  63]]\n",
      "0.7953488372093023\n",
      "precision은 0.8873239436619719\n",
      "recall은 0.6363636363636364\n",
      "f1-score 은 0.7411764705882353\n",
      "n_neighbors = 9 random_state = 18\n",
      "[[100  16]\n",
      " [ 33  66]]\n",
      "0.772093023255814\n",
      "precision은 0.8048780487804879\n",
      "recall은 0.6666666666666666\n",
      "f1-score 은 0.7292817679558011\n",
      "n_neighbors = 5 random_state = 19\n",
      "[[117  17]\n",
      " [ 21  60]]\n",
      "0.8232558139534883\n",
      "precision은 0.7792207792207793\n",
      "recall은 0.7407407407407407\n",
      "f1-score 은 0.7594936708860759\n",
      "n_neighbors = 6 random_state = 19\n",
      "[[120  14]\n",
      " [ 27  54]]\n",
      "0.8093023255813954\n",
      "precision은 0.7941176470588235\n",
      "recall은 0.6666666666666666\n",
      "f1-score 은 0.7248322147651006\n",
      "n_neighbors = 7 random_state = 19\n",
      "[[118  16]\n",
      " [ 24  57]]\n",
      "0.813953488372093\n",
      "precision은 0.7808219178082192\n",
      "recall은 0.7037037037037037\n",
      "f1-score 은 0.7402597402597403\n",
      "n_neighbors = 8 random_state = 19\n",
      "[[119  15]\n",
      " [ 26  55]]\n",
      "0.8093023255813954\n",
      "precision은 0.7857142857142857\n",
      "recall은 0.6790123456790124\n",
      "f1-score 은 0.728476821192053\n",
      "n_neighbors = 9 random_state = 19\n",
      "[[115  19]\n",
      " [ 25  56]]\n",
      "0.7953488372093023\n",
      "precision은 0.7466666666666667\n",
      "recall은 0.691358024691358\n",
      "f1-score 은 0.717948717948718\n",
      "n_neighbors = 5 random_state = 20\n",
      "[[113  11]\n",
      " [ 22  69]]\n",
      "0.8465116279069768\n",
      "precision은 0.8625\n",
      "recall은 0.7582417582417582\n",
      "f1-score 은 0.8070175438596491\n",
      "n_neighbors = 6 random_state = 20\n",
      "[[115   9]\n",
      " [ 28  63]]\n",
      "0.827906976744186\n",
      "precision은 0.875\n",
      "recall은 0.6923076923076923\n",
      "f1-score 은 0.7730061349693251\n",
      "n_neighbors = 7 random_state = 20\n",
      "[[112  12]\n",
      " [ 25  66]]\n",
      "0.827906976744186\n",
      "precision은 0.8461538461538461\n",
      "recall은 0.7252747252747253\n",
      "f1-score 은 0.7810650887573964\n",
      "n_neighbors = 8 random_state = 20\n",
      "[[118   6]\n",
      " [ 30  61]]\n",
      "0.8325581395348837\n",
      "precision은 0.9104477611940298\n",
      "recall은 0.6703296703296703\n",
      "f1-score 은 0.7721518987341772\n",
      "n_neighbors = 9 random_state = 20\n",
      "[[112  12]\n",
      " [ 27  64]]\n",
      "0.8186046511627907\n",
      "precision은 0.8421052631578947\n",
      "recall은 0.7032967032967034\n",
      "f1-score 은 0.7664670658682634\n",
      "n_neighbors = 5 random_state = 21\n",
      "[[112  24]\n",
      " [ 23  56]]\n",
      "0.7813953488372093\n",
      "precision은 0.7\n",
      "recall은 0.7088607594936709\n",
      "f1-score 은 0.7044025157232704\n",
      "n_neighbors = 6 random_state = 21\n",
      "[[120  16]\n",
      " [ 25  54]]\n",
      "0.8093023255813954\n",
      "precision은 0.7714285714285715\n",
      "recall은 0.6835443037974683\n",
      "f1-score 은 0.7248322147651006\n",
      "n_neighbors = 7 random_state = 21\n",
      "[[113  23]\n",
      " [ 21  58]]\n",
      "0.7953488372093023\n",
      "precision은 0.7160493827160493\n",
      "recall은 0.7341772151898734\n",
      "f1-score 은 0.7250000000000001\n",
      "n_neighbors = 8 random_state = 21\n",
      "[[119  17]\n",
      " [ 23  56]]\n",
      "0.813953488372093\n",
      "precision은 0.7671232876712328\n",
      "recall은 0.7088607594936709\n",
      "f1-score 은 0.736842105263158\n",
      "n_neighbors = 9 random_state = 21\n",
      "[[115  21]\n",
      " [ 20  59]]\n",
      "0.8093023255813954\n",
      "precision은 0.7375\n",
      "recall은 0.7468354430379747\n",
      "f1-score 은 0.7421383647798743\n",
      "n_neighbors = 5 random_state = 22\n",
      "[[97 26]\n",
      " [19 73]]\n",
      "0.7906976744186046\n",
      "precision은 0.7373737373737373\n",
      "recall은 0.7934782608695652\n",
      "f1-score 은 0.7643979057591622\n",
      "n_neighbors = 6 random_state = 22\n",
      "[[108  15]\n",
      " [ 31  61]]\n",
      "0.786046511627907\n",
      "precision은 0.8026315789473685\n",
      "recall은 0.6630434782608695\n",
      "f1-score 은 0.7261904761904762\n",
      "n_neighbors = 7 random_state = 22\n",
      "[[106  17]\n",
      " [ 25  67]]\n",
      "0.8046511627906977\n",
      "precision은 0.7976190476190477\n",
      "recall은 0.7282608695652174\n",
      "f1-score 은 0.7613636363636362\n",
      "n_neighbors = 8 random_state = 22\n",
      "[[112  11]\n",
      " [ 31  61]]\n",
      "0.8046511627906977\n",
      "precision은 0.8472222222222222\n",
      "recall은 0.6630434782608695\n",
      "f1-score 은 0.7439024390243902\n",
      "n_neighbors = 9 random_state = 22\n",
      "[[105  18]\n",
      " [ 23  69]]\n",
      "0.8093023255813954\n",
      "precision은 0.7931034482758621\n",
      "recall은 0.75\n",
      "f1-score 은 0.770949720670391\n",
      "n_neighbors = 5 random_state = 23\n",
      "[[111  20]\n",
      " [ 24  60]]\n",
      "0.7953488372093023\n",
      "precision은 0.75\n",
      "recall은 0.7142857142857143\n",
      "f1-score 은 0.7317073170731706\n",
      "n_neighbors = 6 random_state = 23\n",
      "[[124   7]\n",
      " [ 33  51]]\n",
      "0.813953488372093\n",
      "precision은 0.8793103448275862\n",
      "recall은 0.6071428571428571\n",
      "f1-score 은 0.7183098591549295\n",
      "n_neighbors = 7 random_state = 23\n",
      "[[113  18]\n",
      " [ 27  57]]\n",
      "0.7906976744186046\n",
      "precision은 0.76\n",
      "recall은 0.6785714285714286\n",
      "f1-score 은 0.7169811320754718\n",
      "n_neighbors = 8 random_state = 23\n",
      "[[122   9]\n",
      " [ 33  51]]\n",
      "0.8046511627906977\n",
      "precision은 0.85\n",
      "recall은 0.6071428571428571\n",
      "f1-score 은 0.7083333333333333\n",
      "n_neighbors = 9 random_state = 23\n",
      "[[119  12]\n",
      " [ 30  54]]\n",
      "0.8046511627906977\n",
      "precision은 0.8181818181818182\n",
      "recall은 0.6428571428571429\n",
      "f1-score 은 0.7200000000000001\n",
      "n_neighbors = 5 random_state = 24\n",
      "[[108  23]\n",
      " [ 22  62]]\n",
      "0.7906976744186046\n",
      "precision은 0.7294117647058823\n",
      "recall은 0.7380952380952381\n",
      "f1-score 은 0.7337278106508874\n",
      "n_neighbors = 6 random_state = 24\n",
      "[[112  19]\n",
      " [ 28  56]]\n",
      "0.7813953488372093\n",
      "precision은 0.7466666666666667\n",
      "recall은 0.6666666666666666\n",
      "f1-score 은 0.7044025157232704\n",
      "n_neighbors = 7 random_state = 24\n",
      "[[108  23]\n",
      " [ 24  60]]\n",
      "0.7813953488372093\n",
      "precision은 0.7228915662650602\n",
      "recall은 0.7142857142857143\n",
      "f1-score 은 0.718562874251497\n",
      "n_neighbors = 8 random_state = 24\n",
      "[[110  21]\n",
      " [ 29  55]]\n",
      "0.7674418604651163\n",
      "precision은 0.7236842105263158\n",
      "recall은 0.6547619047619048\n",
      "f1-score 은 0.6875\n",
      "n_neighbors = 9 random_state = 24\n",
      "[[105  26]\n",
      " [ 23  61]]\n",
      "0.772093023255814\n",
      "precision은 0.7011494252873564\n",
      "recall은 0.7261904761904762\n",
      "f1-score 은 0.7134502923976608\n",
      "n_neighbors = 5 random_state = 25\n",
      "[[109  20]\n",
      " [ 26  60]]\n",
      "0.786046511627907\n",
      "precision은 0.75\n",
      "recall은 0.6976744186046512\n",
      "f1-score 은 0.7228915662650603\n",
      "n_neighbors = 6 random_state = 25\n",
      "[[113  16]\n",
      " [ 28  58]]\n",
      "0.7953488372093023\n",
      "precision은 0.7837837837837838\n",
      "recall은 0.6744186046511628\n",
      "f1-score 은 0.725\n",
      "n_neighbors = 7 random_state = 25\n",
      "[[103  26]\n",
      " [ 25  61]]\n",
      "0.7627906976744186\n",
      "precision은 0.7011494252873564\n",
      "recall은 0.7093023255813954\n",
      "f1-score 은 0.7052023121387283\n",
      "n_neighbors = 8 random_state = 25\n",
      "[[105  24]\n",
      " [ 29  57]]\n",
      "0.7534883720930232\n",
      "precision은 0.7037037037037037\n",
      "recall은 0.6627906976744186\n",
      "f1-score 은 0.6826347305389222\n",
      "n_neighbors = 9 random_state = 25\n",
      "[[102  27]\n",
      " [ 24  62]]\n",
      "0.7627906976744186\n",
      "precision은 0.6966292134831461\n",
      "recall은 0.7209302325581395\n",
      "f1-score 은 0.7085714285714286\n",
      "n_neighbors = 5 random_state = 26\n",
      "[[114  20]\n",
      " [ 25  56]]\n",
      "0.7906976744186046\n",
      "precision은 0.7368421052631579\n",
      "recall은 0.691358024691358\n",
      "f1-score 은 0.7133757961783439\n",
      "n_neighbors = 6 random_state = 26\n",
      "[[119  15]\n",
      " [ 30  51]]\n",
      "0.7906976744186046\n",
      "precision은 0.7727272727272727\n",
      "recall은 0.6296296296296297\n",
      "f1-score 은 0.6938775510204083\n",
      "n_neighbors = 7 random_state = 26\n",
      "[[111  23]\n",
      " [ 25  56]]\n",
      "0.7767441860465116\n",
      "precision은 0.7088607594936709\n",
      "recall은 0.691358024691358\n",
      "f1-score 은 0.7\n",
      "n_neighbors = 8 random_state = 26\n",
      "[[123  11]\n",
      " [ 27  54]]\n",
      "0.8232558139534883\n",
      "precision은 0.8307692307692308\n",
      "recall은 0.6666666666666666\n",
      "f1-score 은 0.7397260273972603\n",
      "n_neighbors = 9 random_state = 26\n",
      "[[118  16]\n",
      " [ 25  56]]\n",
      "0.8093023255813954\n",
      "precision은 0.7777777777777778\n",
      "recall은 0.691358024691358\n",
      "f1-score 은 0.7320261437908497\n",
      "n_neighbors = 5 random_state = 27\n",
      "[[107  12]\n",
      " [ 32  64]]\n",
      "0.7953488372093023\n",
      "precision은 0.8421052631578947\n",
      "recall은 0.6666666666666666\n",
      "f1-score 은 0.744186046511628\n",
      "n_neighbors = 6 random_state = 27\n",
      "[[110   9]\n",
      " [ 33  63]]\n",
      "0.8046511627906977\n",
      "precision은 0.875\n",
      "recall은 0.65625\n",
      "f1-score 은 0.75\n",
      "n_neighbors = 7 random_state = 27\n",
      "[[105  14]\n",
      " [ 31  65]]\n",
      "0.7906976744186046\n",
      "precision은 0.8227848101265823\n",
      "recall은 0.6770833333333334\n",
      "f1-score 은 0.742857142857143\n",
      "n_neighbors = 8 random_state = 27\n",
      "[[108  11]\n",
      " [ 34  62]]\n",
      "0.7906976744186046\n",
      "precision은 0.8493150684931506\n",
      "recall은 0.6458333333333334\n",
      "f1-score 은 0.7337278106508875\n",
      "n_neighbors = 9 random_state = 27\n",
      "[[102  17]\n",
      " [ 33  63]]\n",
      "0.7674418604651163\n",
      "precision은 0.7875\n",
      "recall은 0.65625\n",
      "f1-score 은 0.7159090909090907\n",
      "n_neighbors = 5 random_state = 28\n",
      "[[112  26]\n",
      " [ 22  55]]\n",
      "0.7767441860465116\n",
      "precision은 0.6790123456790124\n",
      "recall은 0.7142857142857143\n",
      "f1-score 은 0.6962025316455697\n",
      "n_neighbors = 6 random_state = 28\n",
      "[[120  18]\n",
      " [ 27  50]]\n",
      "0.7906976744186046\n",
      "precision은 0.7352941176470589\n",
      "recall은 0.6493506493506493\n",
      "f1-score 은 0.6896551724137931\n",
      "n_neighbors = 7 random_state = 28\n",
      "[[113  25]\n",
      " [ 21  56]]\n",
      "0.786046511627907\n",
      "precision은 0.691358024691358\n",
      "recall은 0.7272727272727273\n",
      "f1-score 은 0.7088607594936708\n",
      "n_neighbors = 8 random_state = 28\n",
      "[[118  20]\n",
      " [ 24  53]]\n",
      "0.7953488372093023\n",
      "precision은 0.726027397260274\n",
      "recall은 0.6883116883116883\n",
      "f1-score 은 0.7066666666666667\n",
      "n_neighbors = 9 random_state = 28\n",
      "[[113  25]\n",
      " [ 22  55]]\n",
      "0.7813953488372093\n",
      "precision은 0.6875\n",
      "recall은 0.7142857142857143\n",
      "f1-score 은 0.7006369426751592\n",
      "n_neighbors = 5 random_state = 29\n",
      "[[105  19]\n",
      " [ 20  71]]\n",
      "0.8186046511627907\n",
      "precision은 0.7888888888888889\n",
      "recall은 0.7802197802197802\n",
      "f1-score 은 0.7845303867403316\n",
      "n_neighbors = 6 random_state = 29\n",
      "[[113  11]\n",
      " [ 24  67]]\n",
      "0.8372093023255814\n",
      "precision은 0.8589743589743589\n",
      "recall은 0.7362637362637363\n",
      "f1-score 은 0.7928994082840237\n",
      "n_neighbors = 7 random_state = 29\n",
      "[[106  18]\n",
      " [ 18  73]]\n",
      "0.8325581395348837\n",
      "precision은 0.8021978021978022\n",
      "recall은 0.8021978021978022\n",
      "f1-score 은 0.8021978021978022\n",
      "n_neighbors = 8 random_state = 29\n",
      "[[111  13]\n",
      " [ 22  69]]\n",
      "0.8372093023255814\n",
      "precision은 0.8414634146341463\n",
      "recall은 0.7582417582417582\n",
      "f1-score 은 0.7976878612716763\n",
      "n_neighbors = 9 random_state = 29\n",
      "[[106  18]\n",
      " [ 17  74]]\n",
      "0.8372093023255814\n",
      "precision은 0.8043478260869565\n",
      "recall은 0.8131868131868132\n",
      "f1-score 은 0.8087431693989071\n",
      "\n",
      "\n",
      "최대정확도는 :  0.8465116279069768\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1단계. csv --> 데이터 프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "print(df.head(), '\\n')\n",
    "\n",
    "# 2.1 결측치를 확인하고 제거하거나 치환한다.\n",
    "# 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "print(df.info()) # 자료형 확인하는 방법\n",
    "print('\\n')\n",
    "\n",
    "# 2.2 결측치(NaN)을 확인한다.\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함\n",
    "# embark 와 embark_town이 같은 데이터(중복데이터)여서 컬럼을 하나 삭제해야함.\n",
    "# embark 컬럼은 삭제한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "rdf = df.drop(['deck', 'embark_town'], axis =1)\n",
    "\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든 행을 삭제한다.\n",
    "# age 열에 891개의 행중에 177개가 NaN값\n",
    "\n",
    "rdf = rdf.dropna(subset = ['age'], how='any', axis = 0)\n",
    "\n",
    "\n",
    "# 설명\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "# 2.5 embark 열의 NaN값을 승선도시중 가장 많이 출현한 값으로 치환하기.\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "\n",
    "\n",
    "# 3. 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked']]\n",
    "print(ndf.head(), '\\n')\n",
    "# 선택된 컬럼중 2개(sex, embarked)가 범주형(문자형)이다.\n",
    "\n",
    "# 3.2 범주형 데이터를 숫자로 변환(원핫 인코딩)\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix = 'town')\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis = 1 , inplace = True)\n",
    "\n",
    "\n",
    "# 4단계. 정규화\n",
    "# survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
    "# survived (종속변수 y)\n",
    "# pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S (독립변수 X)\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨)를 지정한다.\n",
    "X = ndf[['pclass','age','sibsp','parch','female','male','town_C','town_Q','town_S']] # 독립변수\n",
    "y = ndf['survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화(normalization) 한다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다. (반복문까지 추가함!!!!)\n",
    "\n",
    "u = []\n",
    "for i in range(10,30):\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = i)\n",
    "    \n",
    "    # 설명 : test_size = 0.3 에 의해서 7:3 비율로 훈련과 테스트를 나누고 \n",
    "    # random_state = 10 에 의해서 나중에 split할 때도 항상 일정하게 split 할 수 있게 한다.\n",
    "\n",
    "    \n",
    "    # 6단계. 머신러닝 모델을 생성한다.(knn을 사용)\n",
    "    for j in range(5,10):\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors= j) # n_neighbors = 5 (knn의 k값은 5) 변수\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        # 7단계. 테스트 데이터로 예측하기\n",
    "        \n",
    "        y_hat = knn.predict(X_test)\n",
    "\n",
    "   \n",
    "        # 8단계. 모형의 예측 능력을 평가한다.\n",
    "        from sklearn import metrics\n",
    "        knn_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "        print('n_neighbors =', j, 'random_state =', i)\n",
    "        print(knn_matrix)\n",
    "        \n",
    "        # 9단계 정확도 확인\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score( y_test, y_hat)\n",
    "        print(accuracy)\n",
    "\n",
    "        u.append('정확도는 ', accuracy)\n",
    "        \n",
    "        \n",
    "        # precision(정밀도) 구하는 코드\n",
    "        from sklearn.metrics import precision_score\n",
    "        precision = precision_score(y_test,y_hat)\n",
    "\n",
    "        print('precision은', precision)\n",
    " \n",
    "\n",
    "        # recall(재현율) 구하는 코드\n",
    "        from sklearn.metrics import recall_score\n",
    "        recall = recall_score(y_test,y_hat)\n",
    "\n",
    "        print('recall은', recall)\n",
    "\n",
    "\n",
    "        # f1-score 구하는 코드\n",
    "        from sklearn.metrics import f1_score\n",
    "        f1 = f1_score(y_test,y_hat)\n",
    "\n",
    "        print('f1-score 은' ,f1)\n",
    "\n",
    "print('\\n')\n",
    "print('최대정확도는 : ', max(u))\n",
    "        \n",
    "\n",
    "# 정확도 : (109 + 65) / (109 + 16 + 25 + 65)\n",
    "# 정확도 100%는 현실적으로 나오기 힘드니 (예측: 생존 , 실제: 사망 데이터인 25를 0으로 만드는 것을 궁극적으로 추구한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제191. 유방암 데이터의 악성종양을 예측하는 머신러닝 모델을 생성하시오~\n",
    "### 지금까지 배운 8단계를 그대로 적용해서 수행하세요~\n",
    "\n",
    "__데이터 게시판 :__   \n",
    "54번. 유방암 데이터\n",
    "\n",
    "__데이터 설명 :__   \n",
    "Wisconsin Hospital의 병원 데이터 유방암 종양의 크기와 지름, 거칠기 등에 대한 수치   \n",
    "데이터 라벨 컬럼은 diagnosis이고 B가 양성 M이 악성임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1단계 : 데이터 프레임 생성  \n",
    "dataset = pd_read_csv(\"d:\\\\data\\\\wisc_bc_data.csv\")\n",
    "\n",
    "#### 2단계 : 결측치 확인 및 처리  \n",
    "#### 3단계 : 범주형 데이터를 수치형 데이터로   \n",
    "#### 4단계 : 정규화  \n",
    "#### 5단계 : 훈련 데이터와 테스트 데이터를 나눈다.  (sklearn의 train_test_split)\n",
    "X = dataset.iloc[:, 2:].values  \n",
    "y = dataset.iloc[:, 1].values  \n",
    "\n",
    "#### 6단계 : 훈련 데이터 모델 생성  (sklearn의 KNeighborsClassifier)\n",
    "#### 7단계 : 테스트 데이터로 예측을 한다.  (sklearn의 predict)\n",
    "#### 8단계 : 모형의 예측 능력을 평가한다.  (sklearn의 confustion_matrix)\n",
    "#### 9단계 : 모델의 성능을 높인다.\n",
    "\n",
    "   - 앙상블을 이용한다.\n",
    "   - \"파생변수\"를 생성한다. (기존의 raw data로 새로운 학습 데이터를 생성해주어야한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0  87139402         B        12.32         12.39           78.85      464.1   \n",
      "1   8910251         B        10.60         18.95           69.28      346.4   \n",
      "2    905520         B        11.04         16.83           70.92      373.2   \n",
      "3    868871         B        11.28         13.39           73.00      384.8   \n",
      "4   9012568         B        15.19         13.21           97.65      711.8   \n",
      "\n",
      "   smoothness_mean  ...  area_worst  smoothness_worst  compactness_worst  \\\n",
      "0          0.10280  ...       549.1            0.1385             0.1266   \n",
      "1          0.09688  ...       424.8            0.1213             0.2515   \n",
      "2          0.10770  ...       471.4            0.1369             0.1482   \n",
      "3          0.11640  ...       434.0            0.1367             0.1822   \n",
      "4          0.07963  ...       819.1            0.1126             0.1737   \n",
      "\n",
      "   concavity_worst  points_worst  symmetry_worst  dimension_worst  \n",
      "0          0.12420       0.09391          0.2827          0.06771  \n",
      "1          0.19160       0.07926          0.2940          0.07587  \n",
      "2          0.10670       0.07431          0.2998          0.07881  \n",
      "3          0.08669       0.08611          0.2102          0.06784  \n",
      "4          0.13620       0.08178          0.2487          0.06766  \n",
      "\n",
      "[5 rows x 32 columns] \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      "id                   569 non-null int64\n",
      "diagnosis            569 non-null object\n",
      "radius_mean          569 non-null float64\n",
      "texture_mean         569 non-null float64\n",
      "perimeter_mean       569 non-null float64\n",
      "area_mean            569 non-null float64\n",
      "smoothness_mean      569 non-null float64\n",
      "compactness_mean     569 non-null float64\n",
      "concavity_mean       569 non-null float64\n",
      "points_mean          569 non-null float64\n",
      "symmetry_mean        569 non-null float64\n",
      "dimension_mean       569 non-null float64\n",
      "radius_se            569 non-null float64\n",
      "texture_se           569 non-null float64\n",
      "perimeter_se         569 non-null float64\n",
      "area_se              569 non-null float64\n",
      "smoothness_se        569 non-null float64\n",
      "compactness_se       569 non-null float64\n",
      "concavity_se         569 non-null float64\n",
      "points_se            569 non-null float64\n",
      "symmetry_se          569 non-null float64\n",
      "dimension_se         569 non-null float64\n",
      "radius_worst         569 non-null float64\n",
      "texture_worst        569 non-null float64\n",
      "perimeter_worst      569 non-null float64\n",
      "area_worst           569 non-null float64\n",
      "smoothness_worst     569 non-null float64\n",
      "compactness_worst    569 non-null float64\n",
      "concavity_worst      569 non-null float64\n",
      "points_worst         569 non-null float64\n",
      "symmetry_worst       569 non-null float64\n",
      "dimension_worst      569 non-null float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n",
      "None\n",
      "\n",
      "\n",
      "id                   0\n",
      "diagnosis            0\n",
      "radius_mean          0\n",
      "texture_mean         0\n",
      "perimeter_mean       0\n",
      "area_mean            0\n",
      "smoothness_mean      0\n",
      "compactness_mean     0\n",
      "concavity_mean       0\n",
      "points_mean          0\n",
      "symmetry_mean        0\n",
      "dimension_mean       0\n",
      "radius_se            0\n",
      "texture_se           0\n",
      "perimeter_se         0\n",
      "area_se              0\n",
      "smoothness_se        0\n",
      "compactness_se       0\n",
      "concavity_se         0\n",
      "points_se            0\n",
      "symmetry_se          0\n",
      "dimension_se         0\n",
      "radius_worst         0\n",
      "texture_worst        0\n",
      "perimeter_worst      0\n",
      "area_worst           0\n",
      "smoothness_worst     0\n",
      "compactness_worst    0\n",
      "concavity_worst      0\n",
      "points_worst         0\n",
      "symmetry_worst       0\n",
      "dimension_worst      0\n",
      "dtype: int64 \n",
      "\n",
      "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
      "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'points_mean', 'symmetry_mean', 'dimension_mean', 'radius_se',\n",
      "       'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'points_se', 'symmetry_se',\n",
      "       'dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst',\n",
      "       'area_worst', 'smoothness_worst', 'compactness_worst',\n",
      "       'concavity_worst', 'points_worst', 'symmetry_worst', 'dimension_worst'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0         B        12.32         12.39           78.85      464.1   \n",
      "1         B        10.60         18.95           69.28      346.4   \n",
      "2         B        11.04         16.83           70.92      373.2   \n",
      "3         B        11.28         13.39           73.00      384.8   \n",
      "4         B        15.19         13.21           97.65      711.8   \n",
      "\n",
      "   smoothness_mean  compactness_mean  ...  area_worst  smoothness_worst  \\\n",
      "0          0.10280           0.06981  ...       549.1            0.1385   \n",
      "1          0.09688           0.11470  ...       424.8            0.1213   \n",
      "2          0.10770           0.07804  ...       471.4            0.1369   \n",
      "3          0.11640           0.11360  ...       434.0            0.1367   \n",
      "4          0.07963           0.06934  ...       819.1            0.1126   \n",
      "\n",
      "   compactness_worst  concavity_worst  points_worst  symmetry_worst  \\\n",
      "0             0.1266          0.12420       0.09391          0.2827   \n",
      "1             0.2515          0.19160       0.07926          0.2940   \n",
      "2             0.1482          0.10670       0.07431          0.2998   \n",
      "3             0.1822          0.08669       0.08611          0.2102   \n",
      "4             0.1737          0.13620       0.08178          0.2487   \n",
      "\n",
      "   dimension_worst  \n",
      "0          0.06771  \n",
      "1          0.07587  \n",
      "2          0.07881  \n",
      "3          0.06784  \n",
      "4          0.06766  \n",
      "\n",
      "[5 rows x 31 columns] \n",
      "\n",
      "[[-0.51329651 -1.60559452 -0.54037561 ... -0.31513306 -0.11932056\n",
      "  -0.89972108]\n",
      " [-1.00180093 -0.07903849 -0.93456583 ... -0.53820271  0.06348865\n",
      "  -0.44752801]\n",
      " [-0.87683468 -0.57237672 -0.8670139  ... -0.61357437  0.15731992\n",
      "  -0.28460551]\n",
      " ...\n",
      " [ 0.32738551  0.72612674  0.28631171 ...  0.12171802  0.44366709\n",
      "   0.7633076 ]\n",
      " [ 0.11437486 -1.23559085  0.07788929 ... -0.11733956 -0.47685008\n",
      "  -0.32395074]\n",
      " [ 2.05703196 -0.97495933  2.03195239 ...  1.24848623 -0.27624528\n",
      "   0.15040866]]\n",
      "\n",
      "\n",
      "train data 의 갯수: (398, 30)\n",
      "test data 의 갯수: (171, 30)\n",
      "\n",
      "\n",
      "['B' 'M' 'M' 'B' 'M' 'B' 'M' 'B' 'B' 'B']\n",
      "\n",
      "\n",
      "[[108   1]\n",
      " [  8  54]]\n",
      "\n",
      "\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1단계. csv --> 데이터 프레임으로 변환\n",
    "df = pd.read_csv(\"d:\\\\data\\\\wisc_bc_data.csv\")\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "print(df.head(), '\\n')\n",
    "\n",
    "\n",
    "print(df.info())\n",
    "print('\\n') \n",
    "\n",
    "\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "print(df.columns)\n",
    "print('\\n')\n",
    "\n",
    "# 2. 결측치를 제거하거나 치환 (결측치 값이 모든 열에 없기 때문에 과정 생략)\n",
    "# 3. 범주형 데이터를 숫자형으로 변환하기 (문자로 나타나진 값이없어서 과정 생략)\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "ndf = df[['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'points_mean', 'symmetry_mean', 'dimension_mean', 'radius_se',\n",
    "       'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'points_se', 'symmetry_se',\n",
    "       'dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst',\n",
    "       'area_worst', 'smoothness_worst', 'compactness_worst',\n",
    "       'concavity_worst', 'points_worst', 'symmetry_worst', 'dimension_worst']]\n",
    "print(ndf.head(), '\\n')\n",
    "\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨)를 지정한다.\n",
    "X = ndf[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'points_mean', 'symmetry_mean', 'dimension_mean', 'radius_se',\n",
    "       'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'points_se', 'symmetry_se',\n",
    "       'dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst',\n",
    "       'area_worst', 'smoothness_worst', 'compactness_worst',\n",
    "       'concavity_worst', 'points_worst', 'symmetry_worst', 'dimension_worst']] # 독립변수\n",
    "\n",
    "y = ndf['diagnosis'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화(normalization) 한다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "print(X)\n",
    "print('\\n')\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 15)\n",
    "\n",
    "# 설명 : test_size = 0.3 에 의해서 7:3 비율로 훈련과 테스트를 나누고 \n",
    "# random_state = 10 에 의해서 나중에 split할 때도 항상 일정하게 split 할 수 있게 한다.\n",
    "\n",
    "print('train data 의 갯수:', X_train.shape) # (499,9)\n",
    "print('test data 의 갯수:', X_test.shape) # (215, 9)\n",
    "print('\\n')\n",
    "\n",
    "# 6단계. 머신러닝 모델을 생성한다.(knn을 사용)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=28) # n_neighbors = 5 (knn의 k값은 5) 변수\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 7단계. 테스트 데이터로 예측하기\n",
    "\n",
    "y_hat = knn.predict(X_test)\n",
    "print(y_hat[0:10])\n",
    "print('\\n')\n",
    "\n",
    "# 8단계. 모형의 예측 능력을 평가한다.\n",
    "from sklearn import metrics\n",
    "knn_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "print(knn_matrix)\n",
    "print('\\n')\n",
    "\n",
    "# 9단계 정확도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
