{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 11장 . 의사결정트리\n",
    "\n",
    "\n",
    "### 머신러닝의 종류 3가지\n",
    "\n",
    "1. 지도학습 \n",
    "    - 분류 : knn, 나이브베이즈, 의사결정트리\n",
    "    - 회귀 \n",
    "    \n",
    "    \n",
    "2. 비지도학습 \n",
    "3. 강화학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 의사결정트리란?\n",
    "\n",
    "__Decision Tree 는 의사결정 나무__라는 뜻입니다. 컴퓨터 알고리즘에 즐겨사용하는 __트리(tree)구조__를 사용하고,   \n",
    "각 분기점(node)에는 분석 대상의 속성(설명변수)들이 위치한다.    \n",
    "각 분기점 마다 목표값을 가장 잘 분류할 수 있는 속성을 찾아서 배치하고, 해당 속성이 갖는 값을 이용하여 __새로운 가지(branch)__를 만든다.  \n",
    "각 분기점에서 최저의 속성을 선택할 때는 해당 속성을 기준으로 분류한 값들이 구분되는 정도를 측정한다.  \n",
    "다른 종류의 값들이 섞여 있는 정도를 나타내느 __엔트로피(entropy)__를 활용하여 __엔트로피가 낮을 수록 분류가 잘된것__이고   \n",
    "엔트로피가 일정 수준 이하로 낮아질때까지 앞의 과정을 반복합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 의사결정트리 파이썬 코드 예제\n",
    "\n",
    "\" 유방암 데이터의 악성종양과 양성종양을 예측하는 머신러닝 모델 생성 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  clump  cell_size  cell_shape  adhesion  epithlial bare_nuclei  \\\n",
      "0    1000025      5          1           1         1          2           1   \n",
      "1    1002945      5          4           4         5          7          10   \n",
      "2    1015425      3          1           1         1          2           2   \n",
      "3    1016277      6          8           8         1          3           4   \n",
      "4    1017023      4          1           1         3          2           1   \n",
      "..       ...    ...        ...         ...       ...        ...         ...   \n",
      "694   776715      3          1           1         1          3           2   \n",
      "695   841769      2          1           1         1          2           1   \n",
      "696   888820      5         10          10         3          7           3   \n",
      "697   897471      4          8           6         4          3           4   \n",
      "698   897471      4          8           8         5          4           5   \n",
      "\n",
      "     chromatin  normal_nucleoli  mitoses  class  \n",
      "0            3                1        1      2  \n",
      "1            3                2        1      2  \n",
      "2            3                1        1      2  \n",
      "3            3                7        1      2  \n",
      "4            3                1        1      2  \n",
      "..         ...              ...      ...    ...  \n",
      "694          1                1        1      2  \n",
      "695          1                1        1      2  \n",
      "696          8               10        2      4  \n",
      "697         10                6        1      4  \n",
      "698         10                4        1      4  \n",
      "\n",
      "[699 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제196. 위의 컬럼이 모두다 나오게 설정하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  clump  cell_size  cell_shape  adhesion  epithlial bare_nuclei  \\\n",
      "0    1000025      5          1           1         1          2           1   \n",
      "1    1002945      5          4           4         5          7          10   \n",
      "2    1015425      3          1           1         1          2           2   \n",
      "3    1016277      6          8           8         1          3           4   \n",
      "4    1017023      4          1           1         3          2           1   \n",
      "..       ...    ...        ...         ...       ...        ...         ...   \n",
      "694   776715      3          1           1         1          3           2   \n",
      "695   841769      2          1           1         1          2           1   \n",
      "696   888820      5         10          10         3          7           3   \n",
      "697   897471      4          8           6         4          3           4   \n",
      "698   897471      4          8           8         5          4           5   \n",
      "\n",
      "     chromatin  normal_nucleoli  mitoses  class  \n",
      "0            3                1        1      2  \n",
      "1            3                2        1      2  \n",
      "2            3                1        1      2  \n",
      "3            3                7        1      2  \n",
      "4            3                1        1      2  \n",
      "..         ...              ...      ...    ...  \n",
      "694          1                1        1      2  \n",
      "695          1                1        1      2  \n",
      "696          8               10        2      4  \n",
      "697         10                6        1      4  \n",
      "698         10                4        1      4  \n",
      "\n",
      "[699 rows x 11 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "print(df)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 의사결정 머신러닝 모델을 생성하려면 데이터가 전부 숫자형이어야 하므로 숫자형인지 확인해보아야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제197. 유방암 데이터프레임의 구조를 확인해서 데이터 타입이 전부 숫자형인지 확인하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      "id                 699 non-null int64\n",
      "clump              699 non-null int64\n",
      "cell_size          699 non-null int64\n",
      "cell_shape         699 non-null int64\n",
      "adhesion           699 non-null int64\n",
      "epithlial          699 non-null int64\n",
      "bare_nuclei        699 non-null object\n",
      "chromatin          699 non-null int64\n",
      "normal_nucleoli    699 non-null int64\n",
      "mitoses            699 non-null int64\n",
      "class              699 non-null int64\n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제198. 유일하게 숫자형이 아닌 brae_nuclei 컬럼을 숫자형으로 변환하시오!( 힌트 : astype )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')\n",
    "\n",
    "print(df.info()) \n",
    "\n",
    "# 오류 뜸\n",
    "# ValueError: invalid literal for int() with base 10: '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제199. bare_nuclie 데이터 안에 ?가 있어서 숫자형으로 변환되지 않으므로 ?를 NaN으로 replace하고 누락데이터행을 삭제하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 683 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      "id                 683 non-null int64\n",
      "clump              683 non-null int64\n",
      "cell_size          683 non-null int64\n",
      "cell_shape         683 non-null int64\n",
      "adhesion           683 non-null int64\n",
      "epithlial          683 non-null int64\n",
      "bare_nuclei        683 non-null int32\n",
      "chromatin          683 non-null int64\n",
      "normal_nucleoli    683 non-null int64\n",
      "mitoses            683 non-null int64\n",
      "class              683 non-null int64\n",
      "dtypes: int32(1), int64(10)\n",
      "memory usage: 61.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace = True)\n",
    "df.dropna(subset = ['bare_nuclei'], axis = 0, inplace = True)\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')\n",
    "\n",
    "print(df.info()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제200. 독립변수(설명변수)와 종속변수(예측변수)로 데이터를 나누시오~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
      "       'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses', 'class'],\n",
      "      dtype='object')\n",
      "0      2\n",
      "1      2\n",
      "2      2\n",
      "3      2\n",
      "4      2\n",
      "      ..\n",
      "694    2\n",
      "695    2\n",
      "696    4\n",
      "697    4\n",
      "698    4\n",
      "Name: class, Length: 683, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace = True)\n",
    "df.dropna(subset = ['bare_nuclei'], axis = 0, inplace = True)\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "X = df[['clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "       'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses']] # 설명변수\n",
    "\n",
    "y = df['class'] # 예측변수\n",
    "\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제201. 설명변수 데이터를 정규화 하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace = True)\n",
    "df.dropna(subset = ['bare_nuclei'], axis = 0, inplace = True)\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')\n",
    "\n",
    "\n",
    "X = df[['clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "       'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses']] # 설명변수\n",
    "\n",
    "y = df['class'] # 예측변수\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제202. 기존 데이터를 훈련 데이터와 테스트 데이터로 7:3 비율로 나누시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 코드\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace = True)\n",
    "df.dropna(subset = ['bare_nuclei'], axis = 0, inplace = True)\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')\n",
    "\n",
    "\n",
    "X = df[['clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "       'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses']] # 설명변수\n",
    "\n",
    "y = df['class'] # 예측변수\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 10)\n",
    "\n",
    "print('train data 의 갯수:', X_train.shape) # (499, 9)\n",
    "print('test data 의 갯수:', X_test.shape) # (215, 9)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제203. 전처리한 데이터를 의사결정트리 모델에 넣어 예측하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4 4 2 2 4 4]\n",
      "[4 4 4 4 4 4 2 2 4 4]\n"
     ]
    }
   ],
   "source": [
    "# 추가 코드\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 5)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ※ 설명 :   \n",
    "분류 정도를 평가하는 기준으로 __'entrophy'값__을 사용한다.   \n",
    "트리레벨을 5로 지정하여 5단계까지 가지를 확장할 수 있게 하겠다.  \n",
    "레벨이 많아질수록 모형학습에 사용하는 훈련데이터에 대한 예측은 정확해진다.  \n",
    "하지만 모형이 훈련 데이터에 대해서만 지나치게 최적화 되어서 실제 데이터의 예측 능력은 떨어지는 문제가 발생한다.(Overfitting)  \n",
    "그래서 __적절한 레벨값__을 찾는것이 중요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 의 갯수: (478, 9)\n",
      "test data 의 갯수: (205, 9)\n",
      "\n",
      "\n",
      "[4 4 4 4 4 4 2 2 4 4]\n",
      "[4 4 4 4 4 4 2 2 4 4]\n"
     ]
    }
   ],
   "source": [
    "# Full Code.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace = True)\n",
    "df.dropna(subset = ['bare_nuclei'], axis = 0, inplace = True)\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')\n",
    "\n",
    "\n",
    "X = df[['clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "       'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses']] # 설명변수\n",
    "\n",
    "y = df['class'] # 예측변수\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 10)\n",
    "\n",
    "print('train data 의 갯수:', X_train.shape) # (499, 9)\n",
    "print('test data 의 갯수:', X_test.shape) # (215, 9)\n",
    "print('\\n')\n",
    "\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 5)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제204. 혼동행렬을 그려서 의사결정트리의 성능을 확인하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127   4]\n",
      " [  2  72]]\n"
     ]
    }
   ],
   "source": [
    "# 추가 코드\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "print(tree_matrix)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test,y_hat).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Code.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace = True)\n",
    "df.dropna(subset = ['bare_nuclei'], axis = 0, inplace = True)\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')\n",
    "\n",
    "\n",
    "X = df[['clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "       'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses']] # 설명변수\n",
    "\n",
    "y = df['class'] # 예측변수\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 10)\n",
    "\n",
    "print('train data 의 갯수:', X_train.shape) # (499, 9)\n",
    "print('test data 의 갯수:', X_test.shape) # (215, 9)\n",
    "print('\\n')\n",
    "\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 5)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "\n",
    "# 추가 코드\n",
    "from sklearn import metrics\n",
    "\n",
    "tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "print(tree_matrix)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test,y_hat).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.97      0.98       131\n",
      "           4       0.95      0.97      0.96        74\n",
      "\n",
      "    accuracy                           0.97       205\n",
      "   macro avg       0.97      0.97      0.97       205\n",
      "weighted avg       0.97      0.97      0.97       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f1 - score 추가\n",
    "\n",
    "tree_report = metrics.classification_report(y_test,y_hat)\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Code.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace = True)\n",
    "df.dropna(subset = ['bare_nuclei'], axis = 0, inplace = True)\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')\n",
    "\n",
    "\n",
    "X = df[['clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "       'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses']] # 설명변수\n",
    "\n",
    "y = df['class'] # 예측변수\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 10)\n",
    "\n",
    "print('train data 의 갯수:', X_train.shape) # (499, 9)\n",
    "print('test data 의 갯수:', X_test.shape) # (215, 9)\n",
    "print('\\n')\n",
    "\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 5)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "\n",
    "# 추가 코드\n",
    "from sklearn import metrics\n",
    "\n",
    "tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "print(tree_matrix)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test,y_hat).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "\n",
    "# f1 - score 추가\n",
    "\n",
    "tree_report = metrics.classification_report(y_test,y_hat)\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드 정리\n",
    "\n",
    "1. 전처리 작업  \n",
    "?를 결측치로 치환하고 결측치 제거 (699개를 행에서 16개의 행을 삭제하고 683개의 행으로 훈련)  \n",
    "문자형 --> 숫자형\n",
    "\n",
    "2. 전처리 작업\n",
    "정규화 작업 수행  \n",
    "\n",
    "3. 모델 : 의사결정트리 모델(엔진 : entropy, random_state = 33, max_depth = 3)\n",
    "\n",
    "4. accuracy = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 악성종양 코드 변수를 바꾸어서 정확도 0.98까지 올려본 코드\n",
    "# Full Code.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace = True)\n",
    "df.dropna(subset = ['bare_nuclei'], axis = 0, inplace = True)\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')\n",
    "\n",
    "\n",
    "X = df[['clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "       'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses']] # 설명변수\n",
    "\n",
    "y = df['class'] # 예측변수\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 33)\n",
    "\n",
    "print('train data 의 갯수:', X_train.shape) # (499, 9)\n",
    "print('test data 의 갯수:', X_test.shape) # (215, 9)\n",
    "print('\\n')\n",
    "\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 3)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "\n",
    "# 추가 코드\n",
    "from sklearn import metrics\n",
    "\n",
    "tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "print(tree_matrix)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test,y_hat).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "\n",
    "# f1 - score 추가\n",
    "\n",
    "tree_report = metrics.classification_report(y_test,y_hat)\n",
    "print(tree_report)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat).round(5)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제205. skin.csv 데이터를 가지고 쿠폰 반응이 있는 고객과 없는 고객을 예측하는 의사결정트리 모델을 생성하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cust_no  gender  age  job marry  car cupon_react\n",
      "0         1    male   30   NO   YES   NO          NO\n",
      "1         2  female   20  YES   YES  YES          NO\n",
      "2         3  female   20  YES   YES   NO          NO\n",
      "3         4  female   40   NO    NO   NO          NO\n",
      "4         5  female   30   NO   YES   NO          NO\n",
      "5         6  female   30   NO    NO  YES          NO\n",
      "6         7  female   20   NO   YES   NO          NO\n",
      "7         8  female   20   NO   YES  YES         YES\n",
      "8         9  female   30  YES   YES   NO         YES\n",
      "9        10    male   40  YES    NO  YES         YES\n",
      "10       11    male   20   NO    NO   NO          NO\n",
      "11       12    male   30   NO   YES  YES          NO\n",
      "12       13    male   20  YES    NO   NO          NO\n",
      "13       14  female   30  YES   YES   NO         YES\n",
      "14       15    male   30  YES   YES  YES         YES\n",
      "15       16  female   30  YES    NO   NO          NO\n",
      "16       17  female   30   NO   YES  YES         YES\n",
      "17       18    male   20  YES   YES   NO          NO\n",
      "18       19    male   40  YES    NO  YES          NO\n",
      "19       20  female   40  YES   YES   NO         YES\n",
      "20       21  female   20   NO   YES  YES         YES\n",
      "21       22    male   30   NO    NO   NO          NO\n",
      "22       23  female   30  YES   YES   NO         YES\n",
      "23       24    male   30  YES    NO  YES          NO\n",
      "24       25  female   40   NO   YES  YES         YES\n",
      "25       26    male   30   NO   YES   NO          NO\n",
      "26       27  female   30  YES   YES  YES         YES\n",
      "27       28  female   40  YES    NO  YES          NO\n",
      "28       29    male   40  YES   YES   NO         YES\n",
      "29       30  female   40  YES   YES   NO         YES\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 7 columns):\n",
      "cust_no        30 non-null int64\n",
      "gender         30 non-null object\n",
      "age            30 non-null int64\n",
      "job            30 non-null object\n",
      "marry          30 non-null object\n",
      "car            30 non-null object\n",
      "cupon_react    30 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 1.8+ KB\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 악성종양 코드 변수를 바꾸어서 정확도 0.98까지 올려본 코드\n",
    "# Full Code.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "df = pd.read_csv(\"d:\\\\data\\\\skin.csv\", encoding = 'cp949') # 한글이 있기때문에 cp949 로 encoding을 해주어야한다.\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "print(df.info())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 작업 : 문자 ---> 숫자(더미변수 생성)\n",
    "예 : df['gender'] = pd.get_dummies(df['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cust_no  gender  age  job marry  car cupon_react\n",
      "0         1    male   30   NO   YES   NO          NO\n",
      "1         2  female   20  YES   YES  YES          NO\n",
      "2         3  female   20  YES   YES   NO          NO\n",
      "3         4  female   40   NO    NO   NO          NO\n",
      "4         5  female   30   NO   YES   NO          NO\n",
      "5         6  female   30   NO    NO  YES          NO\n",
      "6         7  female   20   NO   YES   NO          NO\n",
      "7         8  female   20   NO   YES  YES         YES\n",
      "8         9  female   30  YES   YES   NO         YES\n",
      "9        10    male   40  YES    NO  YES         YES\n",
      "10       11    male   20   NO    NO   NO          NO\n",
      "11       12    male   30   NO   YES  YES          NO\n",
      "12       13    male   20  YES    NO   NO          NO\n",
      "13       14  female   30  YES   YES   NO         YES\n",
      "14       15    male   30  YES   YES  YES         YES\n",
      "15       16  female   30  YES    NO   NO          NO\n",
      "16       17  female   30   NO   YES  YES         YES\n",
      "17       18    male   20  YES   YES   NO          NO\n",
      "18       19    male   40  YES    NO  YES          NO\n",
      "19       20  female   40  YES   YES   NO         YES\n",
      "20       21  female   20   NO   YES  YES         YES\n",
      "21       22    male   30   NO    NO   NO          NO\n",
      "22       23  female   30  YES   YES   NO         YES\n",
      "23       24    male   30  YES    NO  YES          NO\n",
      "24       25  female   40   NO   YES  YES         YES\n",
      "25       26    male   30   NO   YES   NO          NO\n",
      "26       27  female   30  YES   YES  YES         YES\n",
      "27       28  female   40  YES    NO  YES          NO\n",
      "28       29    male   40  YES   YES   NO         YES\n",
      "29       30  female   40  YES   YES   NO         YES\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 7 columns):\n",
      "cust_no        30 non-null int64\n",
      "gender         30 non-null object\n",
      "age            30 non-null int64\n",
      "job            30 non-null object\n",
      "marry          30 non-null object\n",
      "car            30 non-null object\n",
      "cupon_react    30 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 1.8+ KB\n",
      "None\n",
      "\n",
      "\n",
      "Index(['cust_no', 'gender', 'age', 'job', 'marry', 'car', 'cupon_react'], dtype='object')\n",
      "    cust_no  gender  age  job  marry  car  cupon_react\n",
      "0         1       0   30    1      0    1            1\n",
      "1         2       1   20    0      0    0            1\n",
      "2         3       1   20    0      0    1            1\n",
      "3         4       1   40    1      1    1            1\n",
      "4         5       1   30    1      0    1            1\n",
      "5         6       1   30    1      1    0            1\n",
      "6         7       1   20    1      0    1            1\n",
      "7         8       1   20    1      0    0            0\n",
      "8         9       1   30    0      0    1            0\n",
      "9        10       0   40    0      1    0            0\n",
      "10       11       0   20    1      1    1            1\n",
      "11       12       0   30    1      0    0            1\n",
      "12       13       0   20    0      1    1            1\n",
      "13       14       1   30    0      0    1            0\n",
      "14       15       0   30    0      0    0            0\n",
      "15       16       1   30    0      1    1            1\n",
      "16       17       1   30    1      0    0            0\n",
      "17       18       0   20    0      0    1            1\n",
      "18       19       0   40    0      1    0            1\n",
      "19       20       1   40    0      0    1            0\n",
      "20       21       1   20    1      0    0            0\n",
      "21       22       0   30    1      1    1            1\n",
      "22       23       1   30    0      0    1            0\n",
      "23       24       0   30    0      1    0            1\n",
      "24       25       1   40    1      0    0            0\n",
      "25       26       0   30    1      0    1            1\n",
      "26       27       1   30    0      0    0            0\n",
      "27       28       1   40    0      1    0            1\n",
      "28       29       0   40    0      0    1            0\n",
      "29       30       1   40    0      0    1            0\n",
      "train data 의 갯수: (21, 5)\n",
      "test data 의 갯수: (9, 5)\n",
      "\n",
      "\n",
      "[0 1 0 0 1 1 1 0 0]\n",
      "[0 1 0 0 1 1 1 0 0]\n",
      "[[5 0]\n",
      " [0 4]]\n",
      "5 0 0 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 악성종양 코드 변수를 바꾸어서 정확도 0.98까지 올려본 코드\n",
    "# Full Code.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "df = pd.read_csv(\"d:\\\\data\\\\skin.csv\", encoding = 'cp949') # 한글이 있기때문에 cp949 로 encoding을 해주어야한다.\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "df['gender'] = pd.get_dummies(df['gender'])\n",
    "df['job'] = pd.get_dummies(df['job'])\n",
    "df['marry'] = pd.get_dummies(df['marry'])\n",
    "df['car'] = pd.get_dummies(df['car'])\n",
    "df['cupon_react'] = pd.get_dummies(df['cupon_react'])\n",
    "\n",
    "X = df[['gender', 'age', 'job', 'marry', 'car']] # 설명변수\n",
    "\n",
    "y = df['cupon_react'] # 예측변수\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 34)\n",
    "\n",
    "print('train data 의 갯수:', X_train.shape) # (499, 9)\n",
    "print('test data 의 갯수:', X_test.shape) # (215, 9)\n",
    "print('\\n')\n",
    "\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 3)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "\n",
    "# 추가 코드\n",
    "from sklearn import metrics\n",
    "\n",
    "tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "print(tree_matrix)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test,y_hat).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "\n",
    "# f1 - score 추가\n",
    "\n",
    "tree_report = metrics.classification_report(y_test,y_hat)\n",
    "print(tree_report)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat).round(5)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제206. (점심시간 문제) seaborn의 타이타닉 데이터의 생존자/사망자를 예측하는 의사결정트리 모델을 생성하고 혼동행렬을 출력하여 검사받으시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True   \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 16 columns):\n",
      "survived       891 non-null int64\n",
      "pclass         891 non-null int64\n",
      "sex            891 non-null object\n",
      "age            714 non-null float64\n",
      "sibsp          891 non-null int64\n",
      "parch          891 non-null int64\n",
      "fare           891 non-null float64\n",
      "embarked       889 non-null object\n",
      "class          891 non-null category\n",
      "who            891 non-null object\n",
      "adult_male     891 non-null bool\n",
      "deck           203 non-null category\n",
      "embark_town    889 non-null object\n",
      "alive          891 non-null object\n",
      "alone          891 non-null bool\n",
      "child_women    891 non-null int32\n",
      "dtypes: bool(2), category(2), float64(2), int32(1), int64(4), object(5)\n",
      "memory usage: 84.1+ KB\n",
      "None\n",
      "\n",
      "\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "child_women      0\n",
      "dtype: int64 \n",
      "\n",
      "['survived' 'pclass' 'sex' 'age' 'sibsp' 'parch' 'fare' 'embarked' 'class'\n",
      " 'who' 'adult_male' 'alive' 'alone' 'child_women'] \n",
      "\n",
      "714 \n",
      "\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "alive          0\n",
      "alone          0\n",
      "child_women    0\n",
      "dtype: int64 \n",
      "\n",
      "   survived  pclass     sex   age  sibsp  parch embarked  child_women\n",
      "0         0       3    male  22.0      1      0        S            0\n",
      "1         1       1  female  38.0      1      0        C            1\n",
      "2         1       3  female  26.0      0      0        S            1\n",
      "3         1       1  female  35.0      1      0        S            1\n",
      "4         0       3    male  35.0      0      0        S            0 \n",
      "\n",
      "   survived  pclass   age  sibsp  parch  child_women  female  male  town_C  \\\n",
      "0         0       3  22.0      1      0            0       0     1       0   \n",
      "1         1       1  38.0      1      0            1       1     0       1   \n",
      "2         1       3  26.0      0      0            1       1     0       0   \n",
      "3         1       1  35.0      1      0            1       1     0       0   \n",
      "4         0       3  35.0      0      0            0       0     1       0   \n",
      "\n",
      "   town_Q  town_S  \n",
      "0       0       1  \n",
      "1       0       0  \n",
      "2       0       1  \n",
      "3       0       1  \n",
      "4       0       1  \n",
      "\n",
      "\n",
      "[[ 0.91123237 -0.53037664  0.52457013 ... -0.20203051  0.53307848\n",
      "  -0.83424337]\n",
      " [-1.47636364  0.57183099  0.52457013 ... -0.20203051 -1.87589641\n",
      "   1.19869098]\n",
      " [ 0.91123237 -0.25482473 -0.55170307 ... -0.20203051  0.53307848\n",
      "   1.19869098]\n",
      " ...\n",
      " [-1.47636364 -0.73704057 -0.55170307 ... -0.20203051  0.53307848\n",
      "   1.19869098]\n",
      " [-1.47636364 -0.25482473 -0.55170307 ... -0.20203051 -1.87589641\n",
      "  -0.83424337]\n",
      " [ 0.91123237  0.15850313 -0.55170307 ...  4.94974747 -1.87589641\n",
      "  -0.83424337]]\n",
      "\n",
      "\n",
      "train data 의 갯수: (499, 10)\n",
      "test data 의 갯수: (215, 10)\n",
      "\n",
      "\n",
      "[0 1 0 0 0 0 0 1 1 0]\n",
      "[0 1 1 0 0 1 0 1 1 0]\n",
      "[[135   2]\n",
      " [ 37  41]]\n",
      "\n",
      "\n",
      "135 2 37 41\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87       137\n",
      "           1       0.95      0.53      0.68        78\n",
      "\n",
      "    accuracy                           0.82       215\n",
      "   macro avg       0.87      0.76      0.78       215\n",
      "weighted avg       0.85      0.82      0.80       215\n",
      " \n",
      "\n",
      "0.8186046511627907\n"
     ]
    }
   ],
   "source": [
    "# Full code.\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1단계. csv --> 데이터 프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "print(df.head(), '\\n')\n",
    "\n",
    "mask1 = (df['age'] < 10) | (df['sex'] == 'female')\n",
    "df['child_women'] = mask1.astype(int)\n",
    "\n",
    "# 2.1 결측치를 확인하고 제거하거나 치환한다.\n",
    "# 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "print(df.info()) # 자료형 확인하는 방법\n",
    "print('\\n')\n",
    "# 2.2 결측치(NaN)을 확인한다.\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함\n",
    "# embark 와 embark_town이 같은 데이터(중복데이터)여서 컬럼을 하나 삭제해야함.\n",
    "# embark 컬럼은 삭제한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "rdf = df.drop(['deck', 'embark_town'], axis =1)\n",
    "print(rdf.columns.values, '\\n')\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든 행을 삭제한다.\n",
    "# age 열에 891개의 행중에 177개가 NaN값\n",
    "\n",
    "rdf = rdf.dropna(subset = ['age'], how='any', axis = 0)\n",
    "print(len(rdf), '\\n')\n",
    "\n",
    "# 설명\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "# 2.5 embark 열의 NaN값을 승선도시중 가장 많이 출현한 값으로 치환하기.\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 3. 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked', 'child_women']]\n",
    "print(ndf.head(), '\\n')\n",
    "# 선택된 컬럼중 2개(sex, embarked)가 범주형(문자형)이다.\n",
    "\n",
    "# 3.2 범주형 데이터를 숫자로 변환(원핫 인코딩)\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix = 'town') # 접두사를 정함.\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis = 1 , inplace = True)\n",
    "print(ndf.head())\n",
    "print('\\n')\n",
    "\n",
    "# 4단계. 정규화\n",
    "# survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
    "# survived (종속변수 y)\n",
    "# pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S (독립변수 X)\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨)를 지정한다.\n",
    "X = ndf[['pclass','age','sibsp','parch','female','male','town_C','town_Q','town_S', 'child_women']] # 독립변수\n",
    "y = ndf['survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화(normalization) 한다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "print(X)\n",
    "print('\\n')\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 17)\n",
    "\n",
    "# 설명 : test_size = 0.3 에 의해서 7:3 비율로 훈련과 테스트를 나누고 \n",
    "# random_state = 10 에 의해서 나중에 split할 때도 항상 일정하게 split 할 수 있게 한다.\n",
    "\n",
    "print('train data 의 갯수:', X_train.shape) # (499,9)\n",
    "print('test data 의 갯수:', X_test.shape) # (215, 9)\n",
    "print('\\n')\n",
    "\n",
    "# 6단계. 머신러닝 모델을 생성한다.(나이브 베이즈 분류모형을 사용)\n",
    "\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 3)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# 7단계. 테스트 데이터로 예측하기\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "\n",
    "\n",
    "# 8단계. 모형의 예측 능력을 평가한다. (confusion matrix 만들기!)\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "\"\"\"\n",
    "             예측\n",
    "           사망 생존\n",
    "실제 사망 [[109  16]\n",
    "     생존  [ 25  65]]\n",
    "     \n",
    "\"\"\"\n",
    "\n",
    "# 정확도 : (109 + 65) / (109 + 16 + 25 + 65)\n",
    "# 정확도 100%는 현실적으로 나오기 힘드니 (예측: 생존 , 실제: 사망 데이터인 25를 0으로 만드는 것을 궁극적으로 추구한다.)\n",
    "\n",
    "# confusion matrix에 대한 변수 지정 (tn,fp,fn,tp)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "print('\\n')\n",
    "\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "print(f1_report,'\\n')\n",
    "\n",
    "# 9단계 정확도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 12장. 랜덤포레스트(Random forest)\n",
    "\n",
    "### \" 의사결정트리 + 앙상블 기법 \" 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 앙상블 기법이란 ?\n",
    "\n",
    "다양한 전문가 팀을 만드는 것과 유사한 원리를 활용하는 메타학습 방법을 __앙상블__이라고 합니다.  \n",
    "앙상블 방법은 약한 학습자 여러개를 결합하면 강한 학습자가 만들어진다는 아이디어를 기반으로 합니다.  \n",
    "__앙상블 모형__은 여러개의 분류 모형을 같이 사용하여 한꺼번에 평가를 하는 모형을 말합니다.\n",
    "\n",
    "\n",
    "### ※ 예제  \n",
    "정확도가 60%밖에 되지 않는 분류기 모형들이 즐비한데 이 모형들은 최소한 몇개를 써야 정확도를 90%를 능가하게 만들 수 있을까?  \n",
    "\n",
    "Rstudio에서 r코드로 확인!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_err <- function(n,err) {\n",
    "  sum <- 0 \n",
    "  for(i in floor(n/2):n) { \n",
    "    sum <- sum + choose(n,i) * err^i * (1-err)^(n-i)\n",
    "  }\n",
    "  sum\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for(j in 1:60) {\n",
    "  err <- ret_err(j , 0.4)\n",
    "  cat(j,'--->',1-err,'\\n') \n",
    "  if(1-err >= 0.9) break\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 앙상블로 구현한 머신러닝의 종류 2가지\n",
    "\n",
    "### 1. 배깅(bagging) :   \n",
    "\n",
    "테스트 데이터 샘플링(boostrap)을 통해 여러개의 테스트 데이터를 만들고,  \n",
    "각 테스트 데이터를 이용하여 여러개의 week learner을 만들어 종합하는 앙상블의 한 종류\n",
    "\n",
    "### 2. 부스팅(boosting) : \n",
    "\n",
    "boost \"격려하다, 향상시키다\"  \n",
    "부스팅은 배깅을 약간 더 개선시킨 알고리즘인데 샘플링하는 과정에서 복원추출을 할 때 동일한 확률로 하는게 아니라   \n",
    "추출할때마다 확률을 서로 다르게 개선시키는 방법을 쓴다.  \n",
    "\n",
    "처음에는 모두 동일한 확률로 복원추출하지만  \n",
    "다음번 추출과정에서는 오분류된 데이터를 추출확률이 더 높도록 조정하고 올바르게 분류된 데이터는 추출 확률을 낮게 조정하여 복원 추출을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 랜덤 포레스트(random forests)란?\n",
    "\n",
    "### decision tree 와 bagging을 결합한 알고리즘이다!!! (decision tree + bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 랜덤 포레스트는 의사결정트리가 여러개 이다. 이 여러개가 결합해서 강한 학습자가 되는 구조이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree_model = RandomForestClassifier(n_estimators = 100, oob_score = True, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 설명\n",
    "\n",
    "#### 1. n_estimaors = 100 (생성할 tree(약한학습자)를 100개로 하겠다.)\n",
    "\n",
    "#### 2. oob_score = True ( out of bag 기능을 사용하겠다.)\n",
    "\n",
    "out of back --> 100개의 tree가 훈련 데이터를 사용할 때 63%를 사용하고 나머지 37%의 oob 샘플로 평가하겠다는 뜻이다!  \n",
    "앙상블 평가는 oob 평가를 평균으로 하여 얻습니다.  \n",
    "\n",
    "oob_score = True로 지정하면 훈련이 끝난후에 자동으로 oob평가를 수행합니다. 평가 결과를 보고싶으면 아래의 명령어를 쓴다.  \n",
    "print(tree_model.oob_score_)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제1. 의사결정트리만 이용하였을 때\n",
    "### 예제2. 랜덤포레스트를 사용하였을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 의 갯수: (478, 9)\n",
      "test data 의 갯수: (205, 9)\n",
      "\n",
      "\n",
      "[2 2 4 4 2 2 2 4 2 2]\n",
      "[2 2 4 4 2 2 2 4 2 2]\n",
      "[[119   3]\n",
      " [  0  83]]\n",
      "119 3 0 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      0.98      0.99       122\n",
      "           4       0.97      1.00      0.98        83\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.98      0.99      0.98       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "0.98537\n"
     ]
    }
   ],
   "source": [
    "# 예제1. 의사결정트리만 이용하였을 때\n",
    "# 악성종양 코드 변수를 바꾸어서 정확도 0.98까지 올려본 코드\n",
    "# Full Code.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace = True)\n",
    "df.dropna(subset = ['bare_nuclei'], axis = 0, inplace = True)\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')\n",
    "\n",
    "\n",
    "X = df[['clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "       'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses']] # 설명변수\n",
    "\n",
    "y = df['class'] # 예측변수\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 33)\n",
    "\n",
    "print('train data 의 갯수:', X_train.shape) # (499, 9)\n",
    "print('test data 의 갯수:', X_test.shape) # (215, 9)\n",
    "print('\\n')\n",
    "\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 3)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "\n",
    "# 추가 코드\n",
    "from sklearn import metrics\n",
    "\n",
    "tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "print(tree_matrix)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test,y_hat).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "\n",
    "# f1 - score 추가\n",
    "\n",
    "tree_report = metrics.classification_report(y_test,y_hat)\n",
    "print(tree_report)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat).round(5)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제2. 랜덤포레스트를 사용하였을 때\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree_model = RandomForestClassifier(n_estimators = 100, oob_score = True, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 의 갯수: (478, 9)\n",
      "test data 의 갯수: (205, 9)\n",
      "\n",
      "\n",
      "0.9644351464435147\n",
      "\n",
      "\n",
      "[2 2 4 4 2 2 2 4 2 2]\n",
      "[2 2 4 4 2 2 2 4 2 2]\n",
      "\n",
      "\n",
      "[[121   1]\n",
      " [  1  82]]\n",
      "\n",
      "\n",
      "121 1 1 82\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.99      0.99      0.99       122\n",
      "           4       0.99      0.99      0.99        83\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "정확도는 =  0.99024\n"
     ]
    }
   ],
   "source": [
    "# 예제1. 의사결정트리만 이용하였을 때\n",
    "# 악성종양 코드 변수를 바꾸어서 정확도 0.98까지 올려본 코드\n",
    "# Full Code.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "\n",
    "df.columns = ['id','clump','cell_size','cell_shape', 'adhesion','epithlial',\n",
    "\n",
    "              'bare_nuclei','chromatin','normal_nucleoli', 'mitoses', 'class'] \n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace = True)\n",
    "df.dropna(subset = ['bare_nuclei'], axis = 0, inplace = True)\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')\n",
    "\n",
    "\n",
    "X = df[['clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "       'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses']] # 설명변수\n",
    "\n",
    "y = df['class'] # 예측변수\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 33)\n",
    "\n",
    "print('train data 의 갯수:', X_train.shape) # (499, 9)\n",
    "print('test data 의 갯수:', X_test.shape) # (215, 9)\n",
    "print('\\n')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree_model = RandomForestClassifier(n_estimators = 100, oob_score = True, random_state = 12)\n",
    "\n",
    "\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# oob 평가\n",
    "print(tree_model.oob_score_)\n",
    "print('\\n')\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "print('\\n')\n",
    "\n",
    "# 추가 코드\n",
    "from sklearn import metrics\n",
    "\n",
    "tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test,y_hat).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "print('\\n')\n",
    "\n",
    "# f1 - score 추가\n",
    "\n",
    "tree_report = metrics.classification_report(y_test,y_hat)\n",
    "print(tree_report)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat).round(5)\n",
    "print('정확도는 = ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제207. seaborn의 타이타닉 데이터의 생존자/사망자 예측 모델을 랜덤포레스트로 구현하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True   \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 16 columns):\n",
      "survived       891 non-null int64\n",
      "pclass         891 non-null int64\n",
      "sex            891 non-null object\n",
      "age            714 non-null float64\n",
      "sibsp          891 non-null int64\n",
      "parch          891 non-null int64\n",
      "fare           891 non-null float64\n",
      "embarked       889 non-null object\n",
      "class          891 non-null category\n",
      "who            891 non-null object\n",
      "adult_male     891 non-null bool\n",
      "deck           203 non-null category\n",
      "embark_town    889 non-null object\n",
      "alive          891 non-null object\n",
      "alone          891 non-null bool\n",
      "child_women    891 non-null int32\n",
      "dtypes: bool(2), category(2), float64(2), int32(1), int64(4), object(5)\n",
      "memory usage: 84.1+ KB\n",
      "None\n",
      "\n",
      "\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "child_women      0\n",
      "dtype: int64 \n",
      "\n",
      "['survived' 'pclass' 'sex' 'age' 'sibsp' 'parch' 'fare' 'embarked' 'class'\n",
      " 'who' 'adult_male' 'alive' 'alone' 'child_women'] \n",
      "\n",
      "714 \n",
      "\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "alive          0\n",
      "alone          0\n",
      "child_women    0\n",
      "dtype: int64 \n",
      "\n",
      "   survived  pclass     sex   age  sibsp  parch embarked  child_women\n",
      "0         0       3    male  22.0      1      0        S            0\n",
      "1         1       1  female  38.0      1      0        C            1\n",
      "2         1       3  female  26.0      0      0        S            1\n",
      "3         1       1  female  35.0      1      0        S            1\n",
      "4         0       3    male  35.0      0      0        S            0 \n",
      "\n",
      "   survived  pclass   age  sibsp  parch  child_women  female  male  town_C  \\\n",
      "0         0       3  22.0      1      0            0       0     1       0   \n",
      "1         1       1  38.0      1      0            1       1     0       1   \n",
      "2         1       3  26.0      0      0            1       1     0       0   \n",
      "3         1       1  35.0      1      0            1       1     0       0   \n",
      "4         0       3  35.0      0      0            0       0     1       0   \n",
      "\n",
      "   town_Q  town_S  \n",
      "0       0       1  \n",
      "1       0       0  \n",
      "2       0       1  \n",
      "3       0       1  \n",
      "4       0       1  \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       122\n",
      "           1       0.85      0.80      0.82        93\n",
      "\n",
      "    accuracy                           0.85       215\n",
      "   macro avg       0.85      0.84      0.85       215\n",
      "weighted avg       0.85      0.85      0.85       215\n",
      " \n",
      "\n",
      "0.8511627906976744\n"
     ]
    }
   ],
   "source": [
    "# Full code.\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1단계. csv --> 데이터 프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "print(df.head(), '\\n')\n",
    "\n",
    "mask1 = (df['age'] < 10) | (df['sex'] == 'female')\n",
    "df['child_women'] = mask1.astype(int)\n",
    "\n",
    "# 2.1 결측치를 확인하고 제거하거나 치환한다.\n",
    "# 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "print(df.info()) # 자료형 확인하는 방법\n",
    "print('\\n')\n",
    "# 2.2 결측치(NaN)을 확인한다.\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함\n",
    "# embark 와 embark_town이 같은 데이터(중복데이터)여서 컬럼을 하나 삭제해야함.\n",
    "# embark 컬럼은 삭제한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "rdf = df.drop(['deck', 'embark_town'], axis =1)\n",
    "print(rdf.columns.values, '\\n')\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든 행을 삭제한다.\n",
    "# age 열에 891개의 행중에 177개가 NaN값\n",
    "\n",
    "rdf = rdf.dropna(subset = ['age'], how='any', axis = 0)\n",
    "print(len(rdf), '\\n')\n",
    "\n",
    "# 설명\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "# 2.5 embark 열의 NaN값을 승선도시중 가장 많이 출현한 값으로 치환하기.\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 3. 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked', 'child_women']]\n",
    "print(ndf.head(), '\\n')\n",
    "# 선택된 컬럼중 2개(sex, embarked)가 범주형(문자형)이다.\n",
    "\n",
    "# 3.2 범주형 데이터를 숫자로 변환(원핫 인코딩)\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix = 'town') # 접두사를 정함.\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis = 1 , inplace = True)\n",
    "print(ndf.head())\n",
    "print('\\n')\n",
    "\n",
    "# 4단계. 정규화\n",
    "# survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
    "# survived (종속변수 y)\n",
    "# pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S (독립변수 X)\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨)를 지정한다.\n",
    "X = ndf[['pclass','age','sibsp','parch','female','male','town_C','town_Q','town_S', 'child_women']] # 독립변수\n",
    "y = ndf['survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화(normalization) 한다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 14)\n",
    "\n",
    "# 설명 : test_size = 0.3 에 의해서 7:3 비율로 훈련과 테스트를 나누고 \n",
    "# random_state = 10 에 의해서 나중에 split할 때도 항상 일정하게 split 할 수 있게 한다.\n",
    "\n",
    "\n",
    "# 6단계. 머신러닝 모델을 생성한다.(랜덤 포레스트를 사용)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree_model = RandomForestClassifier(n_estimators = 29, oob_score = True, random_state = 7)\n",
    "\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# oob 평가\n",
    "\"\"\"\n",
    "print(tree_model.oob_score_)\n",
    "print('\\n')\n",
    "\"\"\"\n",
    "\n",
    "# 7단계. 테스트 데이터로 예측하기\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "\n",
    "# 8단계. 모형의 예측 능력을 평가한다. (confusion matrix 만들기!)\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "\n",
    "\"\"\"\n",
    "             예측\n",
    "           사망 생존\n",
    "실제 사망 [[109  16]\n",
    "     생존  [ 25  65]]\n",
    "     \n",
    "\"\"\"\n",
    "\n",
    "# 정확도 : (109 + 65) / (109 + 16 + 25 + 65)\n",
    "# 정확도 100%는 현실적으로 나오기 힘드니 (예측: 생존 , 실제: 사망 데이터인 25를 0으로 만드는 것을 궁극적으로 추구한다.)\n",
    "\n",
    "# confusion matrix에 대한 변수 지정 (tn,fp,fn,tp)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "\n",
    "\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "print(f1_report,'\\n')\n",
    "\n",
    "# 9단계 정확도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 랜덤 포레스트 모델의 성능을 올리기 위하여 데이터 전처리 하는 방법\n",
    "\n",
    "1. 결측치가 많은 컬럼을 삭제 -- cabin\n",
    "2. 나이의 결측치를 치환 - 최빈값으로 치환 : 0.80861 상위 6% 진입\n",
    "3. 이상치를 제거 - 운임(fare)의 이상치를 제거 : 0.81339 상위 5% 진입"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제208. seaborn의 타이타닉 데이터에서 결측치가 가장 많은 컬럼인 deck을 삭제하시오!\n",
    "\n",
    "케글의 타이타닉 데이터의 cabin 컬럼은 객실번호인데  \n",
    "시본의 타이타닉 데이터의 deck과 같은 컬럼이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      NaN\n",
      "1        C\n",
      "2      NaN\n",
      "3        C\n",
      "4      NaN\n",
      "      ... \n",
      "886    NaN\n",
      "887      B\n",
      "888    NaN\n",
      "889      C\n",
      "890    NaN\n",
      "Name: deck, Length: 891, dtype: category\n",
      "Categories (7, object): [A, B, C, D, E, F, G]\n",
      "0       NaN\n",
      "1       C85\n",
      "2       NaN\n",
      "3      C123\n",
      "4       NaN\n",
      "       ... \n",
      "886     NaN\n",
      "887     B42\n",
      "888     NaN\n",
      "889    C148\n",
      "890     NaN\n",
      "Name: Cabin, Length: 891, dtype: object\n",
      "688\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(\"titanic\")\n",
    "df2 = pd.read_csv(\"d:\\\\data\\\\tat\\\\train.csv\")\n",
    "\n",
    "print(df.deck)\n",
    "print(df2.Cabin)\n",
    "print(df.deck.isnull().sum())\n",
    "\n",
    "\n",
    "# 이미 위의 코드에 deck 컬럼을 삭제하는 코드가 구현되어 있다.( 참고만 할 것 !)\n",
    "rdf = df.drop(['deck','embark_town'], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제209. 훈련 데이터의 나이의 결측치를 최빈값으로 치환하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ※설명 : seaborn 타이타닉에서는 24살이 최빈값.\n",
    "age_freq = rdf['age'].value_counts(dropna=True).idxmax()\n",
    "print(age_freq)\n",
    "print('\\n')\n",
    "\n",
    "rdf['age'].fillna(age_freq, inplace = True)\n",
    "\n",
    "# ※설명 : seaborn 타이타닉에서는 24살이 최빈값."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "child_women      0\n",
      "dtype: int64 \n",
      "\n",
      "24.0\n",
      "\n",
      "\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "child_women      0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "891 \n",
      "\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       2\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "alive          0\n",
      "alone          0\n",
      "child_women    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "alive          0\n",
      "alone          0\n",
      "child_women    0\n",
      "dtype: int64 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       166\n",
      "           1       0.86      0.73      0.79       102\n",
      "\n",
      "    accuracy                           0.85       268\n",
      "   macro avg       0.85      0.83      0.84       268\n",
      "weighted avg       0.85      0.85      0.85       268\n",
      " \n",
      "\n",
      "0.8507462686567164\n"
     ]
    }
   ],
   "source": [
    "# 나이의 결측치를 바꾼 최빈값.\n",
    "# Full code.\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1단계. csv --> 데이터 프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "# print(df.head(), '\\n')\n",
    "\n",
    "mask1 = (df['age'] < 10) | (df['sex'] == 'female')\n",
    "df['child_women'] = mask1.astype(int)\n",
    "\n",
    "# 2.1 결측치를 확인하고 제거하거나 치환한다.\n",
    "# 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "# print(df.info()) # 자료형 확인하는 방법\n",
    "# print('\\n')\n",
    "\n",
    "# 2.2 결측치(NaN)을 확인한다.\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함\n",
    "# embark 와 embark_town이 같은 데이터(중복데이터)여서 컬럼을 하나 삭제해야함.\n",
    "# embark 컬럼은 삭제한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "rdf = df.drop(['deck', 'embark_town'], axis =1)\n",
    "# print(rdf.columns.values, '\\n')\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든 행을 삭제한다.\n",
    "# age 열에 891개의 행중에 177개가 NaN값\n",
    "\n",
    "age_freq = rdf['age'].value_counts(dropna=True).idxmax()\n",
    "print(age_freq)\n",
    "print('\\n')\n",
    "\n",
    "print(df.isnull().sum())\n",
    "print('\\n')\n",
    "\n",
    "rdf['age'].fillna(age_freq, inplace = True)\n",
    "\n",
    "print(len(rdf), '\\n')\n",
    "print(rdf.isnull().sum())\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# 2.5 embark 열의 NaN값을 승선도시중 가장 많이 출현한 값으로 치환하기.\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 3. 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked', 'child_women']]\n",
    "# print(ndf.head(), '\\n')\n",
    "# 선택된 컬럼중 2개(sex, embarked)가 범주형(문자형)이다.\n",
    "\n",
    "# 3.2 범주형 데이터를 숫자로 변환(원핫 인코딩)\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix = 'town') # 접두사를 정함.\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis = 1 , inplace = True)\n",
    "# print(ndf.head())\n",
    "# print('\\n')\n",
    "\n",
    "# 4단계. 정규화\n",
    "# survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
    "# survived (종속변수 y)\n",
    "# pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S (독립변수 X)\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨)를 지정한다.\n",
    "X = ndf[['pclass','age','sibsp','parch','female','male','town_C','town_Q','town_S', 'child_women']] # 독립변수\n",
    "y = ndf['survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화(normalization) 한다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 19)\n",
    "\n",
    "# 설명 : test_size = 0.3 에 의해서 7:3 비율로 훈련과 테스트를 나누고 \n",
    "# random_state = 10 에 의해서 나중에 split할 때도 항상 일정하게 split 할 수 있게 한다.\n",
    "\n",
    "\n",
    "# 6단계. 머신러닝 모델을 생성한다.(랜덤 포레스트를 사용)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree_model = RandomForestClassifier(n_estimators = 100, oob_score = True, random_state = 9)\n",
    "\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# oob 평가\n",
    "\"\"\"\n",
    "print(tree_model.oob_score_)\n",
    "print('\\n')\n",
    "\"\"\"\n",
    "\n",
    "# 7단계. 테스트 데이터로 예측하기\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "\n",
    "# 8단계. 모형의 예측 능력을 평가한다. (confusion matrix 만들기!)\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "\n",
    "# confusion matrix에 대한 변수 지정 (tn,fp,fn,tp)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "\n",
    "\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "print(f1_report,'\\n')\n",
    "\n",
    "# 9단계 정확도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 운임(fare)의 이상치를 제거하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제210. 운임의 이상치를 확인하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.2042079685746\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "print(df.fare.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제211. 운임 데이터의 표준편차를 확인하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.693428597180905\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "print(df.fare.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제212. 운임 데이터의 최대값, 최소값, 평균값을 한번에 출력하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    891.000000\n",
      "mean      32.204208\n",
      "std       49.693429\n",
      "min        0.000000\n",
      "25%        7.910400\n",
      "50%       14.454200\n",
      "75%       31.000000\n",
      "max      512.329200\n",
      "Name: fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "print(df.fare.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제213. 아래의 SQL을 파이썬으로 구현하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27     263.0000\n",
      "88     263.0000\n",
      "258    512.3292\n",
      "311    262.3750\n",
      "341    263.0000\n",
      "438    263.0000\n",
      "679    512.3292\n",
      "737    512.3292\n",
      "742    262.3750\n",
      "Name: fare, dtype: float64\n",
      "\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "select fare\n",
    "    from (select fare,\n",
    "                round(5*stddev(fare) over (order by null) local_std\n",
    "            from titanic)\n",
    "         )\n",
    "        \n",
    "    where fare > local_std;\n",
    "\"\"\"\n",
    "\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "local_std = df.fare.std() * 5\n",
    "result = df['fare'][df['fare']> local_std]\n",
    "\n",
    "print(result)\n",
    "print('\\n')\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제214. 위의 9명을 이상치라고 했을 때 이상치를 포함했을때의 운임 평균과 이상치를 제거했을때의 운임평균이 각각 어떻게 되는지 확인하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.2042079685746\n"
     ]
    }
   ],
   "source": [
    "# 이상치 제거전\n",
    "\n",
    "import seaborn as sns\n",
    "df1 = sns.load_dataset('titanic')\n",
    "print(df1.fare.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       7.2500\n",
      "1      71.2833\n",
      "2       7.9250\n",
      "3      53.1000\n",
      "4       8.0500\n",
      "        ...   \n",
      "886    13.0000\n",
      "887    30.0000\n",
      "888    23.4500\n",
      "889    30.0000\n",
      "890     7.7500\n",
      "Name: fare, Length: 882, dtype: float64\n",
      "29.002507596371835\n"
     ]
    }
   ],
   "source": [
    "# 이상치 제거후\n",
    "\n",
    "import seaborn as sns\n",
    "df= sns.load_dataset('titanic')\n",
    "local_std = df.fare.std() * 5 # 이상치의 조건 --> 표준편차의 5배가 되는 값\n",
    "\n",
    "result = df['fare'][df['fare'] < local_std] # 이상치를 제거하는 코드 !!\n",
    "print(result)\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제215. 운임의 이상치(9건)을 제거하고 랜덤 포레스트 모델을 생성해서 정확도를 확인하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True   \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 16 columns):\n",
      "survived       891 non-null int64\n",
      "pclass         891 non-null int64\n",
      "sex            891 non-null object\n",
      "age            714 non-null float64\n",
      "sibsp          891 non-null int64\n",
      "parch          891 non-null int64\n",
      "fare           891 non-null float64\n",
      "embarked       889 non-null object\n",
      "class          891 non-null category\n",
      "who            891 non-null object\n",
      "adult_male     891 non-null bool\n",
      "deck           203 non-null category\n",
      "embark_town    889 non-null object\n",
      "alive          891 non-null object\n",
      "alone          891 non-null bool\n",
      "child_women    891 non-null int32\n",
      "dtypes: bool(2), category(2), float64(2), int32(1), int64(4), object(5)\n",
      "memory usage: 84.1+ KB\n",
      "None\n",
      "\n",
      "\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "child_women      0\n",
      "dtype: int64 \n",
      "\n",
      "24.0\n",
      "\n",
      "\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "child_women      0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "891 \n",
      "\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       2\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "alive          0\n",
      "alone          0\n",
      "child_women    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       2\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "alive          0\n",
      "alone          0\n",
      "child_women    0\n",
      "dtype: int64 \n",
      "\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "alive          0\n",
      "alone          0\n",
      "child_women    0\n",
      "dtype: int64 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       167\n",
      "           1       0.74      0.60      0.66        98\n",
      "\n",
      "    accuracy                           0.77       265\n",
      "   macro avg       0.76      0.74      0.75       265\n",
      "weighted avg       0.77      0.77      0.77       265\n",
      " \n",
      "\n",
      "0.7735849056603774\n"
     ]
    }
   ],
   "source": [
    "# 이상치제거\n",
    "# 나이값 최빈값\n",
    "# 랜덤 포레스트\n",
    "# Full Code.ver1 (반복문 x)\n",
    "\n",
    "# 나이의 결측치를 바꾼 최빈값.\n",
    "# Full code.\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1단계. csv --> 데이터 프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "print(df.head(), '\\n')\n",
    "\n",
    "mask1 = (df['age'] < 10) | (df['sex'] == 'female')\n",
    "df['child_women'] = mask1.astype(int)\n",
    "\n",
    "# 2.1 결측치를 확인하고 제거하거나 치환한다.\n",
    "# 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "print(df.info()) # 자료형 확인하는 방법\n",
    "print('\\n')\n",
    "\n",
    "# 2.2 결측치(NaN)을 확인한다.\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함\n",
    "# embark 와 embark_town이 같은 데이터(중복데이터)여서 컬럼을 하나 삭제해야함.\n",
    "# embark 컬럼은 삭제한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "rdf = df.drop(['deck', 'embark_town'], axis =1)\n",
    "# print(rdf.columns.values, '\\n')\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든 행을 삭제한다.\n",
    "# age 열에 891개의 행중에 177개가 NaN값\n",
    "\n",
    "age_freq = rdf['age'].value_counts(dropna=True).idxmax()\n",
    "print(age_freq)\n",
    "print('\\n')\n",
    "\n",
    "print(df.isnull().sum(axis=0))\n",
    "print('\\n')\n",
    "\n",
    "rdf['age'].fillna(age_freq, inplace = True)\n",
    "\n",
    "print(len(rdf), '\\n')\n",
    "print(rdf.isnull().sum(axis=0))\n",
    "print('\\n')\n",
    "\n",
    "# 운임값(fare)의 이상치를 제거\n",
    "local_std = rdf['fare'].std() * 5\n",
    "rdf = rdf[:][rdf['fare'] < local_std]\n",
    "\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 운임값(fare)의 결측치를 최빈값으로 채움.\n",
    "fare_freq = rdf['fare'].value_counts(dropna=True).idxmax()\n",
    "rdf['fare'].fillna(fare_freq, inplace = True)\n",
    "\n",
    "\n",
    "# 2.5 embark 열의 NaN값을 승선도시중 가장 많이 출현한 값으로 치환하기.\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 3. 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked', 'child_women', 'fare']]\n",
    "# print(ndf.head(), '\\n')\n",
    "# 선택된 컬럼중 2개(sex, embarked)가 범주형(문자형)이다.\n",
    "\n",
    "# 3.2 범주형 데이터를 숫자로 변환(원핫 인코딩)\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix = 'town') # 접두사를 정함.\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis = 1 , inplace = True)\n",
    "# print(ndf.head())\n",
    "# print('\\n')\n",
    "\n",
    "# 4단계. 정규화\n",
    "# survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
    "# survived (종속변수 y)\n",
    "# pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S (독립변수 X)\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨)를 지정한다.\n",
    "X = ndf[['pclass','age','sibsp','parch','female','male','town_C','town_Q','town_S', 'child_women', 'fare']] # 독립변수\n",
    "y = ndf['survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화(normalization) 한다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 19)\n",
    "\n",
    "# 설명 : test_size = 0.3 에 의해서 7:3 비율로 훈련과 테스트를 나누고 \n",
    "# random_state = 10 에 의해서 나중에 split할 때도 항상 일정하게 split 할 수 있게 한다.\n",
    "\n",
    "\n",
    "# 6단계. 머신러닝 모델을 생성한다.(랜덤 포레스트를 사용)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree_model = RandomForestClassifier(n_estimators = 100, oob_score = True, random_state = 9)\n",
    "\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# oob 평가\n",
    "\"\"\"\n",
    "print(tree_model.oob_score_)\n",
    "print('\\n')\n",
    "\"\"\"\n",
    "\n",
    "# 7단계. 테스트 데이터로 예측하기\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "\n",
    "# 8단계. 모형의 예측 능력을 평가한다. (confusion matrix 만들기!)\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "\n",
    "# confusion matrix에 대한 변수 지정 (tn,fp,fn,tp)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "\n",
    "\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "print(f1_report,'\\n')\n",
    "\n",
    "# 9단계 정확도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 위의코드에서 반복문까지 추가해서 작성해보시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code.\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1단계. csv --> 데이터 프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "print(df.head(), '\\n')\n",
    "\n",
    "mask1 = (df['age'] < 10) | (df['sex'] == 'female')\n",
    "df['child_women'] = mask1.astype(int)\n",
    "\n",
    "# 2.1 결측치를 확인하고 제거하거나 치환한다.\n",
    "# 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "print(df.info()) # 자료형 확인하는 방법\n",
    "print('\\n')\n",
    "# 2.2 결측치(NaN)을 확인한다.\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함\n",
    "# embark 와 embark_town이 같은 데이터(중복데이터)여서 컬럼을 하나 삭제해야함.\n",
    "# embark 컬럼은 삭제한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "rdf = df.drop(['deck', 'embark_town'], axis =1)\n",
    "print(rdf.columns.values, '\\n')\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든 행을 삭제한다.\n",
    "# age 열에 891개의 행중에 177개가 NaN값\n",
    "\n",
    "age_freq = rdf['age'].value_counts(dropna=True).idxmax()\n",
    "print(age_freq)\n",
    "print('\\n')\n",
    "\n",
    "rdf['age'].fillna(age_freq, inplace = True)\n",
    "\n",
    "\n",
    "# 운임값(fare)의 이상치를 제거\n",
    "local_std = rdf['fare'].std() * 5\n",
    "rdf = rdf[:][rdf['fare'] < local_std]\n",
    "\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 운임값(fare)의 결측치를 최빈값으로 채움.\n",
    "fare_freq = rdf['fare'].value_counts(dropna=True).idxmax()\n",
    "rdf['fare'].fillna(fare_freq, inplace = True)\n",
    "\n",
    "# 설명\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "# 2.5 embark 열의 NaN값을 승선도시중 가장 많이 출현한 값으로 치환하기.\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 3. 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked', 'child_women', 'fare']]\n",
    "print(ndf.head(), '\\n')\n",
    "# 선택된 컬럼중 2개(sex, embarked)가 범주형(문자형)이다.\n",
    "\n",
    "# 3.2 범주형 데이터를 숫자로 변환(원핫 인코딩)\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix = 'town') # 접두사를 정함.\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis = 1 , inplace = True)\n",
    "print(ndf.head())\n",
    "print('\\n')\n",
    "\n",
    "# 4단계. 정규화\n",
    "# survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
    "# survived (종속변수 y)\n",
    "# pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S (독립변수 X)\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨)를 지정한다.\n",
    "X = ndf[['pclass','age','sibsp','parch','female','male','town_C','town_Q','town_S', 'child_women', 'fare']] # 독립변수\n",
    "y = ndf['survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화(normalization) 한다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "result = []\n",
    "for i in range(20,30,1):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = i)\n",
    "    \n",
    "    # 설명 : test_size = 0.3 에 의해서 7:3 비율로 훈련과 테스트를 나누고 \n",
    "    # random_state = 10 에 의해서 나중에 split할 때도 항상 일정하게 split 할 수 있게 한다.\n",
    "    \n",
    "    \n",
    "    # 6단계. 머신러닝 모델을 생성한다.(랜덤 포레스트를 사용)\n",
    "    for j in range(10,50,2):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        \n",
    "        tree_model = RandomForestClassifier(n_estimators = 100, oob_score = True, random_state = j)\n",
    "        \n",
    "        \n",
    "        tree_model.fit(X_train, y_train)\n",
    "    \n",
    "        # oob 평가\n",
    "        print(tree_model.oob_score_)\n",
    "        print('\\n')\n",
    "        \n",
    "        # 7단계. 테스트 데이터로 예측하기\n",
    "        \n",
    "        y_hat = tree_model.predict(X_test)\n",
    "        \n",
    "        \n",
    "        # 8단계. 모형의 예측 능력을 평가한다. (confusion matrix 만들기!)\n",
    "        from sklearn import metrics\n",
    "        tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "        \n",
    "        \"\"\"\n",
    "                     예측\n",
    "                   사망 생존\n",
    "        실제 사망 [[109  16]\n",
    "             생존  [ 25  65]]\n",
    "             \n",
    "        \"\"\"\n",
    "        \n",
    "        # 정확도 : (109 + 65) / (109 + 16 + 25 + 65)\n",
    "        # 정확도 100%는 현실적으로 나오기 힘드니 (예측: 생존 , 실제: 사망 데이터인 25를 0으로 만드는 것을 궁극적으로 추구한다.)\n",
    "        \n",
    "        # confusion matrix에 대한 변수 지정 (tn,fp,fn,tp)\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "        \n",
    "        \n",
    "        f1_report = metrics.classification_report(y_test, y_hat)\n",
    "        \n",
    "        # 9단계 정확도 확인\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score( y_test, y_hat)\n",
    "        \n",
    "        print(i,j, end = '\\n\\n')\n",
    "        print(accuracy)\n",
    "        result.append(accuracy)\n",
    "\n",
    "print('\\n')\n",
    "print('최대 accuracy는 ', max(result))\n",
    "print('최대값의 위치는 = ', result.index(max(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선생님이 짜신 seaborn 타이타닉 모범코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "child_women      0\n",
      "dtype: int64\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       2\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "alive          0\n",
      "alone          0\n",
      "child_women    0\n",
      "dtype: int64\n",
      "248.46714298590453\n",
      "     survived     fare  pclass   age  sibsp  parch  child_women  female  male  \\\n",
      "0           0   7.2500       3  22.0      1      0            0       0     1   \n",
      "1           1  71.2833       1  38.0      1      0            1       1     0   \n",
      "2           1   7.9250       3  26.0      0      0            1       1     0   \n",
      "3           1  53.1000       1  35.0      1      0            1       1     0   \n",
      "4           0   8.0500       3  35.0      0      0            0       0     1   \n",
      "..        ...      ...     ...   ...    ...    ...          ...     ...   ...   \n",
      "886         0  13.0000       2  27.0      0      0            0       0     1   \n",
      "887         1  30.0000       1  19.0      0      0            1       1     0   \n",
      "888         0  23.4500       3  24.0      1      2            1       1     0   \n",
      "889         1  30.0000       1  26.0      0      0            0       0     1   \n",
      "890         0   7.7500       3  32.0      0      0            0       0     1   \n",
      "\n",
      "     C  Q  S  \n",
      "0    0  0  1  \n",
      "1    1  0  0  \n",
      "2    0  0  1  \n",
      "3    0  0  1  \n",
      "4    0  0  1  \n",
      "..  .. .. ..  \n",
      "886  0  0  1  \n",
      "887  0  0  1  \n",
      "888  0  0  1  \n",
      "889  1  0  0  \n",
      "890  0  1  0  \n",
      "\n",
      "[882 rows x 12 columns]\n",
      "0.7941653160453809\n",
      "[[145  24]\n",
      " [ 20  76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       169\n",
      "           1       0.76      0.79      0.78        96\n",
      "\n",
      "    accuracy                           0.83       265\n",
      "   macro avg       0.82      0.82      0.82       265\n",
      "weighted avg       0.84      0.83      0.83       265\n",
      "\n",
      "0.8339622641509434\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "# 1단계 csv ---> 데이터 프레임으로 변환\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "#df2 = pd.read_csv(\"d://data//train.csv\")\n",
    "#print(df.head())\n",
    "#print(df2.Cabin)\n",
    "\n",
    "\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "\n",
    "pd.set_option('display.max_columns',15)\n",
    "\n",
    "\n",
    "\n",
    "# 2단계 결측치 확인하고 제거하거나 치환한다.\n",
    "\n",
    "# 2.1 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "mask4 = (df.age<10) | (df.sex=='female') \n",
    "\n",
    "df['child_women']=mask4.astype(int)\n",
    "\n",
    "# 2.2 결측치(NaN) 을 확인한다.\n",
    "\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함.\n",
    "\n",
    "#        embark 와 embark_town 이 같은 데이터여서 embark 컬럼을 삭제해야함\n",
    "\n",
    "\n",
    "rdf = df.drop(['deck','embark_town'], axis =1)\n",
    "\n",
    "most_freq = rdf['age'].value_counts(dropna=True).idxmax()\n",
    "\n",
    "print(most_freq)\n",
    "\n",
    "print ( df.isnull().sum( axis=0)  )  \n",
    "\n",
    "rdf['age'].fillna(most_freq, inplace = True)\n",
    "\n",
    "print ( rdf.isnull().sum( axis=0)  )  \n",
    "\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든행을 삭제한다.\n",
    "\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "#rdf = rdf.dropna( subset=['age'], how='any', axis=0)\n",
    "\n",
    "\n",
    "# 2.5 embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\n",
    "\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts().idxmax()\n",
    "\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "\n",
    "\n",
    "# 3단계 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "\n",
    "ndf = rdf[['survived','fare', 'pclass','sex','age','sibsp','parch','embarked','child_women']]\n",
    "\n",
    "\n",
    "\n",
    "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\n",
    "#3.2 범주형 데이터를 숫자로 변환하기(원핫 인코딩)\n",
    "\n",
    "\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "\n",
    "ndf = pd.concat([ndf,gender], axis= 1)\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'])\n",
    "ndf = pd.concat([ndf,onehot_embarked],axis=1)\n",
    "ndf.drop(['sex','embarked'], axis=1, inplace = True)\n",
    "\n",
    "\n",
    "#most_freq = ndf['fare'].value_counts().idxmax()\n",
    "#ndf['fare'].fillna(most_freq, inplace = True)\n",
    "local_std = ndf.fare.std() * 5\n",
    "print(local_std)\n",
    "ndf = ndf[:][ndf['fare'] < local_std]\n",
    "\n",
    "print(ndf)\n",
    "\n",
    "\n",
    "# 4단계 정규화\n",
    "\n",
    "\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\n",
    "\n",
    "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\n",
    "\n",
    "#   라벨                       데이터\n",
    "\n",
    "# 종속변수                     독립변수\n",
    "\n",
    "x = ndf[ ['fare', 'pclass', 'age' ,'sibsp', 'parch' ,'female' ,'male', 'C' ,'Q' ,'S',\n",
    "          'child_women'] ]\n",
    "\n",
    "y = ndf['survived'] # 종속변수\n",
    "\n",
    "\n",
    "\n",
    "# 4.2 독립변수들을 정규화 한다.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "\n",
    "\n",
    "# 5단계 훈련 데이터를 훈련 데이터 / 테스트 데이터로 나눈다\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,\n",
    "                                                 random_state = 14)\n",
    "\n",
    "\n",
    "# sklearn 라이브러리에서 나이브베이즈 분류 모형 가져오기\n",
    "\n",
    "\n",
    "from  sklearn.ensemble   import  RandomForestClassifier \n",
    "\n",
    "tree_model = RandomForestClassifier( n_estimators=100, oob_score=True, \n",
    "                                     random_state=9)  \n",
    "\n",
    "\n",
    "tree_model.fit( X_train, y_train )\n",
    "\n",
    "print ( tree_model.oob_score_)\n",
    "\n",
    "\n",
    "# 7단계 테스트 데이터로 예측을 한다.\n",
    "\n",
    "y_hat = tree_model.predict( X_test )\n",
    "\n",
    "\n",
    "\n",
    "# 8단계 모형의 예측능력을 평가한다.\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "randomforest_matrix = metrics.confusion_matrix( y_test, y_hat )\n",
    "\n",
    "print( randomforest_matrix )\n",
    "\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "\n",
    "\n",
    "\n",
    "f1_report = metrics.classification_report( y_test, y_hat )\n",
    "\n",
    "print( f1_report )\n",
    "\n",
    "#print(np.array([[tp,fp],[fn,tn]]))\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제216.(오늘의 마지막 문제) 케글의 타이타닉 데이터를 랜덤포레스트 모델을 써서 테스트 데이터의 예측값을 구해서 자신의 순위를 올리시오~\n",
    "\n",
    "1. 나이의 결측치를 최빈값으로 치환\n",
    "    - 최빈값으로 치환할 때 훈련데이터는 훈련데이터의 최빈값으로 변경 (31살)\n",
    "    - 최빈값으로 치환할 때 테스트 데이터는 테스트 데이터의 최빈값으로 변경(21살)\n",
    "    \n",
    "    \n",
    "2. 운임의 이상치를 훈련데이터에서만 제거하시오 ~ ( 5* 표준편차)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
