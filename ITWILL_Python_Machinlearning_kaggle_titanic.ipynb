{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이브베이즈 타이타닉 정확도 코드 (반복문으로 확인용!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age  SibSp  Parch Embarked\n",
      "0         0       3    male  22.0      1      0        S\n",
      "1         1       1  female  38.0      1      0        C\n",
      "2         1       3  female  26.0      0      0        S\n",
      "3         1       1  female  35.0      1      0        S\n",
      "4         0       3    male  35.0      0      0        S \n",
      "\n",
      "alpha = 1 random_state = 90\n",
      "accuracy는 0.7581395348837209\n",
      "\n",
      "\n",
      "alpha = 11 random_state = 90\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 21 random_state = 90\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 31 random_state = 90\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 41 random_state = 90\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 51 random_state = 90\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 61 random_state = 90\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 71 random_state = 90\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 81 random_state = 90\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 91 random_state = 90\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 1 random_state = 91\n",
      "accuracy는 0.8\n",
      "\n",
      "\n",
      "alpha = 11 random_state = 91\n",
      "accuracy는 0.8046511627906977\n",
      "\n",
      "\n",
      "alpha = 21 random_state = 91\n",
      "accuracy는 0.8093023255813954\n",
      "\n",
      "\n",
      "alpha = 31 random_state = 91\n",
      "accuracy는 0.813953488372093\n",
      "\n",
      "\n",
      "alpha = 41 random_state = 91\n",
      "accuracy는 0.813953488372093\n",
      "\n",
      "\n",
      "alpha = 51 random_state = 91\n",
      "accuracy는 0.813953488372093\n",
      "\n",
      "\n",
      "alpha = 61 random_state = 91\n",
      "accuracy는 0.813953488372093\n",
      "\n",
      "\n",
      "alpha = 71 random_state = 91\n",
      "accuracy는 0.813953488372093\n",
      "\n",
      "\n",
      "alpha = 81 random_state = 91\n",
      "accuracy는 0.8046511627906977\n",
      "\n",
      "\n",
      "alpha = 91 random_state = 91\n",
      "accuracy는 0.8046511627906977\n",
      "\n",
      "\n",
      "alpha = 1 random_state = 92\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 11 random_state = 92\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 21 random_state = 92\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 31 random_state = 92\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 41 random_state = 92\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 51 random_state = 92\n",
      "accuracy는 0.7627906976744186\n",
      "\n",
      "\n",
      "alpha = 61 random_state = 92\n",
      "accuracy는 0.7627906976744186\n",
      "\n",
      "\n",
      "alpha = 71 random_state = 92\n",
      "accuracy는 0.7627906976744186\n",
      "\n",
      "\n",
      "alpha = 81 random_state = 92\n",
      "accuracy는 0.7627906976744186\n",
      "\n",
      "\n",
      "alpha = 91 random_state = 92\n",
      "accuracy는 0.7627906976744186\n",
      "\n",
      "\n",
      "alpha = 1 random_state = 93\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 11 random_state = 93\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 21 random_state = 93\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 31 random_state = 93\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 41 random_state = 93\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 51 random_state = 93\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 61 random_state = 93\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 71 random_state = 93\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 81 random_state = 93\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 91 random_state = 93\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 1 random_state = 94\n",
      "accuracy는 0.8093023255813954\n",
      "\n",
      "\n",
      "alpha = 11 random_state = 94\n",
      "accuracy는 0.8232558139534883\n",
      "\n",
      "\n",
      "alpha = 21 random_state = 94\n",
      "accuracy는 0.827906976744186\n",
      "\n",
      "\n",
      "alpha = 31 random_state = 94\n",
      "accuracy는 0.827906976744186\n",
      "\n",
      "\n",
      "alpha = 41 random_state = 94\n",
      "accuracy는 0.8372093023255814\n",
      "\n",
      "\n",
      "alpha = 51 random_state = 94\n",
      "accuracy는 0.8372093023255814\n",
      "\n",
      "\n",
      "alpha = 61 random_state = 94\n",
      "accuracy는 0.8232558139534883\n",
      "\n",
      "\n",
      "alpha = 71 random_state = 94\n",
      "accuracy는 0.8232558139534883\n",
      "\n",
      "\n",
      "alpha = 81 random_state = 94\n",
      "accuracy는 0.8232558139534883\n",
      "\n",
      "\n",
      "alpha = 91 random_state = 94\n",
      "accuracy는 0.8186046511627907\n",
      "\n",
      "\n",
      "alpha = 1 random_state = 95\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 11 random_state = 95\n",
      "accuracy는 0.7813953488372093\n",
      "\n",
      "\n",
      "alpha = 21 random_state = 95\n",
      "accuracy는 0.772093023255814\n",
      "\n",
      "\n",
      "alpha = 31 random_state = 95\n",
      "accuracy는 0.772093023255814\n",
      "\n",
      "\n",
      "alpha = 41 random_state = 95\n",
      "accuracy는 0.772093023255814\n",
      "\n",
      "\n",
      "alpha = 51 random_state = 95\n",
      "accuracy는 0.772093023255814\n",
      "\n",
      "\n",
      "alpha = 61 random_state = 95\n",
      "accuracy는 0.772093023255814\n",
      "\n",
      "\n",
      "alpha = 71 random_state = 95\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 81 random_state = 95\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 91 random_state = 95\n",
      "accuracy는 0.7674418604651163\n",
      "\n",
      "\n",
      "alpha = 1 random_state = 96\n",
      "accuracy는 0.7255813953488373\n",
      "\n",
      "\n",
      "alpha = 11 random_state = 96\n",
      "accuracy는 0.7255813953488373\n",
      "\n",
      "\n",
      "alpha = 21 random_state = 96\n",
      "accuracy는 0.7581395348837209\n",
      "\n",
      "\n",
      "alpha = 31 random_state = 96\n",
      "accuracy는 0.7581395348837209\n",
      "\n",
      "\n",
      "alpha = 41 random_state = 96\n",
      "accuracy는 0.7534883720930232\n",
      "\n",
      "\n",
      "alpha = 51 random_state = 96\n",
      "accuracy는 0.7534883720930232\n",
      "\n",
      "\n",
      "alpha = 61 random_state = 96\n",
      "accuracy는 0.7534883720930232\n",
      "\n",
      "\n",
      "alpha = 71 random_state = 96\n",
      "accuracy는 0.7534883720930232\n",
      "\n",
      "\n",
      "alpha = 81 random_state = 96\n",
      "accuracy는 0.7813953488372093\n",
      "\n",
      "\n",
      "alpha = 91 random_state = 96\n",
      "accuracy는 0.7813953488372093\n",
      "\n",
      "\n",
      "alpha = 1 random_state = 97\n",
      "accuracy는 0.786046511627907\n",
      "\n",
      "\n",
      "alpha = 11 random_state = 97\n",
      "accuracy는 0.8046511627906977\n",
      "\n",
      "\n",
      "alpha = 21 random_state = 97\n",
      "accuracy는 0.8093023255813954\n",
      "\n",
      "\n",
      "alpha = 31 random_state = 97\n",
      "accuracy는 0.8093023255813954\n",
      "\n",
      "\n",
      "alpha = 41 random_state = 97\n",
      "accuracy는 0.8093023255813954\n",
      "\n",
      "\n",
      "alpha = 51 random_state = 97\n",
      "accuracy는 0.8046511627906977\n",
      "\n",
      "\n",
      "alpha = 61 random_state = 97\n",
      "accuracy는 0.786046511627907\n",
      "\n",
      "\n",
      "alpha = 71 random_state = 97\n",
      "accuracy는 0.786046511627907\n",
      "\n",
      "\n",
      "alpha = 81 random_state = 97\n",
      "accuracy는 0.786046511627907\n",
      "\n",
      "\n",
      "alpha = 91 random_state = 97\n",
      "accuracy는 0.786046511627907\n",
      "\n",
      "\n",
      "alpha = 1 random_state = 98\n",
      "accuracy는 0.8\n",
      "\n",
      "\n",
      "alpha = 11 random_state = 98\n",
      "accuracy는 0.8093023255813954\n",
      "\n",
      "\n",
      "alpha = 21 random_state = 98\n",
      "accuracy는 0.8093023255813954\n",
      "\n",
      "\n",
      "alpha = 31 random_state = 98\n",
      "accuracy는 0.8093023255813954\n",
      "\n",
      "\n",
      "alpha = 41 random_state = 98\n",
      "accuracy는 0.8093023255813954\n",
      "\n",
      "\n",
      "alpha = 51 random_state = 98\n",
      "accuracy는 0.8093023255813954\n",
      "\n",
      "\n",
      "alpha = 61 random_state = 98\n",
      "accuracy는 0.8093023255813954\n",
      "\n",
      "\n",
      "alpha = 71 random_state = 98\n",
      "accuracy는 0.813953488372093\n",
      "\n",
      "\n",
      "alpha = 81 random_state = 98\n",
      "accuracy는 0.813953488372093\n",
      "\n",
      "\n",
      "alpha = 91 random_state = 98\n",
      "accuracy는 0.813953488372093\n",
      "\n",
      "\n",
      "alpha = 1 random_state = 99\n",
      "accuracy는 0.7813953488372093\n",
      "\n",
      "\n",
      "alpha = 11 random_state = 99\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 21 random_state = 99\n",
      "accuracy는 0.7767441860465116\n",
      "\n",
      "\n",
      "alpha = 31 random_state = 99\n",
      "accuracy는 0.7813953488372093\n",
      "\n",
      "\n",
      "alpha = 41 random_state = 99\n",
      "accuracy는 0.7813953488372093\n",
      "\n",
      "\n",
      "alpha = 51 random_state = 99\n",
      "accuracy는 0.7813953488372093\n",
      "\n",
      "\n",
      "alpha = 61 random_state = 99\n",
      "accuracy는 0.7906976744186046\n",
      "\n",
      "\n",
      "alpha = 71 random_state = 99\n",
      "accuracy는 0.7906976744186046\n",
      "\n",
      "\n",
      "alpha = 81 random_state = 99\n",
      "accuracy는 0.7906976744186046\n",
      "\n",
      "\n",
      "alpha = 91 random_state = 99\n",
      "accuracy는 0.786046511627907\n",
      "\n",
      "\n",
      "최대정확도는 :  0.8372093023255814\n",
      "44 번째순서\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 1단계. csv --> 데이터 프레임으로 변환\n",
    "df = pd.read_csv('d:\\\\data\\\\tat\\\\train.csv')\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "\n",
    "# 2.1 결측치를 확인하고 제거하거나 치환한다.\n",
    "# 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "mask1 = (df['Age'] < 10) | (df['Sex'] == 'female')\n",
    "df['child_women'] = mask1.astype(int)\n",
    "# 2.2 결측치(NaN)을 확인한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 Cabin 컬럼을 삭제한다.\n",
    "rdf = df.drop(['Cabin'], axis =1)\n",
    "\n",
    "\n",
    "# 2.4 Age(나이) 열에 나이가 없는 모든 행을 삭제한다.\n",
    "# age 열에 891개의 행중에 177개가 NaN값\n",
    "\n",
    "rdf = rdf.dropna(subset = ['Age'], how='any', axis = 0)\n",
    "\n",
    "\n",
    "# 설명\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "# 2.5 embark 열의 NaN값을 승선도시중 가장 많이 출현한 값으로 치환하기.\n",
    "\n",
    "most_freq = rdf['Embarked'].value_counts(dropna=True).idxmax()\n",
    "rdf['Embarked'].fillna(most_freq, inplace = True)\n",
    "\n",
    "\n",
    "# 3. 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "ndf = rdf[['Survived','Pclass','Sex','Age','SibSp','Parch','Embarked', 'child_women']]\n",
    "print(ndf.head(), '\\n')\n",
    "\n",
    "\n",
    "# 선택된 컬럼중 2개(sex, embarked)가 범주형(문자형)이다.\n",
    "\n",
    "# 3.2 범주형 데이터를 숫자로 변환(원핫 인코딩)\n",
    "gender = pd.get_dummies(ndf['Sex'])\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['Embarked'], prefix = 'town')\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "\n",
    "ndf.drop(['Sex', 'Embarked'], axis = 1 , inplace = True)\n",
    "\n",
    "\n",
    "# 4단계. 정규화\n",
    "# survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
    "# survived (종속변수 y)\n",
    "# pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S (독립변수 X)\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨)를 지정한다.\n",
    "X = ndf[['Pclass','Age','SibSp','Parch','female','male','town_C','town_Q','town_S', 'child_women']] # 독립변수\n",
    "y = ndf['Survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화(normalization) 한다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "# 4.2 독립변수들을 정규화(normalization) 한다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다. (반복문까지 추가함!!!!)\n",
    "\n",
    "u = []\n",
    "import numpy as np\n",
    "al = list(np.arange(1,100,10))\n",
    "\n",
    "for i in range(90,100):\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = i)\n",
    "    \n",
    "    # 설명 : test_size = 0.3 에 의해서 7:3 비율로 훈련과 테스트를 나누고 \n",
    "    # random_state = 10 에 의해서 나중에 split할 때도 항상 일정하게 split 할 수 있게 한다.\n",
    "\n",
    "    \n",
    "    # 6단계. 머신러닝 모델을 생성한다.(knn을 사용)\n",
    "    for j in al:\n",
    "        from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "        \n",
    "        model = BernoulliNB(alpha= j) # 이걸로 라플라스 값을 지정할 수도 있다.\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # 7단계. 테스트 데이터로 예측하기\n",
    "        \n",
    "        y_hat = model.predict(X_test)\n",
    "\n",
    "   \n",
    "        print('alpha =', j, 'random_state =', i)\n",
    "        \n",
    "        # 9단계 정확도 확인\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score( y_test, y_hat)\n",
    "        print('accuracy는', accuracy)\n",
    "\n",
    "        u.append(accuracy)\n",
    "        print('\\n')\n",
    "        \n",
    "\n",
    "\n",
    "print('최대정확도는 : ', max(u))\n",
    "print(u.index(max(u)), '번째순서')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반복문 x, 나이브 베이즈 코드 (submission.csv제출용 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "child_women    891 non-null int32\n",
      "dtypes: float64(2), int32(1), int64(5), object(5)\n",
      "memory usage: 87.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "child_women    418 non-null int32\n",
      "dtypes: float64(2), int32(1), int64(4), object(5)\n",
      "memory usage: 37.7+ KB\n",
      "None\n",
      "\n",
      "\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "child_women      0\n",
      "dtype: int64 \n",
      "\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "child_women      0\n",
      "dtype: int64 \n",
      "\n",
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Embarked' 'child_women'] \n",
      "\n",
      "['PassengerId' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare'\n",
      " 'Embarked' 'child_women'] \n",
      "\n",
      "714 \n",
      "\n",
      "     PassengerId  Pclass                                          Name  \\\n",
      "0            892       3                              Kelly, Mr. James   \n",
      "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
      "2            894       2                     Myles, Mr. Thomas Francis   \n",
      "3            895       3                              Wirz, Mr. Albert   \n",
      "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
      "..           ...     ...                                           ...   \n",
      "413         1305       3                            Spector, Mr. Woolf   \n",
      "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
      "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
      "416         1308       3                           Ware, Mr. Frederick   \n",
      "417         1309       3                      Peter, Master. Michael J   \n",
      "\n",
      "        Sex       Age  SibSp  Parch              Ticket      Fare Embarked  \\\n",
      "0      male  34.50000      0      0              330911    7.8292        Q   \n",
      "1    female  47.00000      1      0              363272    7.0000        S   \n",
      "2      male  62.00000      0      0              240276    9.6875        Q   \n",
      "3      male  27.00000      0      0              315154    8.6625        S   \n",
      "4    female  22.00000      1      1             3101298   12.2875        S   \n",
      "..      ...       ...    ...    ...                 ...       ...      ...   \n",
      "413    male  30.27259      0      0           A.5. 3236    8.0500        S   \n",
      "414  female  39.00000      0      0            PC 17758  108.9000        C   \n",
      "415    male  38.50000      0      0  SOTON/O.Q. 3101262    7.2500        S   \n",
      "416    male  30.27259      0      0              359309    8.0500        S   \n",
      "417    male  30.27259      1      1                2668   22.3583        C   \n",
      "\n",
      "     child_women  \n",
      "0              0  \n",
      "1              1  \n",
      "2              0  \n",
      "3              0  \n",
      "4              1  \n",
      "..           ...  \n",
      "413            0  \n",
      "414            1  \n",
      "415            0  \n",
      "416            0  \n",
      "417            0  \n",
      "\n",
      "[418 rows x 11 columns] \n",
      "\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "child_women    0\n",
      "dtype: int64 \n",
      "\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "child_women    0\n",
      "dtype: int64 \n",
      "\n",
      "   Survived  Pclass     Sex   Age  SibSp  Parch Embarked  child_women\n",
      "0         0       3    male  22.0      1      0        S            0\n",
      "1         1       1  female  38.0      1      0        C            1\n",
      "2         1       3  female  26.0      0      0        S            1\n",
      "3         1       1  female  35.0      1      0        S            1\n",
      "4         0       3    male  35.0      0      0        S            0 \n",
      "\n",
      "   Pclass     Sex   Age  SibSp  Parch Embarked  child_women\n",
      "0       3    male  34.5      0      0        Q            0\n",
      "1       3  female  47.0      1      0        S            1\n",
      "2       2    male  62.0      0      0        Q            0\n",
      "3       3    male  27.0      0      0        S            0\n",
      "4       3  female  22.0      1      1        S            1 \n",
      "\n",
      "   Survived  Pclass   Age  SibSp  Parch  child_women  female  male  town_C  \\\n",
      "0         0       3  22.0      1      0            0       0     1       0   \n",
      "1         1       1  38.0      1      0            1       1     0       1   \n",
      "2         1       3  26.0      0      0            1       1     0       0   \n",
      "3         1       1  35.0      1      0            1       1     0       0   \n",
      "4         0       3  35.0      0      0            0       0     1       0   \n",
      "\n",
      "   town_Q  town_S  \n",
      "0       0       1  \n",
      "1       0       0  \n",
      "2       0       1  \n",
      "3       0       1  \n",
      "4       0       1  \n",
      "\n",
      "\n",
      "   Pclass   Age  SibSp  Parch  child_women  female  male  town_C  town_Q  \\\n",
      "0       3  34.5      0      0            0       0     1       0       1   \n",
      "1       3  47.0      1      0            1       1     0       0       0   \n",
      "2       2  62.0      0      0            0       0     1       0       1   \n",
      "3       3  27.0      0      0            0       0     1       0       0   \n",
      "4       3  22.0      1      1            1       1     0       0       0   \n",
      "\n",
      "   town_S  \n",
      "0       0  \n",
      "1       1  \n",
      "2       0  \n",
      "3       1  \n",
      "4       1  \n",
      "\n",
      "\n",
      "[[ 0.91123237 -0.53037664  0.52457013 ... -0.20203051  0.53307848\n",
      "  -0.83424337]\n",
      " [-1.47636364  0.57183099  0.52457013 ... -0.20203051 -1.87589641\n",
      "   1.19869098]\n",
      " [ 0.91123237 -0.25482473 -0.55170307 ... -0.20203051  0.53307848\n",
      "   1.19869098]\n",
      " ...\n",
      " [-1.47636364 -0.73704057 -0.55170307 ... -0.20203051  0.53307848\n",
      "   1.19869098]\n",
      " [-1.47636364 -0.25482473 -0.55170307 ... -0.20203051 -1.87589641\n",
      "  -0.83424337]\n",
      " [ 0.91123237  0.15850313 -0.55170307 ...  4.94974747 -1.87589641\n",
      "  -0.83424337]]\n",
      "[[ 0.87348191  0.3349926  -0.49947002 ...  2.84375747 -1.35067551\n",
      "  -0.79950965]\n",
      " [ 0.87348191  1.32553003  0.61699237 ... -0.35164743  0.74037028\n",
      "   1.25076664]\n",
      " [-0.31581919  2.51417495 -0.49947002 ...  2.84375747 -1.35067551\n",
      "  -0.79950965]\n",
      " ...\n",
      " [ 0.87348191  0.65196458 -0.49947002 ... -0.35164743  0.74037028\n",
      "  -0.79950965]\n",
      " [ 0.87348191  0.         -0.49947002 ... -0.35164743  0.74037028\n",
      "  -0.79950965]\n",
      " [ 0.87348191  0.          0.61699237 ... -0.35164743 -1.35067551\n",
      "  -0.79950965]]\n",
      "117 15 12 71\n",
      "\n",
      "\n",
      "0.8744186046511628\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"d:\\\\data\\\\tat\\\\train.csv\")\n",
    "df2 = pd.read_csv(\"d:\\\\data\\\\tat\\\\test.csv\")\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "mask1 = (df['Age'] < 10) | (df['Sex'] == 'female')\n",
    "mask2 = (df2['Age'] < 10) | (df2['Sex'] == 'female')\n",
    "\n",
    "df['child_women'] = mask1.astype(int)\n",
    "df2['child_women'] = mask2.astype(int)\n",
    "\n",
    "\n",
    "print(df.info())\n",
    "print(df2.info())\n",
    "print('\\n')\n",
    "\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "print(df2.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "rdf = df.drop(['Cabin'], axis =1)\n",
    "rdf2 = df2.drop(['Cabin'], axis =1)\n",
    "\n",
    "print(rdf.columns.values, '\\n')\n",
    "print(rdf2.columns.values, '\\n')\n",
    "\n",
    "most_mean = rdf2['Age'].mean()\n",
    "rdf = rdf.dropna(subset = ['Age'], how='any', axis = 0)\n",
    "rdf2['Age'].fillna(most_mean, inplace = True)\n",
    "\n",
    "print(len(rdf), '\\n')\n",
    "print(rdf2, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "most_freq = rdf['Embarked'].value_counts(dropna=True).idxmax()\n",
    "most_freq2 = rdf2['Fare'].value_counts(dropna=True).idxmax()\n",
    "rdf['Embarked'].fillna(most_freq, inplace = True)\n",
    "rdf2['Fare'].fillna(most_freq2, inplace = True)\n",
    "\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "print(rdf2.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "\n",
    "ndf = rdf[['Survived','Pclass','Sex','Age','SibSp','Parch','Embarked', 'child_women']]\n",
    "ndf2 = rdf2[['Pclass','Sex','Age','SibSp','Parch','Embarked', 'child_women']]\n",
    "\n",
    "print(ndf.head(), '\\n')\n",
    "print(ndf2.head(), '\\n')\n",
    "\n",
    "gender = pd.get_dummies(ndf['Sex'])\n",
    "gender2 = pd.get_dummies(ndf2['Sex'])\n",
    "\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "ndf2 = pd.concat([ndf2,gender2], axis = 1)\n",
    "#\n",
    "onehot_embarked = pd.get_dummies(ndf['Embarked'], prefix = 'town') # 접두사를 정함.\n",
    "onehot_embarked2 = pd.get_dummies(ndf2['Embarked'], prefix = 'town') # 접두사를 정함.\n",
    "\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "ndf2 = pd.concat([ndf2, onehot_embarked2], axis = 1)\n",
    "\n",
    "ndf.drop(['Sex', 'Embarked'], axis = 1 , inplace = True)\n",
    "ndf2.drop(['Sex', 'Embarked'], axis = 1 , inplace = True)\n",
    "\n",
    "print(ndf.head())\n",
    "print('\\n')\n",
    "\n",
    "print(ndf2.head())\n",
    "print('\\n')\n",
    "\n",
    "X = ndf[['Pclass','Age','SibSp','Parch','female','male','town_C','town_Q','town_S', 'child_women']] # 독립변수\n",
    "y = ndf['Survived'] # 종속변수\n",
    "\n",
    "test = ndf2[['Pclass','Age','SibSp','Parch','female','male','town_C','town_Q','town_S', 'child_women']]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "test = preprocessing.StandardScaler().fit(test).transform(test)\n",
    "\n",
    "print(X)\n",
    "print(test)\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 94)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "# 모형 객체 생성\n",
    "model = BernoulliNB(alpha=31) # 이걸로 라플라스 값을 지정할 수도 있다.\n",
    "model.fit(X_train, y_train) # model.fit으로 훈련시킨다.\n",
    "\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "\n",
    "# 정확도 : (109 + 65) / (109 + 16 + 25 + 65)\n",
    "# 정확도 100%는 현실적으로 나오기 힘드니 (예측: 생존 , 실제: 사망 데이터인 25를 0으로 만드는 것을 궁극적으로 추구한다.)\n",
    "\n",
    "# confusion matrix에 대한 변수 지정 (tn,fp,fn,tp)\n",
    "from sklearn import metrics\n",
    "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# 9단계 정확도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "sample_submission=pd.read_csv('d:\\\\data\\\\tat\\\\gender_submission.csv', index_col=0)\n",
    "\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame(data=y_pred,columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission.to_csv('d:\\\\data\\\\tat\\\\submission2.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반복문 x, knn 코드 (submission.csv제출용 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "child_women    891 non-null int32\n",
      "dtypes: float64(2), int32(1), int64(5), object(5)\n",
      "memory usage: 87.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "child_women    418 non-null int32\n",
      "dtypes: float64(2), int32(1), int64(4), object(5)\n",
      "memory usage: 37.7+ KB\n",
      "None\n",
      "\n",
      "\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "child_women      0\n",
      "dtype: int64 \n",
      "\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "child_women      0\n",
      "dtype: int64 \n",
      "\n",
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Embarked' 'child_women'] \n",
      "\n",
      "['PassengerId' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare'\n",
      " 'Embarked' 'child_women'] \n",
      "\n",
      "714 \n",
      "\n",
      "     PassengerId  Pclass                                          Name  \\\n",
      "0            892       3                              Kelly, Mr. James   \n",
      "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
      "2            894       2                     Myles, Mr. Thomas Francis   \n",
      "3            895       3                              Wirz, Mr. Albert   \n",
      "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
      "..           ...     ...                                           ...   \n",
      "413         1305       3                            Spector, Mr. Woolf   \n",
      "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
      "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
      "416         1308       3                           Ware, Mr. Frederick   \n",
      "417         1309       3                      Peter, Master. Michael J   \n",
      "\n",
      "        Sex       Age  SibSp  Parch              Ticket      Fare Embarked  \\\n",
      "0      male  34.50000      0      0              330911    7.8292        Q   \n",
      "1    female  47.00000      1      0              363272    7.0000        S   \n",
      "2      male  62.00000      0      0              240276    9.6875        Q   \n",
      "3      male  27.00000      0      0              315154    8.6625        S   \n",
      "4    female  22.00000      1      1             3101298   12.2875        S   \n",
      "..      ...       ...    ...    ...                 ...       ...      ...   \n",
      "413    male  30.27259      0      0           A.5. 3236    8.0500        S   \n",
      "414  female  39.00000      0      0            PC 17758  108.9000        C   \n",
      "415    male  38.50000      0      0  SOTON/O.Q. 3101262    7.2500        S   \n",
      "416    male  30.27259      0      0              359309    8.0500        S   \n",
      "417    male  30.27259      1      1                2668   22.3583        C   \n",
      "\n",
      "     child_women  \n",
      "0              0  \n",
      "1              1  \n",
      "2              0  \n",
      "3              0  \n",
      "4              1  \n",
      "..           ...  \n",
      "413            0  \n",
      "414            1  \n",
      "415            0  \n",
      "416            0  \n",
      "417            0  \n",
      "\n",
      "[418 rows x 11 columns] \n",
      "\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "child_women    0\n",
      "dtype: int64 \n",
      "\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "child_women    0\n",
      "dtype: int64 \n",
      "\n",
      "   Survived  Pclass     Sex   Age  SibSp  Parch Embarked  child_women\n",
      "0         0       3    male  22.0      1      0        S            0\n",
      "1         1       1  female  38.0      1      0        C            1\n",
      "2         1       3  female  26.0      0      0        S            1\n",
      "3         1       1  female  35.0      1      0        S            1\n",
      "4         0       3    male  35.0      0      0        S            0 \n",
      "\n",
      "   Pclass     Sex   Age  SibSp  Parch Embarked  child_women\n",
      "0       3    male  34.5      0      0        Q            0\n",
      "1       3  female  47.0      1      0        S            1\n",
      "2       2    male  62.0      0      0        Q            0\n",
      "3       3    male  27.0      0      0        S            0\n",
      "4       3  female  22.0      1      1        S            1 \n",
      "\n",
      "   Survived  Pclass   Age  SibSp  Parch  child_women  female  male  town_C  \\\n",
      "0         0       3  22.0      1      0            0       0     1       0   \n",
      "1         1       1  38.0      1      0            1       1     0       1   \n",
      "2         1       3  26.0      0      0            1       1     0       0   \n",
      "3         1       1  35.0      1      0            1       1     0       0   \n",
      "4         0       3  35.0      0      0            0       0     1       0   \n",
      "\n",
      "   town_Q  town_S  \n",
      "0       0       1  \n",
      "1       0       0  \n",
      "2       0       1  \n",
      "3       0       1  \n",
      "4       0       1  \n",
      "\n",
      "\n",
      "   Pclass   Age  SibSp  Parch  child_women  female  male  town_C  town_Q  \\\n",
      "0       3  34.5      0      0            0       0     1       0       1   \n",
      "1       3  47.0      1      0            1       1     0       0       0   \n",
      "2       2  62.0      0      0            0       0     1       0       1   \n",
      "3       3  27.0      0      0            0       0     1       0       0   \n",
      "4       3  22.0      1      1            1       1     0       0       0   \n",
      "\n",
      "   town_S  \n",
      "0       0  \n",
      "1       1  \n",
      "2       0  \n",
      "3       1  \n",
      "4       1  \n",
      "\n",
      "\n",
      "0.8325581395348837\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"d:\\\\data\\\\tat\\\\train.csv\")\n",
    "df2 = pd.read_csv(\"d:\\\\data\\\\tat\\\\test.csv\")\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "mask1 = (df['Age'] < 10) | (df['Sex'] == 'female')\n",
    "mask2 = (df2['Age'] < 10) | (df2['Sex'] == 'female')\n",
    "\n",
    "df['child_women'] = mask1.astype(int)\n",
    "df2['child_women'] = mask2.astype(int)\n",
    "\n",
    "\n",
    "print(df.info())\n",
    "print(df2.info())\n",
    "print('\\n')\n",
    "\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "print(df2.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "rdf = df.drop(['Cabin'], axis =1)\n",
    "rdf2 = df2.drop(['Cabin'], axis =1)\n",
    "\n",
    "print(rdf.columns.values, '\\n')\n",
    "print(rdf2.columns.values, '\\n')\n",
    "\n",
    "most_mean = rdf2['Age'].mean()\n",
    "rdf = rdf.dropna(subset = ['Age'], how='any', axis = 0)\n",
    "rdf2['Age'].fillna(most_mean, inplace = True)\n",
    "\n",
    "print(len(rdf), '\\n')\n",
    "print(rdf2, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "most_freq = rdf['Embarked'].value_counts(dropna=True).idxmax()\n",
    "most_freq2 = rdf2['Fare'].value_counts(dropna=True).idxmax()\n",
    "rdf['Embarked'].fillna(most_freq, inplace = True)\n",
    "rdf2['Fare'].fillna(most_freq2, inplace = True)\n",
    "\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "print(rdf2.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "\n",
    "ndf = rdf[['Survived','Pclass','Sex','Age','SibSp','Parch','Embarked', 'child_women']]\n",
    "ndf2 = rdf2[['Pclass','Sex','Age','SibSp','Parch','Embarked', 'child_women']]\n",
    "\n",
    "print(ndf.head(), '\\n')\n",
    "print(ndf2.head(), '\\n')\n",
    "\n",
    "gender = pd.get_dummies(ndf['Sex'])\n",
    "gender2 = pd.get_dummies(ndf2['Sex'])\n",
    "\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "ndf2 = pd.concat([ndf2,gender2], axis = 1)\n",
    "#\n",
    "onehot_embarked = pd.get_dummies(ndf['Embarked'], prefix = 'town') # 접두사를 정함.\n",
    "onehot_embarked2 = pd.get_dummies(ndf2['Embarked'], prefix = 'town') # 접두사를 정함.\n",
    "\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "ndf2 = pd.concat([ndf2, onehot_embarked2], axis = 1)\n",
    "\n",
    "ndf.drop(['Sex', 'Embarked'], axis = 1 , inplace = True)\n",
    "ndf2.drop(['Sex', 'Embarked'], axis = 1 , inplace = True)\n",
    "\n",
    "print(ndf.head())\n",
    "print('\\n')\n",
    "\n",
    "print(ndf2.head())\n",
    "print('\\n')\n",
    "\n",
    "X = ndf[['Pclass','Age','SibSp','Parch','female','male','town_C','town_Q','town_S', 'child_women']] # 독립변수\n",
    "y = ndf['Survived'] # 종속변수\n",
    "\n",
    "test = ndf2[['Pclass','Age','SibSp','Parch','female','male','town_C','town_Q','town_S', 'child_women']]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "test = preprocessing.StandardScaler().fit(test).transform(test)\n",
    "\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 94)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5) # n_neighbors = 5 (knn의 k값은 5) 변수\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_hat = knn.predict(X_test)\n",
    "\n",
    "# Prediction\n",
    "y_pred = knn.predict(test)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "naive_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "\n",
    "# confusion matrix에 대한 변수 지정 (tn,fp,fn,tp)\n",
    "from sklearn import metrics\n",
    "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "\n",
    "\n",
    "\n",
    "# 9단계 정확도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "sample_submission=pd.read_csv('d:\\\\data\\\\tat\\\\gender_submission.csv', index_col=0)\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame(data=y_pred,columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission.to_csv('d:\\\\data\\\\tat\\\\submission2.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반복문 x, 의사결정트리 코드 (submission.csv제출용 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"d:\\\\data\\\\tat\\\\train.csv\")\n",
    "df2 = pd.read_csv(\"d:\\\\data\\\\tat\\\\test.csv\")\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "mask1 = (df['Age'] < 10) | (df['Sex'] == 'female')\n",
    "mask2 = (df2['Age'] < 10) | (df2['Sex'] == 'female')\n",
    "\n",
    "df['child_women'] = mask1.astype(int)\n",
    "df2['child_women'] = mask2.astype(int)\n",
    "\n",
    "\n",
    "print(df.info())\n",
    "print(df2.info())\n",
    "print('\\n')\n",
    "\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "print(df2.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "rdf = df.drop(['Cabin'], axis =1)\n",
    "rdf2 = df2.drop(['Cabin'], axis =1)\n",
    "\n",
    "print(rdf.columns.values, '\\n')\n",
    "print(rdf2.columns.values, '\\n')\n",
    "\n",
    "most_mean = rdf2['Age'].mean()\n",
    "rdf = rdf.dropna(subset = ['Age'], how='any', axis = 0)\n",
    "rdf2['Age'].fillna(most_mean, inplace = True)\n",
    "\n",
    "print(len(rdf), '\\n')\n",
    "print(rdf2, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "most_freq = rdf['Embarked'].value_counts(dropna=True).idxmax()\n",
    "most_freq2 = rdf2['Fare'].value_counts(dropna=True).idxmax()\n",
    "rdf['Embarked'].fillna(most_freq, inplace = True)\n",
    "rdf2['Fare'].fillna(most_freq2, inplace = True)\n",
    "\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "print(rdf2.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "\n",
    "ndf = rdf[['Survived','Pclass','Sex','Age','SibSp','Parch','Embarked', 'child_women']]\n",
    "ndf2 = rdf2[['Pclass','Sex','Age','SibSp','Parch','Embarked', 'child_women']]\n",
    "\n",
    "print(ndf.head(), '\\n')\n",
    "print(ndf2.head(), '\\n')\n",
    "\n",
    "gender = pd.get_dummies(ndf['Sex'])\n",
    "gender2 = pd.get_dummies(ndf2['Sex'])\n",
    "\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "ndf2 = pd.concat([ndf2,gender2], axis = 1)\n",
    "#\n",
    "onehot_embarked = pd.get_dummies(ndf['Embarked'], prefix = 'town') # 접두사를 정함.\n",
    "onehot_embarked2 = pd.get_dummies(ndf2['Embarked'], prefix = 'town') # 접두사를 정함.\n",
    "\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "ndf2 = pd.concat([ndf2, onehot_embarked2], axis = 1)\n",
    "\n",
    "ndf.drop(['Sex', 'Embarked'], axis = 1 , inplace = True)\n",
    "ndf2.drop(['Sex', 'Embarked'], axis = 1 , inplace = True)\n",
    "\n",
    "print(ndf.head())\n",
    "print('\\n')\n",
    "\n",
    "print(ndf2.head())\n",
    "print('\\n')\n",
    "\n",
    "X = ndf[['Pclass','Age','SibSp','Parch','female','male','town_C','town_Q','town_S', 'child_women']] # 독립변수\n",
    "y = ndf['Survived'] # 종속변수\n",
    "\n",
    "test = ndf2[['Pclass','Age','SibSp','Parch','female','male','town_C','town_Q','town_S', 'child_women']]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "test = preprocessing.StandardScaler().fit(test).transform(test)\n",
    "\n",
    "print(X)\n",
    "print(test)\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 94)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 3)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# 7단계. 테스트 데이터로 예측하기\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "\n",
    "# Prediction\n",
    "y_pred = tree_model.predict(test)\n",
    "\n",
    "\n",
    "# 정확도 : (109 + 65) / (109 + 16 + 25 + 65)\n",
    "# 정확도 100%는 현실적으로 나오기 힘드니 (예측: 생존 , 실제: 사망 데이터인 25를 0으로 만드는 것을 궁극적으로 추구한다.)\n",
    "\n",
    "# confusion matrix에 대한 변수 지정 (tn,fp,fn,tp)\n",
    "from sklearn import metrics\n",
    "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# 9단계 정확도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "sample_submission=pd.read_csv('d:\\\\data\\\\tat\\\\gender_submission.csv', index_col=0)\n",
    "\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame(data=y_pred,columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission.to_csv('d:\\\\data\\\\tat\\\\submission2.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반복문 o, 의사결정트리 코드(seaborn 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code.\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1단계. csv --> 데이터 프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "print(df.head(), '\\n')\n",
    "\n",
    "mask1 = (df['age'] < 10) | (df['sex'] == 'female')\n",
    "df['child_women'] = mask1.astype(int)\n",
    "\n",
    "# 2.1 결측치를 확인하고 제거하거나 치환한다.\n",
    "# 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "print(df.info()) # 자료형 확인하는 방법\n",
    "print('\\n')\n",
    "# 2.2 결측치(NaN)을 확인한다.\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함\n",
    "# embark 와 embark_town이 같은 데이터(중복데이터)여서 컬럼을 하나 삭제해야함.\n",
    "# embark 컬럼은 삭제한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "rdf = df.drop(['deck', 'embark_town'], axis =1)\n",
    "print(rdf.columns.values, '\\n')\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든 행을 삭제한다.\n",
    "# age 열에 891개의 행중에 177개가 NaN값\n",
    "\n",
    "rdf = rdf.dropna(subset = ['age'], how='any', axis = 0)\n",
    "print(len(rdf), '\\n')\n",
    "\n",
    "# 설명\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "# 2.5 embark 열의 NaN값을 승선도시중 가장 많이 출현한 값으로 치환하기.\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 3. 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked', 'child_women']]\n",
    "print(ndf.head(), '\\n')\n",
    "# 선택된 컬럼중 2개(sex, embarked)가 범주형(문자형)이다.\n",
    "\n",
    "# 3.2 범주형 데이터를 숫자로 변환(원핫 인코딩)\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix = 'town') # 접두사를 정함.\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis = 1 , inplace = True)\n",
    "print(ndf.head())\n",
    "print('\\n')\n",
    "\n",
    "# 4단계. 정규화\n",
    "# survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
    "# survived (종속변수 y)\n",
    "# pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S (독립변수 X)\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨)를 지정한다.\n",
    "X = ndf[['pclass','age','sibsp','parch','female','male','town_C','town_Q','town_S', 'child_women']] # 독립변수\n",
    "y = ndf['survived'] # 종속변수\n",
    "\n",
    "\n",
    "# 4.2 독립변수들을 정규화(normalization) 한다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "print(X)\n",
    "print('\\n')\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "result = []\n",
    "for i in range(10,20,1):\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = i)\n",
    "    \n",
    "    # 설명 : test_size = 0.3 에 의해서 7:3 비율로 훈련과 테스트를 나누고 \n",
    "    # random_state = 10 에 의해서 나중에 split할 때도 항상 일정하게 split 할 수 있게 한다.\n",
    "    \n",
    "    \n",
    "    # 6단계. 머신러닝 모델을 생성한다.(나이브 베이즈 분류모형을 사용)\n",
    "\n",
    "    for j in range(1,10):\n",
    "        \n",
    "        from sklearn import tree\n",
    "        tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = j)\n",
    "        tree_model.fit(X_train, y_train)\n",
    "        \n",
    "        # 7단계. 테스트 데이터로 예측하기\n",
    "        \n",
    "        y_hat = tree_model.predict(X_test)\n",
    "        \n",
    "        # 8단계. 모형의 예측 능력을 평가한다. (confusion matrix 만들기!)\n",
    "        from sklearn import metrics\n",
    "        tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "    \n",
    "    \n",
    "        \n",
    "        # 정확도 : (109 + 65) / (109 + 16 + 25 + 65)\n",
    "        # 정확도 100%는 현실적으로 나오기 힘드니 (예측: 생존 , 실제: 사망 데이터인 25를 0으로 만드는 것을 궁극적으로 추구한다.)\n",
    "        \n",
    "        # confusion matrix에 대한 변수 지정 (tn,fp,fn,tp)\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "    \n",
    "        \n",
    "        f1_report = metrics.classification_report(y_test, y_hat)\n",
    "    \n",
    "        \n",
    "        # 9단계 정확도 확인\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score( y_test, y_hat)\n",
    "        result.append(accuracy)\n",
    "        \n",
    "        print('random : ', ',', i, 'mex_depth : ', j, ',', accuracy)\n",
    "\n",
    "print('최대정확도는 : ', max(result))\n",
    "print(result.index(max(result)), '번째순서')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반복문 x, 랜덤포레스트 코드 (submission.csv 제출용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "child_women    891 non-null int32\n",
      "dtypes: float64(2), int32(1), int64(5), object(5)\n",
      "memory usage: 87.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "child_women    418 non-null int32\n",
      "dtypes: float64(2), int32(1), int64(4), object(5)\n",
      "memory usage: 37.7+ KB\n",
      "None\n",
      "\n",
      "\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "child_women      0\n",
      "dtype: int64 \n",
      "\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "child_women      0\n",
      "dtype: int64 \n",
      "\n",
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Embarked' 'child_women'] \n",
      "\n",
      "['PassengerId' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare'\n",
      " 'Embarked' 'child_women'] \n",
      "\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "child_women    0\n",
      "dtype: int64 \n",
      "\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           1\n",
      "Embarked       0\n",
      "child_women    0\n",
      "dtype: int64 \n",
      "\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           9\n",
      "Embarked       0\n",
      "child_women    0\n",
      "dtype: int64 \n",
      "\n",
      "   Survived  Pclass     Sex   Age  SibSp  Parch Embarked  child_women     Fare\n",
      "0         0       3    male  22.0      1      0        S            0   7.2500\n",
      "1         1       1  female  38.0      1      0        C            1  71.2833\n",
      "2         1       3  female  26.0      0      0        S            1   7.9250\n",
      "3         1       1  female  35.0      1      0        S            1  53.1000\n",
      "4         0       3    male  35.0      0      0        S            0   8.0500 \n",
      "\n",
      "   Pclass     Sex   Age  SibSp  Parch Embarked  child_women     Fare\n",
      "0       3    male  34.5      0      0        Q            0   7.8292\n",
      "1       3  female  47.0      1      0        S            1   7.0000\n",
      "2       2    male  62.0      0      0        Q            0   9.6875\n",
      "3       3    male  27.0      0      0        S            0   8.6625\n",
      "4       3  female  22.0      1      1        S            1  12.2875 \n",
      "\n",
      "   Survived  Pclass   Age  SibSp  Parch  child_women     Fare  female  male  \\\n",
      "0         0       3  22.0      1      0            0   7.2500       0     1   \n",
      "1         1       1  38.0      1      0            1  71.2833       1     0   \n",
      "2         1       3  26.0      0      0            1   7.9250       1     0   \n",
      "3         1       1  35.0      1      0            1  53.1000       1     0   \n",
      "4         0       3  35.0      0      0            0   8.0500       0     1   \n",
      "\n",
      "   town_C  town_Q  town_S  \n",
      "0       0       0       1  \n",
      "1       1       0       0  \n",
      "2       0       0       1  \n",
      "3       0       0       1  \n",
      "4       0       0       1  \n",
      "\n",
      "\n",
      "   Pclass   Age  SibSp  Parch  child_women     Fare  female  male  town_C  \\\n",
      "0       3  34.5      0      0            0   7.8292       0     1       0   \n",
      "1       3  47.0      1      0            1   7.0000       1     0       0   \n",
      "2       2  62.0      0      0            0   9.6875       0     1       0   \n",
      "3       3  27.0      0      0            0   8.6625       0     1       0   \n",
      "4       3  22.0      1      1            1  12.2875       1     0       0   \n",
      "\n",
      "   town_Q  town_S  \n",
      "0       1       0  \n",
      "1       0       1  \n",
      "2       1       0  \n",
      "3       0       1  \n",
      "4       0       1  \n",
      "\n",
      "\n",
      "[[ 0.82737724 -0.49779327  0.43279337 ...  0.61583843 -0.79678252\n",
      "  -0.5913951 ]\n",
      " [-1.56610693  0.71504807  0.43279337 ... -1.62380254  1.25504761\n",
      "   1.16661127]\n",
      " [ 0.82737724 -0.19458293 -0.4745452  ...  0.61583843  1.25504761\n",
      "  -0.57286327]\n",
      " ...\n",
      " [ 0.82737724 -0.3461881   0.43279337 ...  0.61583843  1.25504761\n",
      "  -0.14663115]\n",
      " [-1.56610693 -0.19458293 -0.4745452  ... -1.62380254 -0.79678252\n",
      "   0.03319624]\n",
      " [ 0.82737724  0.26023257 -0.4745452  ... -1.62380254 -0.79678252\n",
      "  -0.57766782]]\n",
      "[[ 0.87348191  0.42869    -0.49947002 ... -1.35067551 -0.79950965\n",
      "  -0.52329561]\n",
      " [ 0.87348191  1.39981736  0.61699237 ...  0.74037028  1.25076664\n",
      "  -0.5396549 ]\n",
      " [-0.31581919  2.56517019 -0.49947002 ... -1.35067551 -0.79950965\n",
      "  -0.48663319]\n",
      " ...\n",
      " [ 0.87348191  0.73945076 -0.49947002 ...  0.74037028 -0.79950965\n",
      "  -0.53472265]\n",
      " [ 0.87348191 -0.38705698 -0.49947002 ...  0.74037028 -0.79950965\n",
      "  -0.51893944]\n",
      " [ 0.87348191 -0.38705698  0.61699237 ... -1.35067551 -0.79950965\n",
      "  -0.23665085]]\n",
      "[0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 1 0 0 1 0 0 0]\n",
      "151 15 27 75\n",
      "\n",
      "\n",
      "0.8432835820895522\n"
     ]
    }
   ],
   "source": [
    "# 나이의 결측치를 바꾼 최빈값.\n",
    "# Full code.\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 1단계. csv --> 데이터 프레임으로 변환\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "# print(df.head(), '\\n')\n",
    "\n",
    "mask1 = (df['age'] < 10) | (df['sex'] == 'female')\n",
    "df['child_women'] = mask1.astype(int)\n",
    "\n",
    "# 2.1 결측치를 확인하고 제거하거나 치환한다.\n",
    "# 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "# print(df.info()) # 자료형 확인하는 방법\n",
    "# print('\\n')\n",
    "\n",
    "# 2.2 결측치(NaN)을 확인한다.\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함\n",
    "# embark 와 embark_town이 같은 데이터(중복데이터)여서 컬럼을 하나 삭제해야함.\n",
    "# embark 컬럼은 삭제한다.\n",
    "\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "rdf = df.drop(['deck', 'embark_town'], axis =1)\n",
    "# print(rdf.columns.values, '\\n')\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든 행을 삭제한다.\n",
    "# age 열에 891개의 행중에 177개가 NaN값\n",
    "\n",
    "age_freq = rdf['age'].value_counts(dropna=True).idxmax()\n",
    "print(age_freq)\n",
    "print('\\n')\n",
    "\n",
    "print(df.isnull().sum(axis=0))\n",
    "print('\\n')\n",
    "\n",
    "rdf['age'].fillna(age_freq, inplace = True)\n",
    "\n",
    "print(len(rdf), '\\n')\n",
    "print(rdf.isnull().sum(axis=0))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# 2.5 embark 열의 NaN값을 승선도시중 가장 많이 출현한 값으로 치환하기.\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# 3. 범주형 데이터를 숫자형으로 변환하기\n",
    "\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked', 'child_women']]\n",
    "# print(ndf.head(), '\\n')\n",
    "# 선택된 컬럼중 2개(sex, embarked)가 범주형(문자형)이다.\n",
    "\n",
    "# 3.2 범주형 데이터를 숫자로 변환(원핫 인코딩)\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix = 'town') # 접두사를 정함.\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis = 1 , inplace = True)\n",
    "# print(ndf.head())\n",
    "# print('\\n')\n",
    "\n",
    "# 4단계. 정규화\n",
    "# survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
    "# survived (종속변수 y)\n",
    "# pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S (독립변수 X)\n",
    "\n",
    "# 4.1 독립변수와 종속변수(라벨)를 지정한다.\n",
    "X = ndf[['pclass','age','sibsp','parch','female','male','town_C','town_Q','town_S', 'child_women']] # 독립변수\n",
    "y = ndf['survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화(normalization) 한다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 19)\n",
    "\n",
    "# 설명 : test_size = 0.3 에 의해서 7:3 비율로 훈련과 테스트를 나누고 \n",
    "# random_state = 10 에 의해서 나중에 split할 때도 항상 일정하게 split 할 수 있게 한다.\n",
    "\n",
    "\n",
    "# 6단계. 머신러닝 모델을 생성한다.(랜덤 포레스트를 사용)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree_model = RandomForestClassifier(n_estimators = 100, oob_score = True, random_state = 9)\n",
    "\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# oob 평가\n",
    "\"\"\"\n",
    "print(tree_model.oob_score_)\n",
    "print('\\n')\n",
    "\"\"\"\n",
    "\n",
    "# 7단계. 테스트 데이터로 예측하기\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "\n",
    "# 8단계. 모형의 예측 능력을 평가한다. (confusion matrix 만들기!)\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test,y_hat)\n",
    "\n",
    "# confusion matrix에 대한 변수 지정 (tn,fp,fn,tp)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "\n",
    "\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "print(f1_report,'\\n')\n",
    "\n",
    "# 9단계 정확도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반복문 o, 랜덤포레스트 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 포레스트 적용\n",
    "# age 부분 최빈값으로 대체\n",
    "# fare 부분 이상치 제거 및 최빈값으로 NaN 대체\n",
    "# deck 부분 컬럼 삭제\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"d:\\\\data\\\\tat\\\\train.csv\")\n",
    "df2 = pd.read_csv(\"d:\\\\data\\\\tat\\\\test.csv\")\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "mask1 = (df['Age'] < 10) | (df['Sex'] == 'female')\n",
    "mask2 = (df2['Age'] < 10) | (df2['Sex'] == 'female')\n",
    "\n",
    "df['child_women'] = mask1.astype(int)\n",
    "df2['child_women'] = mask2.astype(int)\n",
    "\n",
    "\n",
    "print(df.info())\n",
    "print(df2.info())\n",
    "print('\\n')\n",
    "\n",
    "print(df.isnull().sum(axis=0), '\\n')\n",
    "print(df2.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "# Cabin 칼럼 날려버리기\n",
    "rdf = df.drop(['Cabin'], axis =1)\n",
    "rdf2 = df2.drop(['Cabin'], axis =1)\n",
    "\n",
    "print(rdf.columns.values, '\\n')\n",
    "print(rdf2.columns.values, '\\n')\n",
    "\n",
    "\n",
    "# 나이값 Age컬럼의 결측치를 최빈값으로 대체\n",
    "age_freq1 = rdf['Age'].value_counts(dropna=True).idxmax()\n",
    "age_freq2 = rdf2['Age'].value_counts(dropna=True).idxmax()\n",
    "\n",
    "print(age_freq1) # 24.0\n",
    "print(age_freq2) # 24.0\n",
    "\n",
    "rdf['Age'].fillna(age_freq1, inplace = True)\n",
    "rdf2['Age'].fillna(age_freq2, inplace = True)\n",
    "\n",
    "\n",
    "# Embarked 결측치 값을 최빈값으로 대체\n",
    "# test.csv 에는 Embarked에 결측치 값이 없으므로 과정 생략.\n",
    "most_freq1 = rdf['Embarked'].value_counts(dropna=True).idxmax()\n",
    "# most_freq2 = rdf2['Embarked'].value_counts(dropna=True).idxmax()\n",
    "\n",
    "rdf['Embarked'].fillna(most_freq1, inplace = True)\n",
    "# rdf2['Embarked'].fillna(most_freq2, inplace = True)\n",
    "\n",
    "print(rdf.isnull().sum(axis=0), '\\n')\n",
    "print(rdf2.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ndf = rdf[['Survived','Pclass','Sex','Age','SibSp','Parch','Embarked', 'child_women', 'Fare']]\n",
    "ndf2 = rdf2[['Pclass','Sex','Age','SibSp','Parch','Embarked', 'child_women', 'Fare']]\n",
    "\n",
    "print(ndf.head(), '\\n')\n",
    "print(ndf2.head(), '\\n')\n",
    "\n",
    "gender = pd.get_dummies(ndf['Sex'])\n",
    "gender2 = pd.get_dummies(ndf2['Sex'])\n",
    "\n",
    "ndf = pd.concat([ndf,gender], axis = 1)\n",
    "ndf2 = pd.concat([ndf2,gender2], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['Embarked'], prefix = 'town') # 접두사를 정함.\n",
    "onehot_embarked2 = pd.get_dummies(ndf2['Embarked'], prefix = 'town') # 접두사를 정함.\n",
    "\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "ndf2 = pd.concat([ndf2, onehot_embarked2], axis = 1)\n",
    "\n",
    "ndf.drop(['Sex', 'Embarked'], axis = 1 , inplace = True)\n",
    "ndf2.drop(['Sex', 'Embarked'], axis = 1 , inplace = True)\n",
    "\n",
    "# 운임값(fare)의 이상치를 제거 (훈련데이터만)\n",
    "local_std1 = ndf['Fare'].std() * 5\n",
    "\n",
    "\n",
    "result1 = ndf['Fare'][rdf['Fare'] > local_std1]\n",
    "print(result1)\n",
    "\n",
    "\n",
    "ndf = ndf[:][rdf['Fare'] < local_std1]\n",
    "\n",
    "\n",
    "print(ndf.isnull().sum(axis=0), '\\n')\n",
    "print(ndf2.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "\n",
    "# 운임값(fare)의 결측치를 최빈값으로 채움.\n",
    "fare_freq1 = ndf['Fare'].value_counts(dropna=True).idxmax()\n",
    "fare_freq2 = ndf2['Fare'].value_counts(dropna=True).idxmax()\n",
    "\n",
    "\n",
    "ndf['Fare'].fillna(fare_freq1, inplace = True)\n",
    "ndf2['Fare'].fillna(fare_freq2, inplace = True)\n",
    "\n",
    "print(ndf.isnull().sum(axis=0), '\\n')\n",
    "print(ndf2.isnull().sum(axis=0), '\\n')\n",
    "\n",
    "\n",
    "print(ndf.head())\n",
    "print('\\n')\n",
    "\n",
    "print(ndf2.head())\n",
    "print('\\n')\n",
    "\n",
    "X = ndf[['Pclass','Age','SibSp','Parch','female','male','town_C','town_Q','town_S', 'child_women', 'Fare']] # 독립변수\n",
    "y = ndf['Survived'] # 종속변수\n",
    "\n",
    "test = ndf2[['Pclass','Age','SibSp','Parch','female','male','town_C','town_Q','town_S', 'child_women', 'Fare']]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "test = preprocessing.StandardScaler().fit(test).transform(test)\n",
    "\n",
    "print(X)\n",
    "print(test)\n",
    "\n",
    "\n",
    "# 5단계 . 데이터셋을 훈련데이터와 테스트 데이터로 나눈다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 14)\n",
    "\n",
    "# 설명 : test_size = 0.3 에 의해서 7:3 비율로 훈련과 테스트를 나누고 \n",
    "# random_state = 10 에 의해서 나중에 split할 때도 항상 일정하게 split 할 수 있게 한다.\n",
    "\n",
    "\n",
    "# 6단계. 머신러닝 모델을 생성한다.(랜덤 포레스트를 사용)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree_model = RandomForestClassifier(n_estimators = 60, oob_score = True, random_state = 15)\n",
    "\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# oob 평가\n",
    "\"\"\"\n",
    "print(tree_model.oob_score_)\n",
    "print('\\n')\n",
    "\"\"\"\n",
    "\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "\n",
    "\n",
    "# confusion matrix에 대한 변수 지정 (tn,fp,fn,tp)\n",
    "from sklearn import metrics\n",
    "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# 9단계 정확도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "# Prediction\n",
    "y_pred = tree_model.predict(test)\n",
    "\n",
    "sample_submission=pd.read_csv('d:\\\\data\\\\tat\\\\gender_submission.csv', index_col=0)\n",
    "\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame(data=y_pred,columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission.to_csv('d:\\\\data\\\\tat\\\\submission_randomforest.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
